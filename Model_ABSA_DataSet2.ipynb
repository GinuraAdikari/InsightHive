{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GinuraAdikari/InsightHive/blob/Sentiment_Analysis/Model_ABSA_DataSet2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUDyjbPN36Yy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_scheduler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "ABSA = pd.read_csv(\"ABSA_dataset.csv\")\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "WvlPOyw6aG6F",
        "outputId": "8f763ec4-04ff-4155-c5d8-0f47118a9835"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"ABSA\",\n  \"rows\": 1310,\n  \"fields\": [\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1310,\n        \"samples\": [\n          \"['pretty', 'spend', '##y', 'program', 'decent', 'feature', 'useful', 'opinion', 'especially', 'price', 'free', 'near', 'free', 'resource', 'web', 'nearly', 'useful', 'fraction', 'investment', 'ended', 'going', 'manual', 'abandoning', 'largely', 'business', 'did', 'nt', 'fit', 'admitted', '##ly', 'dozen', 'pre', '##loaded', 'template', 'really', 'well']\",\n          \"['bought', 'alternate', 'play', 'game', 'instead', 'dragging', 'laptop', 'everywhere', 'go', 'apps', 'available', 'also', 'apps', 'are', 'nt', 'updated', 'level', 'almost', 'wished', 'would', 'held', 'buying', 'saved', 'money']\",\n          \"['joy', 'reading', 'ok', 'lame', 'title', 'review', 'really', 'great', 'book', 'sit', 'read', 'page', 'page', 'get', 'drawn', 'world', 'lo', '##han', 'taylor', 'you', 'll', 'find', 'pub', 'listening', 'ji', '##g', 'drinking', 'gui', '##ness', 'singing', 'along', '##you', '##ll', 'cr', '##inge', 'thought', 'benjamin', 'taylor', 'cheer', 'aid', '##a', 'faith', 'sara', 'cry', 'when', '##well', 'going', 'tell', 'you', 'll', 'cry', 'wills', '##it', 'back', 'pull', 'cover', 'prepare', 'transported', 'world', 'two', 'enthusiastic', 'thumb', 'dark', 'side', 'moon']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aspect_mask\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1275,\n        \"samples\": [\n          \"[1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0]\",\n          \"[1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1]\",\n          \"[1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "ABSA"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-cc8b790a-816e-49bb-8d87-6eb7f0eeadbb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>aspect_mask</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['one', 'best', 'game', 'music', 'soundtrack',...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['best', 'purchase', 'ever', 'bought', 'ex', '...</td>\n",
              "      <td>[1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['book', 'slow', 'weak', 'one', 'best', '##st'...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['must', '##rea', '##d', 'every', 'southern', ...</td>\n",
              "      <td>[0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['horrible', 'watch', 'napoleon', 'want', 'fun...</td>\n",
              "      <td>[1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc8b790a-816e-49bb-8d87-6eb7f0eeadbb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc8b790a-816e-49bb-8d87-6eb7f0eeadbb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc8b790a-816e-49bb-8d87-6eb7f0eeadbb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b2c0349f-fc4e-4095-92d8-26787d6f3646\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2c0349f-fc4e-4095-92d8-26787d6f3646')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b2c0349f-fc4e-4095-92d8-26787d6f3646 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              tokens  \\\n",
              "0  ['one', 'best', 'game', 'music', 'soundtrack',...   \n",
              "1  ['best', 'purchase', 'ever', 'bought', 'ex', '...   \n",
              "2  ['book', 'slow', 'weak', 'one', 'best', '##st'...   \n",
              "3  ['must', '##rea', '##d', 'every', 'southern', ...   \n",
              "4  ['horrible', 'watch', 'napoleon', 'want', 'fun...   \n",
              "\n",
              "                                         aspect_mask  sentiment  \n",
              "0  [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, ...          1  \n",
              "1  [1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, ...          1  \n",
              "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, ...          0  \n",
              "3  [0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, ...          1  \n",
              "4  [1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...          0  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ABSA.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWDJMyII4BiY",
        "outputId": "2a8d9022-6ec7-4ac1-81a2-699f76c10aa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train and test datasets created!\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train (80%) and test (20%)\n",
        "train_df, test_df = train_test_split(ABSA, test_size=0.2, random_state=42, stratify=ABSA[\"sentiment\"])\n",
        "\n",
        "print(\"Train and test datasets created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "QQLG929bZrw5",
        "outputId": "cf5dc5da-68a5-4bdd-955b-8a90868de553"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 1048,\n  \"fields\": [\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1048,\n        \"samples\": [\n          \"['would', 'recommend', 'product', 'folk', 'do', 'nt', 'much', 'computer', 'daily', 'weekly', 'monthly', 'one']\",\n          \"['great', 'fi', '##ct', '##ious', 'book', 'book', 'like', 'reading', 'indiana', 'jones', 'agree', 'realistic', 'came', 'many', 'christian', 'theory', 'like', 'justification', 'beat', 'around', 'bush', 'buy', 'respect', 'world', 'truth', 'world', 'buried', 'alive', 'good', 'word', 'author', 'career']\",\n          \"['screen', 'lost', 'color', 'month', 'screen', 'display', 'quality', 'low', '##be', '##for', '##e', 'died', 'even', 'close', 'no', '##ok', 'kind', '##le', 'display', 'poor', 'battery', 'life', 'battery', 'life', 'declined', 'rapidly', 'day', 'one', 'o', 'bug', '##gy', 'even', 'close', 'performance', 'tab', 'version', 'seems', 'based', 'phone', 'rom', 'definitely', 'opt', '##imi', '##zed', 'hardware', 'support', 'sale', 'update', 'o', 'custom', 'rom', 'hard', 'find', 'due', 'unknown', 'exact', 'hardware', 'version', 'would', 'better', 'spend', 'better', 'hardware']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aspect_mask\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1024,\n        \"samples\": [\n          \"[1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1]\",\n          \"[1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1]\",\n          \"[0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3cc2cba5-9d0c-486a-82c5-f7cb65144b7c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>aspect_mask</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>['hey', 'hey', 'wanted', 'say', 'awesome', 'cd...</td>\n",
              "      <td>[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>549</th>\n",
              "      <td>['fantastic', 'information', 'i', 've', 'learn...</td>\n",
              "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>988</th>\n",
              "      <td>['son', 'law', 'loved']</td>\n",
              "      <td>[1, 1, 0]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>['seen', 'old', 'movie', 'many', 'time', 'grea...</td>\n",
              "      <td>[0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>882</th>\n",
              "      <td>['work', 'great', 'house', 'extend', 'wi', '##...</td>\n",
              "      <td>[0, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cc2cba5-9d0c-486a-82c5-f7cb65144b7c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3cc2cba5-9d0c-486a-82c5-f7cb65144b7c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3cc2cba5-9d0c-486a-82c5-f7cb65144b7c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-259bc13c-63e8-4ad3-80a7-d347b517fde0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-259bc13c-63e8-4ad3-80a7-d347b517fde0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-259bc13c-63e8-4ad3-80a7-d347b517fde0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                tokens  \\\n",
              "163  ['hey', 'hey', 'wanted', 'say', 'awesome', 'cd...   \n",
              "549  ['fantastic', 'information', 'i', 've', 'learn...   \n",
              "988                            ['son', 'law', 'loved']   \n",
              "512  ['seen', 'old', 'movie', 'many', 'time', 'grea...   \n",
              "882  ['work', 'great', 'house', 'extend', 'wi', '##...   \n",
              "\n",
              "                                           aspect_mask  sentiment  \n",
              "163  [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...          1  \n",
              "549  [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          1  \n",
              "988                                          [1, 1, 0]          1  \n",
              "512            [0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0]          1  \n",
              "882                           [0, 1, 1, 1, 1, 1, 1, 1]          1  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "QFHk2reKZvn0",
        "outputId": "1c375081-8686-4472-f646-d97de99d61fc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 262,\n  \"fields\": [\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 262,\n        \"samples\": [\n          \"['d', 'suck', 'ps', '##p', 'rock', 'ds', '##pro', '##s', 'ca', 'nt', 'think', 'net', '##hing', '##con', '##s', 'good', 'game', 'plastic', '##y', 'made', 'year', 'old', 'two', 'screen', 'suck', 'bad', 'graphics', '##over', '##all', 'rating', 'i', 'm', 'gen', '##our', '##ous', '##ps', '##pp', '##ros', 'everything', 'great', '##con', '##s', 'battery', 'life', 'ok', '##over', '##all', 'rating', 'regret', 'getting', 'd']\",\n          \"['well', 'name', 'xp', '##lay', 'book', 'favorite', 'show', 'book', 'kind', 'boring', 'thing', 'xp', '##lay', 'interview', 'cast', 'crew', 'rating', 'game', 'review', 'written', 'random', 'people', 'work', 'make', 'ref', '##rence', 'morgan', 'adam', 'ty', '##po', '##es', 'nothing', 'big', 'good', 'ref', '##rence', 'old', 'video', 'game', 'well', 'old', 'also', 'good', 'people', 'do', 'nt', 'watch', 'o', '##d', 'episode', 'watch', 'old', 'review', 'youtube', 'read', 'review', 'computer']\",\n          \"['awesome', 'even', 'button', 'led', 'show', 'charge', 'level']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aspect_mask\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 261,\n        \"samples\": [\n          \"[1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1]\",\n          \"[0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1]\",\n          \"[1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "test_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3822c888-5600-476a-ba8d-a8c372145807\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>aspect_mask</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>684</th>\n",
              "      <td>['book', 'must', 'must', 'pas', 'child', 'fina...</td>\n",
              "      <td>[1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>['reading', 'review', 'almost', 'regretted', '...</td>\n",
              "      <td>[1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1045</th>\n",
              "      <td>['bought', 'husband', 'galaxy', 'tab', 'use', ...</td>\n",
              "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845</th>\n",
              "      <td>['fast', 'easy', 'setup', 'ca', 'nt', 'ask', '...</td>\n",
              "      <td>[1, 1, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936</th>\n",
              "      <td>['log', '##ite', '##ch', 'wireless', 'gaming',...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3822c888-5600-476a-ba8d-a8c372145807')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3822c888-5600-476a-ba8d-a8c372145807 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3822c888-5600-476a-ba8d-a8c372145807');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bdf7c505-46de-4205-aca2-8417106f96e6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bdf7c505-46de-4205-aca2-8417106f96e6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bdf7c505-46de-4205-aca2-8417106f96e6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                 tokens  \\\n",
              "684   ['book', 'must', 'must', 'pas', 'child', 'fina...   \n",
              "972   ['reading', 'review', 'almost', 'regretted', '...   \n",
              "1045  ['bought', 'husband', 'galaxy', 'tab', 'use', ...   \n",
              "845   ['fast', 'easy', 'setup', 'ca', 'nt', 'ask', '...   \n",
              "936   ['log', '##ite', '##ch', 'wireless', 'gaming',...   \n",
              "\n",
              "                                            aspect_mask  sentiment  \n",
              "684   [1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...          1  \n",
              "972   [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...          1  \n",
              "1045               [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]          1  \n",
              "845                            [1, 1, 1, 0, 0, 0, 0, 0]          1  \n",
              "936   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, ...          1  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zoqs58aUPnOg",
        "outputId": "deb73436-89f6-439f-c197-c7b5237137ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ABSADataset class loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "class ABSADataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length=128):\n",
        "        self.tokens = df[\"tokens\"].tolist()\n",
        "        self.aspect_masks = df[\"aspect_mask\"].tolist()\n",
        "        self.sentiments = df[\"sentiment\"].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.tokens[idx]\n",
        "\n",
        "        #  Ensure tokens are lists (avoid string format issues)\n",
        "        if isinstance(tokens, str):\n",
        "            tokens = eval(tokens)\n",
        "        elif not isinstance(tokens, list):\n",
        "            tokens = [tokens]\n",
        "\n",
        "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        #  Use \"aspect_mask\" directly\n",
        "        aspect_mask = self.aspect_masks[idx]\n",
        "        if isinstance(aspect_mask, str):\n",
        "            aspect_mask = eval(aspect_mask)\n",
        "        elif not isinstance(aspect_mask, list):\n",
        "            aspect_mask = [aspect_mask]\n",
        "\n",
        "        #  Create attention mask (1 for actual tokens, 0 for padding)\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "\n",
        "        #  Padding & Truncation\n",
        "        padding_length = self.max_length - len(input_ids)\n",
        "        if padding_length > 0:\n",
        "            input_ids += [0] * padding_length\n",
        "            attention_mask += [0] * padding_length\n",
        "            aspect_mask += [0] * padding_length\n",
        "        else:\n",
        "            input_ids = input_ids[:self.max_length]\n",
        "            attention_mask = attention_mask[:self.max_length]\n",
        "            aspect_mask = aspect_mask[:self.max_length]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
        "            \"aspect_mask\": torch.tensor(aspect_mask, dtype=torch.long),\n",
        "            \"labels\": torch.tensor(self.sentiments[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "print(\" ABSADataset class loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85mAd8pHPrim"
      },
      "outputs": [],
      "source": [
        "class BertForABSA(nn.Module):\n",
        "    def __init__(self, bert_model=\"bert-base-uncased\", num_labels=2):\n",
        "        super(BertForABSA, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model)\n",
        "        self.aspect_attention = nn.Linear(self.bert.config.hidden_size, 1)  # Aspect-aware attention\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)  # Sentiment classification\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, aspect_mask, labels=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        hidden_states = outputs.last_hidden_state\n",
        "\n",
        "        #  Apply aspect-aware attention\n",
        "        aspect_weights = torch.softmax(self.aspect_attention(hidden_states), dim=1)\n",
        "        aspect_weights = aspect_weights * aspect_mask.unsqueeze(-1)\n",
        "        aspect_representations = hidden_states * aspect_weights\n",
        "\n",
        "        #  Use sum instead of mean for better aspect representation\n",
        "        pooled_output = torch.sum(aspect_representations, dim=1)\n",
        "\n",
        "        # Classification layer\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = loss_fn(logits, labels)\n",
        "\n",
        "        return loss, logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek6ozA3EPuki",
        "outputId": "31a7cb94-f21e-4735-b7e3-37e20bc16a95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Loss = 0.6875\n",
            "Epoch 2: Loss = 0.6745\n",
            "Epoch 3: Loss = 0.4988\n"
          ]
        }
      ],
      "source": [
        "#  Initialize device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#  Load tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "#  Load dataset\n",
        "train_dataset = ABSADataset(train_df, tokenizer)\n",
        "test_dataset = ABSADataset(test_df, tokenizer)\n",
        "\n",
        "#  Create DataLoaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "#  Initialize Model\n",
        "model = BertForABSA(num_labels=2).to(device)\n",
        "\n",
        "#  Compute class weights for imbalance handling\n",
        "class_labels = np.array([0, 1])\n",
        "class_weights = compute_class_weight(\"balanced\", classes=class_labels, y=train_df[\"sentiment\"].values)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "#  Define weighted loss function\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "#  Define optimizer and scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "num_epochs = 3\n",
        "num_training_steps = len(train_dataloader) * num_epochs\n",
        "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=100, num_training_steps=num_training_steps)\n",
        "\n",
        "#  Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        loss, logits = model(batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"aspect_mask\"], batch[\"labels\"])\n",
        "        loss = loss_fn(logits, batch[\"labels\"])\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_dataloader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SaDWz-4UPynb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa62bf38-c5ac-428e-ce88-e4ee2933b0ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.71      0.68      0.70        82\n",
            "    Positive       0.86      0.87      0.87       180\n",
            "\n",
            "    accuracy                           0.81       262\n",
            "   macro avg       0.78      0.78      0.78       262\n",
            "weighted avg       0.81      0.81      0.81       262\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#  Evaluate Model\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        _, logits = model(batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"aspect_mask\"])\n",
        "        predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "        y_pred.extend(predictions)\n",
        "        y_true.extend(batch[\"labels\"].cpu().numpy())\n",
        "\n",
        "#  Print classification report\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Negative\", \"Positive\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cnYggB3zP03a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a16e18-09f0-4c93-c9c7-25e76d0ade7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'game': 'Positive', 'music': 'Negative', 'soundtracks': 'Negative', 'fact': 'Positive', 'portion': 'Negative', 'connection': 'Negative', 'soundtrack': 'Negative', 'albums': 'Negative'}\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "#  Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_aspects(sentence):\n",
        "    \"\"\"\n",
        "    Extracts potential aspects from a sentence using POS tagging.\n",
        "    Returns a list of extracted aspect terms.\n",
        "    \"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    aspects = [token.text for token in doc if token.pos_ in [\"NOUN\"]]  # Extract only nouns\n",
        "    return aspects\n",
        "\n",
        "def predict_aspect_sentiment_auto(model, tokenizer, sentence):\n",
        "    \"\"\"\n",
        "    Automatically extracts aspects from a sentence and predicts their sentiment.\n",
        "    Returns a dictionary {aspect: sentiment}.\n",
        "    \"\"\"\n",
        "    aspects = extract_aspects(sentence)  #  Extract aspects using POS tagging\n",
        "    model.eval()\n",
        "    inputs = tokenizer(sentence, padding=\"max_length\", truncation=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    aspect_sentiments = {}\n",
        "\n",
        "    for aspect in aspects:\n",
        "        aspect_tokens = tokenizer.tokenize(aspect)\n",
        "        aspect_mask = torch.zeros_like(inputs[\"input_ids\"], dtype=torch.float).to(device)\n",
        "\n",
        "        for i in range(len(inputs[\"input_ids\"][0]) - len(aspect_tokens) + 1):\n",
        "            if tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][i: i + len(aspect_tokens)]) == aspect_tokens:\n",
        "                aspect_mask[0, i: i + len(aspect_tokens)] = 1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            _, logits = model(inputs[\"input_ids\"], inputs[\"attention_mask\"], aspect_mask)\n",
        "\n",
        "        sentiment_label = torch.argmax(logits, dim=-1).cpu().item()\n",
        "        aspect_sentiments[aspect] = \"Positive\" if sentiment_label == 1 else \"Negative\"\n",
        "\n",
        "    return aspect_sentiments\n",
        "\n",
        "#  Example Usage\n",
        "sentence = \"One of the best game music soundtracks - for a game I didn't really play: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums.\"\n",
        "\n",
        "result = predict_aspect_sentiment_auto(model, tokenizer, sentence)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iflXIQ9TKey"
      },
      "source": [
        "Input Representation for Aspect Awareness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVZnAC_b4ELd"
      },
      "outputs": [],
      "source": [
        "def convert_example_to_features(sentence, aspect, tokenizer, max_length=128):\n",
        "    \"\"\"\n",
        "    Converts a sentence into BERT input features, including an aspect mask.\n",
        "\n",
        "    - sentence: Full review text\n",
        "    - aspect: Aspect term (e.g., 'food', 'service')\n",
        "    - tokenizer: BERT tokenizer\n",
        "    - max_length: Maximum sequence length\n",
        "    \"\"\"\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # Create attention mask\n",
        "    attention_mask = [1] * len(input_ids)\n",
        "\n",
        "    # Generate aspect mask (1 for aspect-related tokens, 0 otherwise)\n",
        "    aspect_mask = [0] * len(input_ids)\n",
        "    aspect_tokens = tokenizer.tokenize(aspect)\n",
        "\n",
        "    for i in range(len(tokens) - len(aspect_tokens) + 1):\n",
        "        if tokens[i: i + len(aspect_tokens)] == aspect_tokens:\n",
        "            aspect_mask[i: i + len(aspect_tokens)] = [1] * len(aspect_tokens)\n",
        "\n",
        "    # Pad sequences\n",
        "    padding_length = max_length - len(input_ids)\n",
        "    input_ids += [0] * padding_length\n",
        "    attention_mask += [0] * padding_length\n",
        "    aspect_mask += [0] * padding_length\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
        "        \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
        "        \"aspect_mask\": torch.tensor(aspect_mask, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3Gii3keTUuW"
      },
      "source": [
        "BERT model for Aspect-Aware Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh3xnSc14IcS"
      },
      "outputs": [],
      "source": [
        "from transformers import BertPreTrainedModel, BertModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BertForABSA(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.bert = BertModel(config)\n",
        "        self.aspect_attention = nn.Linear(config.hidden_size, 1)\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, aspect_mask, labels=None):\n",
        "        # Get BERT output\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        hidden_states = outputs.last_hidden_state  # Shape: (batch_size, seq_len, hidden_dim)\n",
        "\n",
        "        # Apply aspect-aware attention\n",
        "        aspect_weights = torch.sigmoid(self.aspect_attention(hidden_states))  # Compute attention scores\n",
        "        aspect_weights = aspect_weights * aspect_mask.unsqueeze(-1)  # Apply aspect mask\n",
        "        aspect_representations = hidden_states * aspect_weights  # Scale hidden states by attention weights\n",
        "\n",
        "        # Pool aspect-aware representations\n",
        "        pooled_output = aspect_representations.mean(dim=1)\n",
        "\n",
        "        # Classification layer\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fn = nn.CrossEntropyLoss()\n",
        "            loss = loss_fn(logits, labels)\n",
        "\n",
        "        return loss, logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2RuJmheTda7"
      },
      "source": [
        "Training pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e14y7_iO4NNS",
        "outputId": "5202a402-39ee-47fc-ef18-4d03eb60d954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Dataset class loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class ABSADataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length=128):\n",
        "        self.tokens = df[\"tokens\"].tolist()\n",
        "        self.aspect_masks = df[\"aspect_mask\"].tolist()\n",
        "        self.sentiments = df[\"sentiment\"].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.tokens[idx]\n",
        "\n",
        "        # Ensure tokens is a list\n",
        "        if isinstance(tokens, str):  # If stored as string, convert to list\n",
        "            tokens = eval(tokens)\n",
        "        elif not isinstance(tokens, list):  # If somehow still not list, wrap in list\n",
        "            tokens = [tokens]\n",
        "\n",
        "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # Ensure aspect_mask is a list\n",
        "        aspect_mask = self.aspect_masks[idx]\n",
        "        if isinstance(aspect_mask, str):\n",
        "            aspect_mask = eval(aspect_mask)\n",
        "        elif not isinstance(aspect_mask, list):\n",
        "            aspect_mask = [aspect_mask]\n",
        "\n",
        "        # Create attention mask (1 for actual tokens, 0 for padding)\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "\n",
        "        # ** Fix: Ensure consistent sequence length using padding**\n",
        "        if len(input_ids) > self.max_length:\n",
        "            input_ids = input_ids[:self.max_length]\n",
        "            attention_mask = attention_mask[:self.max_length]\n",
        "            aspect_mask = aspect_mask[:self.max_length]\n",
        "        else:\n",
        "            padding_length = self.max_length - len(input_ids)\n",
        "            input_ids += [0] * padding_length\n",
        "            attention_mask += [0] * padding_length\n",
        "            aspect_mask += [0] * padding_length\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
        "            \"aspect_mask\": torch.tensor(aspect_mask, dtype=torch.long),\n",
        "            \"labels\": torch.tensor(self.sentiments[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "print(\" Dataset class loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yglQpd6TW8R4"
      },
      "source": [
        "class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITaKWnCLW-MG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "train_dataset = ABSADataset(train_df, tokenizer)\n",
        "test_dataset = ABSADataset(test_df, tokenizer)\n",
        "\n",
        "#  Fix: Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#  Fix: Ensure `y` is a NumPy array\n",
        "class_labels = np.array([0, 1])  # Only two classes now\n",
        "class_weights = compute_class_weight(\"balanced\", classes=class_labels, y=train_df[\"sentiment\"].values)\n",
        "\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvTrt8bt7r99",
        "outputId": "db60fc8d-84a0-4323-f28e-99a66602801f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train and Test DataLoaders are ready!\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "print(\"Train and Test DataLoaders are ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USRgp4YpTDst"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324,
          "referenced_widgets": [
            "1fa7b91ebaba4b67b14a7fba21132618",
            "482547baa39e4439a51d04c7f23af6e7",
            "267a2f3ae00745ba88cccdeb1ceb5a65",
            "03b1c7652a8b4be98ba082109e648e5a",
            "e64b244718154260acdf32b5f864d4f7",
            "3aca1a57886041cfac9eb50bad8ab062",
            "b1e4b9469a304096b4055bb4c9c601e4",
            "ec0bf5b1513148c2a22af68de3129224",
            "c3b0a78cd0024c619ed75e37075d83c0",
            "20ad16051d5a4ed296f5bc17d025dde3",
            "5f5ec41095864dac815088ebd3ba1c9d"
          ]
        },
        "id": "qHwB0W5g4Qa7",
        "outputId": "95b5469b-9703-4aee-d303-dc586771b836"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fa7b91ebaba4b67b14a7fba21132618",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForABSA were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['aspect_attention.bias', 'aspect_attention.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Starting Training...\n",
            "Epoch [1/3] Step [50/66] - Loss: 0.6844\n",
            "Epoch [1/3] Step [66/66] - Loss: 0.7161\n",
            " Epoch 1 Completed! Avg Loss: 0.6916\n",
            "Epoch [2/3] Step [50/66] - Loss: 0.7050\n",
            "Epoch [2/3] Step [66/66] - Loss: 0.6266\n",
            " Epoch 2 Completed! Avg Loss: 0.6270\n",
            "Epoch [3/3] Step [50/66] - Loss: 0.4958\n",
            "Epoch [3/3] Step [66/66] - Loss: 0.4560\n",
            " Epoch 3 Completed! Avg Loss: 0.4771\n",
            " Training Finished!\n"
          ]
        }
      ],
      "source": [
        "from transformers import AdamW, get_scheduler\n",
        "import torch\n",
        "\n",
        "# Initialize model\n",
        "model = BertForABSA.from_pretrained(\"bert-base-uncased\", num_labels=2)  # 3 sentiment classes (Neg, Neu, Pos)\n",
        "\n",
        "# Define optimizer with weight decay for better generalization\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "# Define learning rate scheduler\n",
        "num_training_steps = len(train_dataloader) * num_epochs\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\", optimizer=optimizer, num_warmup_steps=100, num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "# Set up device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Training Loop\n",
        "print(\" Starting Training...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    num_batches = len(train_dataloader)\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        # Forward pass\n",
        "        loss, logits = model(\n",
        "            batch[\"input_ids\"],\n",
        "            batch[\"attention_mask\"],\n",
        "            batch[\"aspect_mask\"],\n",
        "            batch[\"labels\"]\n",
        "        )\n",
        "\n",
        "        loss = loss_fn(logits, batch[\"labels\"])\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Print loss every 50 steps\n",
        "        if (step + 1) % 50 == 0 or (step + 1) == num_batches:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}] Step [{step+1}/{num_batches}] - Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    print(f\" Epoch {epoch+1} Completed! Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "print(\" Training Finished!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBmf4zsWTmC8"
      },
      "source": [
        "Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZv-L7Yd4SpC",
        "outputId": "c7b91569-5c57-4ab6-8a79-8dc92aa2a4a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.82      0.66      0.73        82\n",
            "    Positive       0.86      0.93      0.89       180\n",
            "\n",
            "    accuracy                           0.85       262\n",
            "   macro avg       0.84      0.80      0.81       262\n",
            "weighted avg       0.84      0.85      0.84       262\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            _, logits = model(batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"aspect_mask\"])\n",
        "            predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "            y_pred.extend(predictions)\n",
        "            y_true.extend(batch[\"labels\"].cpu().numpy())\n",
        "\n",
        "    print(classification_report(y_true, y_pred, target_names=[\"Negative\", \"Positive\"]))\n",
        "\n",
        "# Run evaluation\n",
        "evaluate_model(model, test_dataloader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Guugyr94Wk5z"
      },
      "source": [
        "hyperparameter tunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfTTAe9TWnVZ",
        "outputId": "f6640037-ef4b-4760-df8f-2bc3fd316e9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Training with params: {'batch_size': 8, 'learning_rate': 2e-05, 'weight_decay': 0.01}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForABSA were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['aspect_attention.bias', 'aspect_attention.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Loss: 0.6534200262932377\n",
            "Epoch 2 - Loss: 0.5424236830409247\n",
            "Epoch 3 - Loss: 0.5091745596350604\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.70      0.39      0.50        82\n",
            "    Positive       0.77      0.92      0.84       180\n",
            "\n",
            "    accuracy                           0.76       262\n",
            "   macro avg       0.73      0.66      0.67       262\n",
            "weighted avg       0.75      0.76      0.73       262\n",
            "\n",
            "\n",
            " Training with params: {'batch_size': 8, 'learning_rate': 2e-05, 'weight_decay': 0.001}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForABSA were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['aspect_attention.bias', 'aspect_attention.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Loss: 0.6641075499640167\n",
            "Epoch 2 - Loss: 0.5481806626074187\n",
            "Epoch 3 - Loss: 0.395243507873921\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.80      0.65      0.72        82\n",
            "    Positive       0.85      0.93      0.89       180\n",
            "\n",
            "    accuracy                           0.84       262\n",
            "   macro avg       0.83      0.79      0.80       262\n",
            "weighted avg       0.84      0.84      0.83       262\n",
            "\n",
            "\n",
            " Training with params: {'batch_size': 8, 'learning_rate': 3e-05, 'weight_decay': 0.01}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForABSA were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['aspect_attention.bias', 'aspect_attention.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from transformers import get_scheduler\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Define possible hyperparameters\n",
        "param_grid = {\n",
        "    \"learning_rate\": [2e-5, 3e-5, 5e-5],  # Common BERT fine-tuning rates\n",
        "    \"batch_size\": [8, 16],  # Trade-off between speed and performance\n",
        "    \"weight_decay\": [0.01, 0.001]  # Regularization to avoid overfitting\n",
        "}\n",
        "\n",
        "# Create all possible hyperparameter combinations\n",
        "param_combinations = list(ParameterGrid(param_grid))\n",
        "\n",
        "best_model = None\n",
        "best_f1_score = 0  # Track the best model based on F1-score\n",
        "\n",
        "for params in param_combinations:\n",
        "    print(f\"\\n Training with params: {params}\")\n",
        "\n",
        "    # Load model\n",
        "    model = BertForABSA.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "    model.to(device)\n",
        "\n",
        "    # Optimizer & Learning Rate Scheduler\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=params[\"learning_rate\"], weight_decay=params[\"weight_decay\"])\n",
        "    num_training_steps = len(train_dataloader) * 3  # Assuming 3 epochs\n",
        "    lr_scheduler = get_scheduler(\n",
        "        \"linear\", optimizer=optimizer, num_warmup_steps=100, num_training_steps=num_training_steps\n",
        "    )\n",
        "\n",
        "    # Loss function\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Data Loaders\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
        "    val_dataloader = DataLoader(test_dataset, batch_size=params[\"batch_size\"])\n",
        "\n",
        "    # Training Loop\n",
        "    for epoch in range(3):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch in train_dataloader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss, logits = model(batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"aspect_mask\"], batch[\"labels\"])\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1} - Loss: {total_loss / len(train_dataloader)}\")\n",
        "\n",
        "    # Validate Model\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            _, logits = model(batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"aspect_mask\"])\n",
        "            predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "            y_pred.extend(predictions)\n",
        "            y_true.extend(batch[\"labels\"].cpu().numpy())\n",
        "\n",
        "    # Compute F1-score\n",
        "    report = classification_report(y_true, y_pred, target_names=[\"Negative\", \"Positive\"], output_dict=True)\n",
        "    f1_score = report[\"macro avg\"][\"f1-score\"]\n",
        "    print(classification_report(y_true, y_pred, target_names=[\"Negative\", \"Positive\"]))\n",
        "\n",
        "    # Save best model based on F1-score\n",
        "    if f1_score > best_f1_score:\n",
        "        best_f1_score = f1_score\n",
        "        best_model = model\n",
        "        best_params = params\n",
        "\n",
        "# Save the best model\n",
        "best_model.save_pretrained(\"best_absa_model\")\n",
        "print(f\" Best model saved with params: {best_params} (F1-score: {best_f1_score:.4f})\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiVtImGmgJLRYTOB68zK8h",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03b1c7652a8b4be98ba082109e648e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20ad16051d5a4ed296f5bc17d025dde3",
            "placeholder": "",
            "style": "IPY_MODEL_5f5ec41095864dac815088ebd3ba1c9d",
            "value": "440M/440M[00:08&lt;00:00,48.4MB/s]"
          }
        },
        "1fa7b91ebaba4b67b14a7fba21132618": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_482547baa39e4439a51d04c7f23af6e7",
              "IPY_MODEL_267a2f3ae00745ba88cccdeb1ceb5a65",
              "IPY_MODEL_03b1c7652a8b4be98ba082109e648e5a"
            ],
            "layout": "IPY_MODEL_e64b244718154260acdf32b5f864d4f7"
          }
        },
        "20ad16051d5a4ed296f5bc17d025dde3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "267a2f3ae00745ba88cccdeb1ceb5a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec0bf5b1513148c2a22af68de3129224",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3b0a78cd0024c619ed75e37075d83c0",
            "value": 440449768
          }
        },
        "3aca1a57886041cfac9eb50bad8ab062": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "482547baa39e4439a51d04c7f23af6e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aca1a57886041cfac9eb50bad8ab062",
            "placeholder": "",
            "style": "IPY_MODEL_b1e4b9469a304096b4055bb4c9c601e4",
            "value": "model.safetensors:100%"
          }
        },
        "5f5ec41095864dac815088ebd3ba1c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1e4b9469a304096b4055bb4c9c601e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3b0a78cd0024c619ed75e37075d83c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e64b244718154260acdf32b5f864d4f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec0bf5b1513148c2a22af68de3129224": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}