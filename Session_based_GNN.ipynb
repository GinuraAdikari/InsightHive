{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "CRxB48iDiAF_",
    "ExecuteTime": {
     "end_time": "2025-04-06T15:28:00.728772Z",
     "start_time": "2025-04-06T15:28:00.714949Z"
    }
   },
   "source": [
    "\n",
    "import copy\n",
    "import pickle\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HGQ13SWwiHRl",
    "ExecuteTime": {
     "end_time": "2025-04-06T15:28:10.115174Z",
     "start_time": "2025-04-06T15:28:02.107212Z"
    }
   },
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "import torch_geometric as pyg\n",
    "import torch_geometric.data as pyg_data\n",
    "from torch_geometric.typing import Adj, OptTensor\n",
    "import torch_sparse"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pn79u2Vc7Bi7",
    "outputId": "750d5825-42cc-42f2-9a1d-a64d13259797",
    "ExecuteTime": {
     "end_time": "2025-04-06T15:28:10.875068Z",
     "start_time": "2025-04-06T15:28:10.133049Z"
    }
   },
   "source": [
    "events = pd.read_csv('events.csv')\n",
    "print(events.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       timestamp  visitorid event  itemid  transactionid\n",
      "0  1433221332117     257597  view  355908            NaN\n",
      "1  1433224214164     992329  view  248676            NaN\n",
      "2  1433221999827     111016  view  318965            NaN\n",
      "3  1433221955914     483717  view  253185            NaN\n",
      "4  1433221337106     951259  view  367447            NaN\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "oD7SEiObBC8x",
    "outputId": "6218a809-1c60-4797-9c42-c6de8ffa93d6",
    "ExecuteTime": {
     "end_time": "2025-04-06T06:39:29.473626Z",
     "start_time": "2025-04-06T06:39:29.163936Z"
    }
   },
   "source": "events.describe()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          timestamp     visitorid        itemid  transactionid\n",
       "count  2.756101e+06  2.756101e+06  2.756101e+06   22457.000000\n",
       "mean   1.436424e+12  7.019229e+05  2.349225e+05    8826.497796\n",
       "std    3.366312e+09  4.056875e+05  1.341954e+05    5098.996290\n",
       "min    1.430622e+12  0.000000e+00  3.000000e+00       0.000000\n",
       "25%    1.433478e+12  3.505660e+05  1.181200e+05    4411.000000\n",
       "50%    1.436453e+12  7.020600e+05  2.360670e+05    8813.000000\n",
       "75%    1.439225e+12  1.053437e+06  3.507150e+05   13224.000000\n",
       "max    1.442545e+12  1.407579e+06  4.668670e+05   17671.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.756101e+06</td>\n",
       "      <td>2.756101e+06</td>\n",
       "      <td>2.756101e+06</td>\n",
       "      <td>22457.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.436424e+12</td>\n",
       "      <td>7.019229e+05</td>\n",
       "      <td>2.349225e+05</td>\n",
       "      <td>8826.497796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.366312e+09</td>\n",
       "      <td>4.056875e+05</td>\n",
       "      <td>1.341954e+05</td>\n",
       "      <td>5098.996290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.430622e+12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.433478e+12</td>\n",
       "      <td>3.505660e+05</td>\n",
       "      <td>1.181200e+05</td>\n",
       "      <td>4411.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.436453e+12</td>\n",
       "      <td>7.020600e+05</td>\n",
       "      <td>2.360670e+05</td>\n",
       "      <td>8813.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.439225e+12</td>\n",
       "      <td>1.053437e+06</td>\n",
       "      <td>3.507150e+05</td>\n",
       "      <td>13224.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.442545e+12</td>\n",
       "      <td>1.407579e+06</td>\n",
       "      <td>4.668670e+05</td>\n",
       "      <td>17671.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WLaXTMI3TqYe",
    "outputId": "23fd452c-2ec8-483c-ddc5-f4a62ee17638",
    "ExecuteTime": {
     "end_time": "2025-04-06T06:39:29.644586Z",
     "start_time": "2025-04-06T06:39:29.522689Z"
    }
   },
   "source": "max(events['itemid'])",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "466867"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36yeTCZ6-O6_",
    "outputId": "27afc431-2bf5-458d-953f-9029c796ca88",
    "ExecuteTime": {
     "end_time": "2025-04-06T15:28:52.184719Z",
     "start_time": "2025-04-06T15:28:52.025346Z"
    }
   },
   "source": [
    "# Filter only the 'view' events.\n",
    "view_events = events[events['event'] == 'view']\n",
    "print( {len(view_events)})"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2664312}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "72rxoxUqBT3J",
    "ExecuteTime": {
     "end_time": "2025-04-06T15:28:58.679228Z",
     "start_time": "2025-04-06T15:28:58.367405Z"
    }
   },
   "source": [
    "# Filter out visitors with single clicks.\n",
    "visits_per_visitor = view_events['visitorid'].value_counts(dropna=False)\n",
    "visits_per_visitor.head()\n",
    "\n",
    "filtered_visits_of_visitors = visits_per_visitor[\n",
    "    visits_per_visitor > 1\n",
    "].index\n",
    "view_events = view_events[\n",
    "    view_events['visitorid'].isin(filtered_visits_of_visitors)]"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jQDjX6S1D-nH",
    "outputId": "5d04fea2-11e3-491b-9898-abdbb29f7982",
    "ExecuteTime": {
     "end_time": "2025-04-06T15:29:51.438225Z",
     "start_time": "2025-04-06T15:29:09.798978Z"
    }
   },
   "source": [
    "# Let's group events and their timing data.\n",
    "visits_data = {}\n",
    "for _, row in enumerate(tqdm(view_events.iterrows())):\n",
    "    timestamp, visitorid, event, itemid, transactionid = row[1].values\n",
    "\n",
    "    if visitorid not in visits_data:\n",
    "        visits_data[visitorid] = {'itemids': [], 'timestamps': []}\n",
    "    visits_data[visitorid]['itemids'].append(itemid)\n",
    "    visits_data[visitorid]['timestamps'].append(timestamp)\n",
    "\n",
    "print(f'There are {len(visits_data)} visitors left.')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1656582it [00:41, 39814.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 396449 visitors left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0YdCvwXpIpN6",
    "outputId": "d0c0f98c-1147-46d0-81fb-333c1954c794",
    "ExecuteTime": {
     "end_time": "2025-04-06T15:29:53.365701Z",
     "start_time": "2025-04-06T15:29:51.454358Z"
    }
   },
   "source": [
    "# We will separate sessions by 1 hr.\n",
    "session_gap = 1 * 3600 * 1000\n",
    "\n",
    "# Let's group events from visitors into sessions.\n",
    "sessions_of_visitors = {}\n",
    "for visitorid, visitor_dict in visits_data.items():\n",
    "    sessions = [[]]\n",
    "    sorted_events = sorted(zip(visitor_dict['timestamps'],\n",
    "                               visitor_dict['itemids']))\n",
    "    for i in range(len(sorted_events) - 1):\n",
    "        sessions[-1].append(sorted_events[i][1])\n",
    "        if (sorted_events[i+1][0] - sorted_events[i][0]) > session_gap:\n",
    "            sessions.append([])\n",
    "    sessions[-1].append(sorted_events[len(sorted_events) - 1][1])\n",
    "    sessions_of_visitors[visitorid] = sessions\n",
    "\n",
    "print({len(sessions_of_visitors)})"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{396449}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "80Shzu4P-s_9",
    "ExecuteTime": {
     "end_time": "2025-04-06T15:29:57.980193Z",
     "start_time": "2025-04-06T15:29:57.813046Z"
    }
   },
   "source": [
    "# Adjsut sampling rate ([0, 1]) to generate smaller datasets.\n",
    "# Setting `sampling_rate` to 1 will lead to a full dataset split.\n",
    "sampling_rate = 1\n",
    "\n",
    "# We use random seed for reproducibility.\n",
    "seed = 42\n",
    "all_visitors = list(sessions_of_visitors.keys())\n",
    "random.Random(seed).shuffle(all_visitors)\n",
    "\n",
    "num_train = int(len(all_visitors) * 0.8 * sampling_rate)\n",
    "num_val = int(len(all_visitors) * 0.1 * sampling_rate)\n",
    "num_test = int(len(all_visitors) * 0.1 * sampling_rate)\n",
    "\n",
    "train_visitors = all_visitors[:num_train]\n",
    "val_visitors = all_visitors[num_train : num_train+num_val]\n",
    "test_visitors = all_visitors[num_train+num_val:num_train+num_val+num_test]"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vOt9UVcesil7",
    "ExecuteTime": {
     "end_time": "2025-04-06T15:30:01.786306Z",
     "start_time": "2025-04-06T15:30:01.770580Z"
    }
   },
   "source": [
    "def extract_subsessions(sessions):\n",
    "    all_sessions = []\n",
    "    for session in sessions:\n",
    "        for i in range(1, len(session)):\n",
    "            all_sessions.append(session[:i+1])\n",
    "    return all_sessions"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOTFciFbAHDl",
    "outputId": "cd7a9dd2-3944-409c-97cf-28ff20555ddd",
    "ExecuteTime": {
     "end_time": "2025-04-06T15:30:08.770279Z",
     "start_time": "2025-04-06T15:30:07.390884Z"
    }
   },
   "source": [
    "# Check the number of visitors in each split\n",
    "print(f'train, val, and test visitors: {len(train_visitors), len(val_visitors), len(test_visitors)}')\n",
    "\n",
    "train_sessions, val_sessions, test_sessions = [], [], []\n",
    "for visitor in train_visitors:\n",
    "    train_sessions.extend(extract_subsessions(sessions_of_visitors[visitor]))\n",
    "for visitor in val_visitors:\n",
    "    val_sessions.extend(extract_subsessions(sessions_of_visitors[visitor]))\n",
    "for visitor in test_visitors:\n",
    "    test_sessions.extend(extract_subsessions(sessions_of_visitors[visitor]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, val, and test visitors: (317159, 39644, 39644)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sHNN9AV55P-v",
    "outputId": "538dbb6d-b5c2-4498-c502-9a5e95bf76e5",
    "ExecuteTime": {
     "end_time": "2025-04-06T15:30:19.904302Z",
     "start_time": "2025-04-06T15:30:19.428068Z"
    }
   },
   "source": [
    "# Check the number of (sub)sessions in each split\n",
    "print(f'train, val, and test sessions: {len(train_sessions), len(val_sessions), len(test_sessions)}')\n",
    "\n",
    "# Save the processed files.\n",
    "with open('raw/train.txt', 'wb') as f:\n",
    "    pickle.dump(train_sessions, f)\n",
    "with open('raw/val.txt', 'wb') as f:\n",
    "    pickle.dump(val_sessions, f)\n",
    "with open('raw/test.txt', 'wb') as f:\n",
    "    pickle.dump(test_sessions, f)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, val, and test sessions: (759943, 88625, 93999)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "82KWESLd-1gV",
    "ExecuteTime": {
     "end_time": "2025-04-06T15:31:36.119476Z",
     "start_time": "2025-04-06T15:31:36.103666Z"
    }
   },
   "source": [
    "class GraphDataset(pyg_data.InMemoryDataset):\n",
    "    def __init__(self, root, file_name, transform=None, pre_transform=None):\n",
    "        self.file_name = file_name\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0], weights_only=False)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [f'{self.file_name}.txt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f'{self.file_name}.pt']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        raw_data_file = f'{self.raw_dir}/{self.raw_file_names[0]}'\n",
    "        with open(raw_data_file, 'rb') as f:\n",
    "            sessions = pickle.load(f)\n",
    "        data_list = []\n",
    "\n",
    "        for session in sessions:\n",
    "            session, y = session[:-1], session[-1]\n",
    "            codes, uniques = pd.factorize(session)\n",
    "            senders, receivers = codes[:-1], codes[1:]\n",
    "\n",
    "            edge_index = torch.tensor(np.array([senders, receivers]))\n",
    "            x = torch.tensor(uniques, dtype=torch.long).unsqueeze(1)\n",
    "            y = torch.tensor([y], dtype=torch.long)\n",
    "            data_list.append(pyg_data.Data(x=x, edge_index=edge_index, y=y))\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7K3HWrcwqp0Z",
    "ExecuteTime": {
     "end_time": "2025-04-06T15:31:37.323091Z",
     "start_time": "2025-04-06T15:31:37.307157Z"
    }
   },
   "source": [
    "class GatedSessionGraphConv(pyg.nn.conv.MessagePassing):\n",
    "    def __init__(self, out_channels, aggr: str = 'add', **kwargs):\n",
    "        super().__init__(aggr=aggr, **kwargs)\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.gru = torch.nn.GRUCell(out_channels, out_channels, bias=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        m = self.propagate(edge_index, x=x, size=None)\n",
    "        x = self.gru(m, x)\n",
    "        return x\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t, x):\n",
    "        return matmul(adj_t, x, reduce=self.aggr)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TNsAHq8PCN3k",
    "ExecuteTime": {
     "end_time": "2025-04-06T15:31:39.523354Z",
     "start_time": "2025-04-06T15:31:39.507229Z"
    }
   },
   "source": [
    "class SRGNN(nn.Module):\n",
    "    def __init__(self, hidden_size, n_items):\n",
    "        super(SRGNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_items = n_items\n",
    "\n",
    "        self.embedding = nn.Embedding(self.n_items, self.hidden_size)\n",
    "        self.gated = GatedSessionGraphConv(self.hidden_size)\n",
    "\n",
    "        self.q = nn.Linear(self.hidden_size, 1)\n",
    "        self.W_1 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.W_2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.W_3 = nn.Linear(2 * self.hidden_size, self.hidden_size, bias=False)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch_map = data.x, data.edge_index, data.batch\n",
    "\n",
    "        embedding = self.embedding(x).squeeze()\n",
    "\n",
    "        v_i = self.gated(embedding, edge_index)\n",
    "\n",
    "        sections = list(torch.bincount(batch_map).cpu())\n",
    "        v_i_split = torch.split(v_i, sections)\n",
    "\n",
    "        v_n, v_n_repeat = [], []\n",
    "        for session in v_i_split:\n",
    "            v_n.append(session[-1])\n",
    "            v_n_repeat.append(\n",
    "                session[-1].view(1, -1).repeat(session.shape[0], 1))\n",
    "        v_n, v_n_repeat = torch.stack(v_n), torch.cat(v_n_repeat, dim=0)\n",
    "\n",
    "        q1 = self.W_1(v_n_repeat)\n",
    "        q2 = self.W_2(v_i)\n",
    "\n",
    "        #creating global Embedding\n",
    "        alpha = self.q(F.sigmoid(q1 + q2))\n",
    "        s_g_split = torch.split(alpha * v_i, sections)\n",
    "\n",
    "        s_g = []\n",
    "        for session in s_g_split:\n",
    "            s_g_session = torch.sum(session, dim=0)\n",
    "            s_g.append(s_g_session)\n",
    "        s_g = torch.stack(s_g)\n",
    "\n",
    "        s_l = v_n # local Embedding\n",
    "        s_h = self.W_3(torch.cat([s_l, s_g], dim=-1))\n",
    "\n",
    "        z = torch.mm(self.embedding.weight, s_h.T).T\n",
    "        return z"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T06:40:04.469486Z",
     "start_time": "2025-04-06T06:40:04.438028Z"
    }
   },
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.backends.cudnn.enabled)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu126\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T06:40:04.827321Z",
     "start_time": "2025-04-06T06:40:04.811425Z"
    }
   },
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Desktop\\ML viva\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T06:40:04.868591Z",
     "start_time": "2025-04-06T06:40:04.852694Z"
    }
   },
   "source": [
    "import torch\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.6.0+cu126\n",
      "CUDA Available: True\n",
      "CUDA Version: 12.6\n",
      "GPU Name: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5gMZqEW81HYj",
    "ExecuteTime": {
     "end_time": "2025-04-06T06:40:05.231064Z",
     "start_time": "2025-04-06T06:40:05.215067Z"
    }
   },
   "source": [
    "# hyperparameters.\n",
    "args = {\n",
    "    'batch_size': 128,\n",
    "    'hidden_dim': 64,\n",
    "    'epochs': 10,\n",
    "    'l2_penalty': 0.0001,\n",
    "    'weight_decay': 0.1,\n",
    "    'step': 5,\n",
    "    'lr': 0.001,\n",
    "    'num_items': 466868}\n",
    "\n",
    "class objectview(object):\n",
    "    def __init__(self, d): \n",
    "        self.__dict__ = d\n",
    "\n",
    "args = objectview(args)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T06:40:05.246879Z",
     "start_time": "2025-04-06T06:40:05.231064Z"
    }
   },
   "source": [
    "print(\"w\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8iVoTPoJAKkU",
    "ExecuteTime": {
     "end_time": "2025-04-06T15:33:37.398592Z",
     "start_time": "2025-04-06T15:33:37.386887Z"
    }
   },
   "source": [
    "def train(args):\n",
    "    # Prepare data pipeline\n",
    "    train_dataset = GraphDataset('./', 'train')\n",
    "    train_loader = pyg_data.DataLoader(train_dataset,\n",
    "                                       batch_size=args.batch_size,\n",
    "                                       shuffle=False,\n",
    "                                       drop_last=True)\n",
    "    val_dataset = GraphDataset('./', 'val')\n",
    "    val_loader = pyg_data.DataLoader(val_dataset,\n",
    "                                     batch_size=args.batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     drop_last=True)\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    # Build model\n",
    "    model = SRGNN(args.hidden_dim, args.num_items).to(device)\n",
    "\n",
    "    # Get training components\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=args.lr,\n",
    "                                 weight_decay=args.l2_penalty)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer,\n",
    "                                          step_size=args.step,\n",
    "                                          gamma=args.weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train\n",
    "    losses = []\n",
    "    test_accs = []\n",
    "    top_k_accs = []\n",
    "\n",
    "    best_acc = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for _, batch in enumerate(tqdm(train_loader)):\n",
    "            batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model(batch)\n",
    "            label = batch.y\n",
    "            loss = criterion(pred, label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "\n",
    "        total_loss /= len(train_loader.dataset)\n",
    "        losses.append(total_loss)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "          test_acc, top_k_acc = test(val_loader, model, is_validation=True)\n",
    "          print(test_acc)\n",
    "          test_accs.append(test_acc)\n",
    "          top_k_accs.append(top_k_acc)\n",
    "          if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "          test_accs.append(test_accs[-1])\n",
    "  \n",
    "    return test_accs, top_k_accs, losses, best_model, best_acc, val_loader"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T19:07:31.750123Z",
     "start_time": "2025-03-28T19:07:31.742101Z"
    },
    "id": "UTiJJ1pm0ks9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▊                                                                                                                     | 11/747 [00:02<05:31,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▎                                                                                                                   | 21/747 [00:05<05:15,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████▉                                                                                                                  | 31/747 [00:08<04:56,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 30 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██████▌                                                                                                                | 41/747 [00:11<05:39,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 40 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████████                                                                                                               | 51/747 [00:13<04:57,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████████▋                                                                                                             | 61/747 [00:16<04:45,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 60 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████▎                                                                                                           | 71/747 [00:19<04:56,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 70 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████████▉                                                                                                          | 81/747 [00:21<04:36,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 80 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████████▍                                                                                                        | 91/747 [00:24<04:53,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 90 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████████▉                                                                                                      | 101/747 [00:27<04:32,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████▌                                                                                                    | 111/747 [00:29<04:29,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 110 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████████                                                                                                   | 121/747 [00:32<04:23,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 120 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████████▋                                                                                                 | 131/747 [00:35<04:23,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 130 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████████████▎                                                                                               | 141/747 [00:37<03:43,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 140 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████▊                                                                                              | 151/747 [00:40<04:45,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 150 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████████▍                                                                                            | 161/747 [00:43<03:39,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 160 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████████████                                                                                           | 171/747 [00:46<04:09,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 170 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████████████▌                                                                                         | 181/747 [00:48<04:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 180 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████████████▏                                                                                       | 191/747 [00:51<03:36,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 190 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████████████▊                                                                                      | 201/747 [00:54<03:44,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████████████████▎                                                                                    | 211/747 [00:56<03:45,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 210 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████████████▉                                                                                   | 221/747 [00:59<03:48,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 220 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████████████████▍                                                                                 | 231/747 [01:01<03:13,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 230 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████████████                                                                                | 241/747 [01:04<03:44,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 240 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████████████████▋                                                                              | 251/747 [01:07<03:16,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████████████████▍                                                                            | 262/747 [01:10<02:52,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 260 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████████████████████▊                                                                           | 271/747 [01:12<03:11,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 270 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████████████████████▍                                                                         | 281/747 [01:15<03:28,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 280 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████████████████████▉                                                                        | 291/747 [01:18<03:17,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 290 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████████████████▌                                                                      | 301/747 [01:20<03:09,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 300 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████████████████████▏                                                                    | 311/747 [01:23<02:46,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 310 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████████████████████▋                                                                   | 321/747 [01:26<03:13,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 320 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████████████████████▎                                                                 | 331/747 [01:29<02:56,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 330 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████████████████████▊                                                                | 341/747 [01:31<02:37,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 340 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|███████████████████████████████████████████████████████▍                                                              | 351/747 [01:34<02:29,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 350 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████████████████████████                                                             | 361/747 [01:36<02:38,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 360 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████▌                                                           | 371/747 [01:39<02:36,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 370 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████████████████████████▏                                                         | 381/747 [01:41<02:28,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 380 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████████████████████████▊                                                        | 391/747 [01:44<02:28,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 390 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████████████████████████████████████▎                                                      | 401/747 [01:47<02:09,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 400 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████████████████████████████████████████████▉                                                     | 411/747 [01:49<02:01,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 410 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████████████████████████████████████████████████▌                                                   | 421/747 [01:52<02:18,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 420 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|████████████████████████████████████████████████████████████████████                                                  | 431/747 [01:55<02:07,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 430 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████████████████████████████████████████████████████████████████████▋                                                | 441/747 [01:57<02:12,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 440 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████████████████████████▏                                              | 451/747 [02:00<02:03,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 450 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████████████████████████████████████████████████████▊                                             | 461/747 [02:02<01:58,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 460 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████████████████████████████▍                                           | 471/747 [02:05<01:54,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 470 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████████████████████████████▉                                          | 481/747 [02:08<01:54,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 480 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████████████████████████████▌                                        | 491/747 [02:10<01:32,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 490 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████████████████████████████████▏                                      | 501/747 [02:13<01:39,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████████████████████████████████▋                                     | 511/747 [02:16<01:43,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 510 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████████████████████████████▎                                   | 521/747 [02:19<01:34,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 520 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████████████████████████████████████████████████████████▋                                  | 530/747 [02:21<02:10,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 530 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████████████████████████████████████▍                                | 541/747 [02:24<01:26,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 540 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████████████████████████████████                               | 551/747 [02:27<01:27,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 550 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████████████████████████████████▌                             | 561/747 [02:29<01:12,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 560 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████████████████████████████████████████████████████████████████████▏                           | 571/747 [02:32<01:25,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 570 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████▊                          | 581/747 [02:35<01:15,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 580 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████████████████████████████████████████████▎                        | 591/747 [02:38<01:11,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 590 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████████████████████████████████▊                       | 600/747 [02:41<01:07,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 600 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████████████████████████████████████████████████████████████████████▌                     | 611/747 [02:43<00:46,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 610 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████████████████████████████████████████                    | 621/747 [02:46<00:52,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 620 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████████████████████████████████████▋                  | 631/747 [02:49<00:49,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 630 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎                | 641/747 [02:51<00:46,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 640 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 650/747 [02:54<00:53,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 650 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 661/747 [02:57<00:36,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 660 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 670/747 [02:59<00:45,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 670 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌          | 681/747 [03:02<00:26,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 680 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏        | 691/747 [03:05<00:23,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 690 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋       | 701/747 [03:07<00:17,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 700 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 711/747 [03:10<00:15,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 710 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 721/747 [03:13<00:11,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 720 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 731/747 [03:15<00:06,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 730 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████ | 741/747 [03:18<00:02,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 740 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 747/747 [03:19<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.250892458723784, 'hit_rate@k': 0.5554439982150825, 'precision@k': 0.6428571428571429, 'recall@k': 0.6428571428571429, 'mrr': 0.38575762477770986, 'ndcg@k': 0.4410254088639926, 'diversity': 0.41785714285714287, 'novelty': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def precision_at_k(predictions, labels, k):\n",
    "    top_k_preds = predictions.argsort(axis=1)[:, -k:]\n",
    "    hits = (top_k_preds == labels[:, None]).sum(axis=1)\n",
    "    return hits.mean()\n",
    "\n",
    "def recall_at_k(predictions, labels, k):\n",
    "    top_k_preds = predictions.argsort(axis=1)[:, -k:]\n",
    "    hits = (top_k_preds == labels[:, None]).sum(axis=1)\n",
    "    return hits.mean()\n",
    "\n",
    "def mean_reciprocal_rank(predictions, labels):\n",
    "    recip_ranks = []\n",
    "    for i in range(predictions.shape[0]):\n",
    "        pred = predictions[i]\n",
    "        rank = np.where(pred.argsort()[::-1] == labels[i])[0][0]\n",
    "        recip_ranks.append(1.0 / (rank + 1))\n",
    "    return np.mean(recip_ranks)\n",
    "\n",
    "def ndcg_at_k(predictions, labels, k):\n",
    "    def dcg(scores):\n",
    "        return np.sum(scores / np.log2(np.arange(2, scores.size + 2)))\n",
    "\n",
    "    ndcg_scores = []\n",
    "    for i in range(predictions.shape[0]):\n",
    "        pred = predictions[i]\n",
    "        true_relevance = np.zeros(pred.shape)\n",
    "        true_relevance[labels[i]] = 1\n",
    "        ranked_relevance = true_relevance[pred.argsort()[::-1]]\n",
    "        ideal_relevance = np.sort(true_relevance)[::-1]\n",
    "        ndcg_scores.append(dcg(ranked_relevance[:k]) / dcg(ideal_relevance[:k]))\n",
    "    return np.mean(ndcg_scores)\n",
    "\n",
    "def diversity(predictions, k):\n",
    "    top_k_preds = predictions.argsort(axis=1)[:, -k:]\n",
    "    unique_items = np.unique(top_k_preds)\n",
    "    return len(unique_items) / (predictions.shape[0] * k)\n",
    "\n",
    "def save_checkpoint(epoch, data, filename='checkpoint.pth.tar'):\n",
    "    torch.save({'epoch': epoch, 'data': data}, filename)\n",
    "\n",
    "def test(loader, test_model, is_validation=False, save_model_preds=False, item_popularity=None, checkpoint_interval=10):\n",
    "    test_model.eval()\n",
    "\n",
    "    # Define K for metrics.\n",
    "    k = 10\n",
    "    correct = 0\n",
    "    top_k_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_scores = []\n",
    "\n",
    "    batch_count = 0\n",
    "\n",
    "    for idx, data in enumerate(tqdm(loader)):\n",
    "        try:\n",
    "            data = data.to('cuda')\n",
    "            with torch.no_grad():\n",
    "                score = test_model(data)\n",
    "                pred = score.max(dim=1)[1]\n",
    "                label = data.y\n",
    "\n",
    "            if save_model_preds:\n",
    "                all_preds.extend(pred.view(-1).cpu().detach().numpy())\n",
    "                all_labels.extend(label.view(-1).cpu().detach().numpy())\n",
    "                all_scores.extend(score.cpu().detach().numpy())\n",
    "\n",
    "            correct += pred.eq(label).sum().item()\n",
    "            total_samples += label.size(0)\n",
    "\n",
    "            if not is_validation:\n",
    "                score = score.cpu().detach().numpy()\n",
    "                for row in range(pred.size(0)):\n",
    "                    top_k_pred = np.argpartition(score[row], -k)[-k:]\n",
    "                    if label[row].item() in top_k_pred:\n",
    "                        top_k_correct += 1\n",
    "\n",
    "            # Save checkpoint\n",
    "            if save_model_preds and (idx + 1) % checkpoint_interval == 0:\n",
    "                save_checkpoint(idx + 1, {\n",
    "                    'pred': all_preds,\n",
    "                    'label': all_labels,\n",
    "                    'score': all_scores\n",
    "                })\n",
    "                # Clear intermediate results to free up memory\n",
    "                all_preds = []\n",
    "                all_labels = []\n",
    "                all_scores = []\n",
    "\n",
    "            # Clear CUDA cache to free up memory\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            batch_count += 1\n",
    "            if batch_count % 10 == 0:\n",
    "                print(f\"Processed {batch_count} batches\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch: {e}\")\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    if save_model_preds:\n",
    "        data = {\n",
    "            'pred': all_preds,\n",
    "            'label': all_labels,\n",
    "            'score': all_scores\n",
    "        }\n",
    "        df = pd.DataFrame(data=data)\n",
    "        df.to_csv('pred.csv', sep=',', index=False)\n",
    "\n",
    "    if not is_validation:\n",
    "        all_scores = np.array(all_scores)\n",
    "        all_labels = np.array(all_labels)\n",
    "        precision_k = precision_at_k(all_scores, all_labels, k)\n",
    "        recall_k = recall_at_k(all_scores, all_labels, k)\n",
    "        mrr = mean_reciprocal_rank(all_scores, all_labels)\n",
    "        ndcg_k = ndcg_at_k(all_scores, all_labels, k)\n",
    "        diversity_score = diversity(all_scores, k)\n",
    "\n",
    "        return {\n",
    "            'hit_rate': correct / total_samples,\n",
    "            'hit_rate@k': top_k_correct / total_samples,\n",
    "            'precision@k': precision_k,\n",
    "            'recall@k': recall_k,\n",
    "            'mrr': mrr,\n",
    "            'ndcg@k': ndcg_k,\n",
    "            'diversity': diversity_score,\n",
    "        }\n",
    "    else:\n",
    "        return correct / total_samples, 0\n",
    "\n",
    "test_dataset = GraphDataset('./', 'test')\n",
    "test_loader = pyg_data.DataLoader(test_dataset,\n",
    "                                  batch_size=args.batch_size // 10,  # Further reduce batch size\n",
    "                                  shuffle=False,\n",
    "                                  drop_last=True)\n",
    "\n",
    "item_popularity = np.zeros((args.num_items,))\n",
    "\n",
    "metrics = test(test_loader, best_model, is_validation=False, save_model_preds=True, item_popularity=item_popularity)\n",
    "print(metrics)"
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-06T06:40:27.684266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def precision_at_k(predictions, labels, k):\n",
    "    top_k_preds = predictions.argsort(axis=1)[:, -k:]\n",
    "    hits = (top_k_preds == labels[:, None]).sum(axis=1)\n",
    "    return hits.mean()\n",
    "\n",
    "def recall_at_k(predictions, labels, k):\n",
    "    top_k_preds = predictions.argsort(axis=1)[:, -k:]\n",
    "    hits = (top_k_preds == labels[:, None]).sum(axis=1)\n",
    "    return hits.mean()\n",
    "\n",
    "def mean_reciprocal_rank(predictions, labels):\n",
    "    recip_ranks = []\n",
    "    for i in range(predictions.shape[0]):\n",
    "        pred = predictions[i]\n",
    "        rank = np.where(pred.argsort()[::-1] == labels[i])[0][0]\n",
    "        recip_ranks.append(1.0 / (rank + 1))\n",
    "    return np.mean(recip_ranks)\n",
    "\n",
    "def ndcg_at_k(predictions, labels, k):\n",
    "    def dcg(scores):\n",
    "        return np.sum(scores / np.log2(np.arange(2, scores.size + 2)))\n",
    "\n",
    "    ndcg_scores = []\n",
    "    for i in range(predictions.shape[0]):\n",
    "        pred = predictions[i]\n",
    "        true_relevance = np.zeros(pred.shape)\n",
    "        true_relevance[labels[i]] = 1\n",
    "        ranked_relevance = true_relevance[pred.argsort()[::-1]]\n",
    "        ideal_relevance = np.sort(true_relevance)[::-1]\n",
    "        ndcg_scores.append(dcg(ranked_relevance[:k]) / dcg(ideal_relevance[:k]))\n",
    "    return np.mean(ndcg_scores)\n",
    "\n",
    "def diversity(predictions, k):\n",
    "    top_k_preds = predictions.argsort(axis=1)[:, -k:]\n",
    "    unique_items = np.unique(top_k_preds)\n",
    "    return len(unique_items) / (predictions.shape[0] * k)\n",
    "\n",
    "def save_checkpoint(epoch, data, filename='checkpoint.pth.tar'):\n",
    "    torch.save({'epoch': epoch, 'data': data}, filename)\n",
    "\n",
    "def test(loader, test_model, is_validation=False, save_model_preds=False, item_popularity=None, checkpoint_interval=10):\n",
    "    test_model.eval()\n",
    "\n",
    "    # Define K for metrics.\n",
    "    k = 10\n",
    "    correct = 0\n",
    "    top_k_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_scores = []\n",
    "\n",
    "    batch_count = 0\n",
    "\n",
    "    for idx, data in enumerate(tqdm(loader)):\n",
    "        try:\n",
    "            data = data.to('cuda')\n",
    "            with torch.no_grad():\n",
    "                score = test_model(data)\n",
    "                pred = score.max(dim=1)[1]\n",
    "                label = data.y\n",
    "\n",
    "            if save_model_preds:\n",
    "                all_preds.extend(pred.view(-1).cpu().detach().numpy())\n",
    "                all_labels.extend(label.view(-1).cpu().detach().numpy())\n",
    "                all_scores.extend(score.cpu().detach().numpy())\n",
    "\n",
    "            correct += pred.eq(label).sum().item()\n",
    "            total_samples += label.size(0)\n",
    "\n",
    "            if not is_validation:\n",
    "                score = score.cpu().detach().numpy()\n",
    "                for row in range(pred.size(0)):\n",
    "                    top_k_pred = np.argpartition(score[row], -k)[-k:]\n",
    "                    if label[row].item() in top_k_pred:\n",
    "                        top_k_correct += 1\n",
    "\n",
    "            # Save checkpoint\n",
    "            if save_model_preds and (idx + 1) % checkpoint_interval == 0:\n",
    "                save_checkpoint(idx + 1, {\n",
    "                    'pred': all_preds,\n",
    "                    'label': all_labels,\n",
    "                    'score': all_scores\n",
    "                })\n",
    "                # Clear intermediate results to free up memory\n",
    "                all_preds = []\n",
    "                all_labels = []\n",
    "                all_scores = []\n",
    "\n",
    "            # Clear CUDA cache to free up memory\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            batch_count += 1\n",
    "            if batch_count % 10 == 0:\n",
    "                print(f\"Processed {batch_count} batches\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch: {e}\")\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    if save_model_preds:\n",
    "        data = {\n",
    "            'pred': all_preds,\n",
    "            'label': all_labels,\n",
    "            'score': all_scores\n",
    "        }\n",
    "        df = pd.DataFrame(data=data)\n",
    "        df.to_csv('pred.csv', sep=',', index=False)\n",
    "\n",
    "    if not is_validation:\n",
    "        all_scores = np.array(all_scores)\n",
    "        all_labels = np.array(all_labels)\n",
    "        precision_k = precision_at_k(all_scores, all_labels, k)\n",
    "        recall_k = recall_at_k(all_scores, all_labels, k)\n",
    "        mrr = mean_reciprocal_rank(all_scores, all_labels)\n",
    "        ndcg_k = ndcg_at_k(all_scores, all_labels, k)\n",
    "        diversity_score = diversity(all_scores, k)\n",
    "\n",
    "        return {\n",
    "            'hit_rate': correct / total_samples,\n",
    "            'hit_rate@k': top_k_correct / total_samples,\n",
    "            'precision@k': precision_k,\n",
    "            'recall@k': recall_k,\n",
    "            'mrr': mrr,\n",
    "            'ndcg@k': ndcg_k,\n",
    "            'diversity': diversity_score,\n",
    "        }\n",
    "    else:\n",
    "        return correct / total_samples, 0\n",
    "\n",
    "# Run test for our best model to save the predictions!\n",
    "train_dataset = GraphDataset('./', 'train')\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                                  batch_size=args.batch_size // 10,  # Further reduce batch size\n",
    "                                  shuffle=False,\n",
    "                                  drop_last=True)\n",
    "\n",
    "# Assuming item_popularity is a numpy array with the popularity of each item\n",
    "item_popularity = np.zeros((args.num_items,))\n",
    "\n",
    "metrics = test(train_loader, best_model, is_validation=False, save_model_preds=True, item_popularity=item_popularity)\n",
    "print(metrics)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/31146 [00:03<3:56:27,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/31146 [00:06<3:40:31,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 31/31146 [00:08<3:26:55,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 30 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 41/31146 [00:11<3:59:58,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 40 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 52/31146 [00:14<3:01:17,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 61/31146 [00:17<3:47:07,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 60 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 71/31146 [00:20<4:03:07,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 70 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 81/31146 [00:22<3:11:56,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 80 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 91/31146 [00:25<3:42:53,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 90 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 101/31146 [00:28<3:50:25,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 112/31146 [00:31<3:12:00,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 110 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 121/31146 [00:33<3:53:21,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 120 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 131/31146 [00:36<3:32:03,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 130 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 141/31146 [00:39<3:46:18,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 140 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 151/31146 [00:42<3:21:27,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 150 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 161/31146 [00:44<3:25:38,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 160 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 171/31146 [00:47<3:43:45,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 170 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 181/31146 [00:50<3:42:35,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 180 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 191/31146 [00:52<3:46:58,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 190 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 201/31146 [00:55<2:57:05,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 211/31146 [00:58<3:30:55,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 210 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 221/31146 [01:01<3:57:16,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 220 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 231/31146 [01:03<3:16:21,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 230 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 241/31146 [01:06<3:44:27,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 240 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 251/31146 [01:08<3:37:26,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 261/31146 [01:11<3:39:31,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 260 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 271/31146 [01:14<3:34:32,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 270 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 281/31146 [01:16<3:26:20,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 280 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 290/31146 [01:19<5:08:04,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 290 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 301/31146 [01:22<3:49:13,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 300 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 311/31146 [01:25<3:52:30,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 310 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 321/31146 [01:28<3:49:29,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 320 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 331/31146 [01:30<3:16:57,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 330 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 341/31146 [01:33<3:53:24,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 340 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 351/31146 [01:36<3:59:33,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 350 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 361/31146 [01:39<3:41:36,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 360 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 371/31146 [01:41<3:51:38,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 370 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 381/31146 [01:44<3:32:03,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 380 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 391/31146 [01:47<3:27:33,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 390 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 401/31146 [01:50<3:51:40,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 400 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 411/31146 [01:53<3:54:47,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 410 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 422/31146 [01:56<3:15:30,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 420 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 431/31146 [01:58<3:49:38,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 430 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 441/31146 [02:01<3:38:33,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 440 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 450/31146 [02:04<5:16:59,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 450 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 461/31146 [02:06<3:42:44,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 460 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 471/31146 [02:09<3:54:12,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 470 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 481/31146 [02:12<3:26:47,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 480 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 491/31146 [02:15<3:28:54,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 490 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 502/31146 [02:18<3:06:32,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 511/31146 [02:20<3:08:22,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 510 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 522/31146 [02:23<2:55:51,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 520 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 531/31146 [02:26<3:29:27,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 530 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 541/31146 [02:28<3:37:09,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 540 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 551/31146 [02:31<3:19:01,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 550 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 561/31146 [02:34<3:46:09,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 560 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 571/31146 [02:37<3:27:07,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 570 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 581/31146 [02:39<3:45:31,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 580 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 591/31146 [02:42<3:13:43,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 590 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 601/31146 [02:45<3:56:44,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 600 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 611/31146 [02:48<3:34:14,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 610 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 621/31146 [02:50<3:38:06,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 620 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 631/31146 [02:53<3:46:07,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 630 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 641/31146 [02:56<3:35:48,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 640 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 652/31146 [02:59<2:55:50,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 650 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 661/31146 [03:01<3:53:52,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 660 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 671/31146 [03:04<3:52:57,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 670 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 681/31146 [03:07<3:40:29,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 680 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 691/31146 [03:10<3:42:36,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 690 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 701/31146 [03:12<3:25:04,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 700 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 711/31146 [03:15<3:07:22,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 710 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 721/31146 [03:18<3:52:20,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 720 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 731/31146 [03:21<3:46:20,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 730 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 741/31146 [03:24<3:48:47,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 740 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 751/31146 [03:26<3:31:19,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 750 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 761/31146 [03:29<3:11:03,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 760 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 771/31146 [03:32<3:53:27,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 770 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 781/31146 [03:35<3:37:03,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 780 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 791/31146 [03:37<3:40:30,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 790 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 801/31146 [03:40<3:16:20,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 800 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 812/31146 [03:43<2:51:15,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 810 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 821/31146 [03:46<3:23:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 820 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 830/31146 [03:48<4:53:21,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 830 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 841/31146 [03:51<3:51:06,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 840 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 851/31146 [03:54<3:24:44,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 850 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 861/31146 [03:57<3:46:11,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 860 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 871/31146 [04:00<3:46:31,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 870 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 881/31146 [04:02<3:43:40,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 880 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 891/31146 [04:05<3:01:04,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 890 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 901/31146 [04:08<3:48:38,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 900 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 911/31146 [04:10<3:39:51,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 910 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 921/31146 [04:13<3:50:25,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 920 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 931/31146 [04:16<3:27:30,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 930 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 941/31146 [04:19<3:53:51,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 940 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 951/31146 [04:21<3:28:03,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 950 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 961/31146 [04:24<3:23:09,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 960 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 971/31146 [04:27<3:47:29,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 970 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 981/31146 [04:30<3:23:55,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 980 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 991/31146 [04:33<3:45:28,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 990 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1001/31146 [04:35<3:18:43,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1011/31146 [04:38<3:40:49,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1010 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1021/31146 [04:41<3:28:36,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1020 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1031/31146 [04:44<3:24:05,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1030 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1042/31146 [04:46<3:06:24,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1040 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1051/31146 [04:49<3:36:25,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1050 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1061/31146 [04:52<3:49:43,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1060 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1070/31146 [04:54<3:49:47,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1070 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1081/31146 [04:57<3:11:56,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1080 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1091/31146 [05:00<3:08:26,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1090 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1101/31146 [05:03<3:41:44,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1100 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1111/31146 [05:06<3:43:43,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1110 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1121/31146 [05:08<3:24:04,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1120 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1131/31146 [05:11<3:41:46,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1130 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1141/31146 [05:14<3:35:00,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1140 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1151/31146 [05:16<3:27:34,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1150 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1161/31146 [05:19<3:22:19,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1160 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1171/31146 [05:22<3:43:07,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1170 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1181/31146 [05:25<3:13:04,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1180 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1190/31146 [05:27<4:46:07,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1190 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1201/31146 [05:30<3:39:01,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1200 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1211/31146 [05:33<2:59:04,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1210 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1221/31146 [05:36<3:41:03,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1220 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1231/31146 [05:38<3:37:51,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1230 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1241/31146 [05:41<3:13:08,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1240 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1251/31146 [05:44<3:54:29,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1261/31146 [05:47<3:32:06,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1260 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1271/31146 [05:49<3:40:07,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1270 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1281/31146 [05:52<3:45:37,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1280 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1291/31146 [05:55<3:41:05,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1290 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1301/31146 [05:58<3:43:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1300 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1311/31146 [06:01<3:10:32,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1310 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1321/31146 [06:03<3:24:00,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1320 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1331/31146 [06:06<3:47:57,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1330 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1341/31146 [06:09<3:45:29,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1340 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1350/31146 [06:12<5:08:45,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1350 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1361/31146 [06:14<3:35:30,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1360 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1370/31146 [06:17<4:43:20,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1370 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1381/31146 [06:20<3:28:33,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1380 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1391/31146 [06:23<3:37:52,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1390 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1401/31146 [06:25<3:00:27,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1400 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1411/31146 [06:28<3:42:35,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1410 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1421/31146 [06:31<3:25:22,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1420 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1431/31146 [06:34<3:37:01,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1430 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1441/31146 [06:36<3:21:28,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1440 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1451/31146 [06:39<3:47:02,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1450 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1461/31146 [06:42<3:27:29,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1460 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1471/31146 [06:45<3:39:55,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1470 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1481/31146 [06:47<3:37:49,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1480 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1491/31146 [06:50<3:06:46,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1490 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1501/31146 [06:53<3:09:08,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1500 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1511/31146 [06:56<3:40:53,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1510 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1521/31146 [06:58<3:36:40,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1520 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1531/31146 [07:01<3:37:34,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1530 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1541/31146 [07:04<3:45:05,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1540 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1551/31146 [07:06<3:28:35,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1550 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1561/31146 [07:09<3:46:50,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1560 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1570/31146 [07:12<4:43:41,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1570 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1581/31146 [07:15<3:22:25,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1580 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1591/31146 [07:18<3:47:02,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1590 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1601/31146 [07:20<3:21:11,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1600 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1611/31146 [07:23<3:39:50,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1610 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1621/31146 [07:26<3:43:01,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1620 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1631/31146 [07:29<3:41:38,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1630 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1641/31146 [07:31<3:40:28,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1640 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1651/31146 [07:34<3:35:40,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1650 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1662/31146 [07:37<2:59:26,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1660 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1671/31146 [07:40<3:33:33,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1670 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1681/31146 [07:42<3:33:46,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1680 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1691/31146 [07:45<3:40:53,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1690 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1700/31146 [07:48<4:54:01,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1700 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1711/31146 [07:51<3:31:21,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1710 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1721/31146 [07:53<3:41:47,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1720 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1731/31146 [07:56<3:43:24,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1730 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1741/31146 [07:59<3:12:03,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1740 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1751/31146 [08:02<3:06:14,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1750 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1761/31146 [08:04<3:09:06,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1760 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1771/31146 [08:07<3:32:45,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1770 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1781/31146 [08:10<3:43:56,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1780 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1791/31146 [08:13<3:44:51,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1790 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1801/31146 [08:15<3:39:38,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1800 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1811/31146 [08:18<3:05:50,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1810 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1821/31146 [08:21<3:27:25,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1820 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1831/31146 [08:24<3:10:00,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1830 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1841/31146 [08:26<3:33:16,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1840 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1851/31146 [08:29<3:33:44,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1850 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1861/31146 [08:32<3:35:07,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1860 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1871/31146 [08:34<3:32:44,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1870 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1881/31146 [08:37<3:37:11,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1880 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1891/31146 [08:40<3:07:20,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1890 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1901/31146 [08:43<3:36:42,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1900 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1911/31146 [08:45<3:19:32,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1910 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1921/31146 [08:48<3:41:41,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1920 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1931/31146 [08:51<3:25:56,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1930 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1940/31146 [08:54<4:48:12,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1940 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1951/31146 [08:56<3:13:37,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1950 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1961/31146 [08:59<3:10:47,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1960 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1971/31146 [09:02<3:22:29,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1970 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1981/31146 [09:04<3:19:24,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1980 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1991/31146 [09:07<3:39:02,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1990 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 2001/31146 [09:10<3:36:34,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2000 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 2011/31146 [09:13<3:19:45,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2010 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 2022/31146 [09:16<2:58:40,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2020 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2031/31146 [09:18<3:31:36,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2030 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2041/31146 [09:21<3:34:50,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2040 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2051/31146 [09:24<3:07:21,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2050 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2061/31146 [09:26<3:33:05,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2060 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2072/31146 [09:29<2:43:52,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2070 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2081/31146 [09:32<3:28:39,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2080 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2091/31146 [09:34<3:40:11,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2090 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2101/31146 [09:37<3:20:06,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2100 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2111/31146 [09:40<3:36:29,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2110 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2120/31146 [09:43<4:44:43,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2120 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2131/31146 [09:46<3:35:38,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2130 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2141/31146 [09:48<3:29:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2140 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2151/31146 [09:51<3:45:56,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2150 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2161/31146 [09:54<3:34:07,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2160 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2171/31146 [09:56<3:10:24,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2170 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2181/31146 [09:59<3:31:55,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2180 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2191/31146 [10:02<3:36:43,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2190 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2201/31146 [10:05<3:34:01,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2200 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2211/31146 [10:07<3:39:19,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2210 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2221/31146 [10:10<3:31:50,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2220 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2231/31146 [10:13<3:33:04,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2230 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2241/31146 [10:16<3:34:54,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2240 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2251/31146 [10:18<3:37:34,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2261/31146 [10:21<3:32:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2260 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2271/31146 [10:24<3:04:15,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2270 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2281/31146 [10:27<3:45:21,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2280 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2291/31146 [10:30<3:31:51,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2290 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2301/31146 [10:32<3:33:10,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2300 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2311/31146 [10:35<3:12:21,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2310 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2321/31146 [10:38<3:27:54,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2320 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2331/31146 [10:40<2:45:39,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2330 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2341/31146 [10:43<3:38:33,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2340 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2351/31146 [10:46<3:29:42,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2350 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2361/31146 [10:49<3:30:52,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2360 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2371/31146 [10:51<3:26:57,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2370 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2381/31146 [10:54<2:56:07,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2380 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2390/31146 [10:57<4:48:53,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2390 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2401/31146 [10:59<3:22:08,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2400 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2411/31146 [11:02<3:34:09,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2410 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2421/31146 [11:05<3:06:35,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2420 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2431/31146 [11:08<3:08:27,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2430 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2441/31146 [11:11<3:40:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2440 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2451/31146 [11:13<3:00:53,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2450 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2461/31146 [11:16<3:06:27,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2460 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2471/31146 [11:19<3:35:20,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2470 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2481/31146 [11:21<3:19:20,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2480 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2491/31146 [11:24<3:13:21,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2490 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2501/31146 [11:27<3:31:54,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2500 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2511/31146 [11:30<3:26:12,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2510 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2520/31146 [11:32<4:45:17,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2520 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2531/31146 [11:35<3:10:18,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2530 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2541/31146 [11:38<3:27:43,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2540 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2551/31146 [11:41<3:34:04,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2550 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2561/31146 [11:43<3:26:03,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2560 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2571/31146 [11:46<3:17:42,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2570 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2581/31146 [11:49<3:21:14,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2580 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2591/31146 [11:51<3:26:51,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2590 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2601/31146 [11:54<3:33:59,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2600 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2611/31146 [11:57<3:32:41,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2610 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2621/31146 [12:00<3:11:57,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2620 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2631/31146 [12:02<3:27:54,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2630 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2641/31146 [12:05<3:05:56,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2640 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 2650/31146 [12:08<4:40:16,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2650 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 2661/31146 [12:11<3:35:19,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2660 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 2671/31146 [12:14<3:33:38,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2670 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 2681/31146 [12:16<3:12:39,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2680 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 2691/31146 [12:19<3:37:17,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2690 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 2702/31146 [12:22<2:43:38,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2700 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 2711/31146 [12:24<2:51:28,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2710 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 2721/31146 [12:27<3:29:43,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2720 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2731/31146 [12:30<3:25:16,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2730 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2741/31146 [12:32<2:41:27,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2740 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2752/31146 [12:35<2:39:43,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2750 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2761/31146 [12:38<3:27:58,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2760 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2771/31146 [12:41<3:27:22,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2770 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2781/31146 [12:43<3:33:26,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2780 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2791/31146 [12:46<3:27:03,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2790 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2801/31146 [12:49<3:35:48,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2800 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2811/31146 [12:52<3:26:48,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2810 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2820/31146 [12:54<4:36:35,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2820 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2831/31146 [12:57<3:29:38,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2830 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2841/31146 [13:00<3:27:02,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2840 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2851/31146 [13:03<3:05:01,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2850 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2861/31146 [13:05<3:30:26,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2860 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2871/31146 [13:08<3:04:41,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2870 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2881/31146 [13:11<2:53:03,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2880 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2891/31146 [13:14<3:31:03,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2890 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2901/31146 [13:16<3:15:01,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2900 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2911/31146 [13:19<3:38:40,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2910 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2921/31146 [13:22<3:20:10,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2920 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2931/31146 [13:25<3:31:51,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2930 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2941/31146 [13:27<3:17:40,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2940 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2951/31146 [13:30<3:23:18,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2950 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 2961/31146 [13:33<2:57:56,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2960 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 2971/31146 [13:35<3:25:24,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2970 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 2981/31146 [13:38<3:08:42,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2980 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 2991/31146 [13:41<3:39:34,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2990 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 3000/31146 [13:44<4:50:11,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3000 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 3011/31146 [13:47<3:19:20,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3010 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 3021/31146 [13:50<3:34:39,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3020 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 3031/31146 [13:52<3:03:18,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3030 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 3041/31146 [13:55<3:07:22,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3040 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 3051/31146 [13:58<3:31:19,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3050 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 3061/31146 [14:01<3:06:45,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3060 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 3071/31146 [14:03<3:35:50,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3070 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 3081/31146 [14:06<3:28:59,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3080 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 3091/31146 [14:09<3:40:21,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3090 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 3101/31146 [14:12<3:31:36,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3100 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 3111/31146 [14:15<3:33:18,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3110 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3121/31146 [14:18<3:10:29,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3120 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3131/31146 [14:20<3:32:53,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3130 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3141/31146 [14:23<3:23:29,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3140 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3151/31146 [14:26<3:25:19,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3150 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3161/31146 [14:29<3:27:45,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3160 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3171/31146 [14:31<2:58:05,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3170 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3181/31146 [14:34<3:03:06,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3180 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3191/31146 [14:37<3:07:34,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3190 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3201/31146 [14:40<3:26:14,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3200 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3211/31146 [14:42<2:59:51,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3210 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3221/31146 [14:45<3:20:02,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3220 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3231/31146 [14:48<3:00:02,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3230 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3241/31146 [14:51<3:26:31,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3240 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3251/31146 [14:53<3:02:13,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3261/31146 [14:56<3:32:51,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3260 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3271/31146 [14:59<3:30:49,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3270 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3281/31146 [15:02<3:23:46,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3280 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3291/31146 [15:04<2:48:54,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3290 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3301/31146 [15:07<3:12:49,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3300 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3311/31146 [15:10<3:03:11,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3310 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3321/31146 [15:12<3:24:30,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3320 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3331/31146 [15:15<3:22:46,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3330 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3341/31146 [15:18<3:01:05,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3340 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3351/31146 [15:21<3:30:36,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3350 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3361/31146 [15:24<3:27:59,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3360 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3371/31146 [15:26<3:01:55,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3370 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3381/31146 [15:29<3:06:19,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3380 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3391/31146 [15:32<3:24:45,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3390 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3401/31146 [15:35<3:08:48,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3400 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3411/31146 [15:38<3:38:42,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3410 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3420/31146 [15:40<4:40:04,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3420 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3431/31146 [15:43<3:10:28,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3430 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3441/31146 [15:46<2:55:11,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3440 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3451/31146 [15:48<3:02:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3450 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3461/31146 [15:51<3:31:44,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3460 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3471/31146 [15:54<3:30:48,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3470 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3481/31146 [15:57<3:29:40,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3480 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3491/31146 [16:00<3:25:46,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3490 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3501/31146 [16:02<3:06:32,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3500 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 3511/31146 [16:05<2:53:59,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3510 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 3521/31146 [16:08<3:23:03,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3520 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 3532/31146 [16:11<2:50:03,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3530 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 3541/31146 [16:14<3:11:05,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3540 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 3551/31146 [16:16<3:36:22,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3550 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 3561/31146 [16:19<3:18:24,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3560 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 3571/31146 [16:22<3:28:09,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3570 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 3581/31146 [16:25<2:58:58,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3580 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3591/31146 [16:27<3:21:50,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3590 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3601/31146 [16:30<2:55:43,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3600 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3611/31146 [16:33<3:23:45,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3610 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3621/31146 [16:36<3:09:21,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3620 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3631/31146 [16:38<3:08:59,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3630 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3641/31146 [16:41<3:16:16,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3640 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3651/31146 [16:44<3:18:16,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3650 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3661/31146 [16:46<3:31:15,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3660 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3671/31146 [16:49<2:44:07,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3670 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3681/31146 [16:52<3:06:03,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3680 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3691/31146 [16:55<3:23:30,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3690 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3701/31146 [16:58<3:02:15,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3700 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3711/31146 [17:00<3:08:07,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3710 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3721/31146 [17:03<3:07:55,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3720 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3731/31146 [17:06<3:20:45,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3730 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3741/31146 [17:09<3:10:32,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3740 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3751/31146 [17:11<3:24:18,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3750 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3761/31146 [17:14<3:15:55,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3760 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3771/31146 [17:17<3:04:11,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3770 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3781/31146 [17:20<3:18:34,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3780 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3791/31146 [17:22<3:19:47,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3790 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3801/31146 [17:25<2:45:20,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3800 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3811/31146 [17:28<2:54:09,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3810 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3821/31146 [17:31<3:19:09,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3820 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3831/31146 [17:33<3:17:26,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3830 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3841/31146 [17:36<3:27:29,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3840 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3851/31146 [17:39<3:16:32,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3850 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3861/31146 [17:41<2:57:15,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3860 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3871/31146 [17:44<3:24:22,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3870 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3881/31146 [17:47<3:24:02,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3880 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3891/31146 [17:50<3:00:44,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3890 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 3901/31146 [17:53<2:52:08,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3900 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 3911/31146 [17:55<3:26:39,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3910 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 3921/31146 [17:58<3:27:15,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3920 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 3931/31146 [18:01<3:27:09,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3930 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 3941/31146 [18:04<3:16:34,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3940 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 3951/31146 [18:07<3:18:03,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3950 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 3961/31146 [18:09<3:07:07,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3960 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 3971/31146 [18:12<3:16:38,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3970 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 3981/31146 [18:15<3:21:05,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3980 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 3991/31146 [18:18<3:21:23,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3990 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4001/31146 [18:20<3:17:39,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4000 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4011/31146 [18:23<3:11:52,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4010 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4021/31146 [18:26<3:28:35,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4020 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4031/31146 [18:29<3:01:07,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4030 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4041/31146 [18:32<3:23:54,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4040 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4051/31146 [18:34<2:58:20,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4050 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4061/31146 [18:37<3:19:17,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4060 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4071/31146 [18:40<3:07:38,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4070 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4081/31146 [18:43<3:17:45,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4080 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4091/31146 [18:45<3:24:59,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4090 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4101/31146 [18:48<3:08:43,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4100 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4111/31146 [18:51<3:21:22,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4110 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4121/31146 [18:54<3:23:55,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4120 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4131/31146 [18:56<2:49:56,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4130 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4141/31146 [18:59<3:14:51,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4140 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4151/31146 [19:02<3:12:28,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4150 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4161/31146 [19:04<3:17:37,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4160 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4171/31146 [19:07<3:15:02,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4170 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4181/31146 [19:10<3:02:56,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4180 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4191/31146 [19:13<3:16:58,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4190 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4201/31146 [19:15<3:15:56,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4200 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 4211/31146 [19:18<2:56:01,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4210 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 4221/31146 [19:21<3:19:49,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4220 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 4231/31146 [19:24<3:10:13,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4230 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 4240/31146 [19:26<4:19:17,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4240 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 4251/31146 [19:29<2:49:44,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 4261/31146 [19:32<3:15:54,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4260 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 4271/31146 [19:34<2:52:51,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4270 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 4281/31146 [19:37<3:18:40,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4280 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4291/31146 [19:40<3:15:10,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4290 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4301/31146 [19:43<3:21:29,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4300 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4311/31146 [19:45<2:39:41,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4310 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4321/31146 [19:48<3:20:09,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4320 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4331/31146 [19:51<3:16:23,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4330 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4341/31146 [19:54<3:25:02,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4340 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4351/31146 [19:56<3:26:45,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4350 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4361/31146 [19:59<3:20:03,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4360 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4371/31146 [20:02<2:53:13,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4370 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4381/31146 [20:05<2:53:41,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4380 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4391/31146 [20:07<3:13:19,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4390 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4401/31146 [20:10<2:46:03,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4400 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4411/31146 [20:13<3:16:34,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4410 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4421/31146 [20:16<3:21:07,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4420 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4431/31146 [20:18<3:20:10,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4430 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4441/31146 [20:21<2:48:23,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4440 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4451/31146 [20:24<3:28:21,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4450 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4461/31146 [20:27<3:05:19,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4460 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4471/31146 [20:29<3:18:36,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4470 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4481/31146 [20:32<3:16:42,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4480 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4491/31146 [20:35<3:15:16,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4490 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4500/31146 [20:38<4:19:08,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4500 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4511/31146 [20:40<3:21:26,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4510 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 4521/31146 [20:43<3:21:51,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4520 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 4531/31146 [20:46<3:00:52,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4530 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 4541/31146 [20:49<3:19:21,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4540 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 4551/31146 [20:52<2:41:34,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4550 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 4561/31146 [20:54<3:21:38,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4560 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 4571/31146 [20:57<3:22:28,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4570 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 4581/31146 [21:00<2:42:19,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4580 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 4591/31146 [21:03<3:11:34,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4590 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 4601/31146 [21:05<2:46:09,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4600 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 4611/31146 [21:08<3:16:24,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4610 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 4621/31146 [21:11<3:09:21,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4620 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 4632/31146 [21:14<2:42:11,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4630 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 4641/31146 [21:16<2:46:43,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4640 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 4651/31146 [21:19<2:49:03,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4650 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 4660/31146 [21:22<4:12:06,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4660 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 4671/31146 [21:24<2:56:53,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4670 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4681/31146 [21:27<3:16:43,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4680 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4691/31146 [21:30<3:24:02,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4690 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4701/31146 [21:33<3:14:30,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4700 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4711/31146 [21:36<3:00:16,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4710 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4721/31146 [21:38<3:05:51,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4720 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4730/31146 [21:41<4:27:32,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4730 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4741/31146 [21:44<3:09:14,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4740 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4751/31146 [21:47<3:16:43,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4750 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4761/31146 [21:49<2:59:40,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4760 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4772/31146 [21:52<2:43:01,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4770 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4781/31146 [21:55<3:00:27,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4780 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4790/31146 [21:57<4:09:27,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4790 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4800/31146 [22:00<4:13:45,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4800 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4811/31146 [22:03<3:17:31,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4810 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4821/31146 [22:06<3:13:49,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4820 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4830/31146 [22:08<4:14:09,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4830 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4841/31146 [22:11<2:49:12,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4840 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4851/31146 [22:14<3:13:30,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4850 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4861/31146 [22:17<3:13:49,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4860 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4871/31146 [22:19<3:08:44,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4870 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4881/31146 [22:22<3:11:37,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4880 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4891/31146 [22:25<3:18:15,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4890 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4901/31146 [22:28<3:16:16,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4900 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4911/31146 [22:31<3:14:33,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4910 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4921/31146 [22:33<3:10:14,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4920 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4931/31146 [22:36<3:11:38,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4930 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4941/31146 [22:39<2:34:33,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4940 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4951/31146 [22:41<2:47:05,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4950 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4961/31146 [22:44<3:13:13,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4960 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4971/31146 [22:47<3:14:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4970 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4982/31146 [22:50<2:35:39,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4980 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4991/31146 [22:52<2:36:13,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4990 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 5001/31146 [22:55<2:55:21,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5000 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 5011/31146 [22:58<3:00:50,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5010 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 5021/31146 [23:00<2:49:19,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5020 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 5031/31146 [23:03<3:13:54,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5030 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 5041/31146 [23:06<2:37:46,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5040 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 5051/31146 [23:09<3:04:18,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5050 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 5061/31146 [23:11<3:13:56,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5060 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 5071/31146 [23:14<2:56:47,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5070 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 5081/31146 [23:17<2:42:16,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5080 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 5091/31146 [23:20<3:14:21,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5090 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 5101/31146 [23:22<2:39:11,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5100 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 5111/31146 [23:25<2:52:43,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5110 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 5121/31146 [23:28<2:51:49,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5120 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 5131/31146 [23:31<3:10:05,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5130 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5141/31146 [23:33<3:13:34,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5140 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5151/31146 [23:36<2:46:01,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5150 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5161/31146 [23:39<3:11:07,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5160 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5171/31146 [23:41<2:53:35,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5170 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5181/31146 [23:44<3:14:08,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5180 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5191/31146 [23:47<3:14:22,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5190 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5201/31146 [23:50<3:08:44,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5200 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5211/31146 [23:54<3:07:23,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5210 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5221/31146 [23:56<2:55:30,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5220 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5231/31146 [23:59<3:10:27,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5230 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5241/31146 [24:02<3:11:02,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5240 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5251/31146 [24:05<2:58:44,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5261/31146 [24:07<3:12:33,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5260 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5272/31146 [24:10<2:23:44,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5270 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5281/31146 [24:13<2:49:53,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5280 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5291/31146 [24:16<3:09:13,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5290 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5300/31146 [24:18<4:04:37,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5300 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5311/31146 [24:21<2:45:56,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5310 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5321/31146 [24:24<2:57:39,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5320 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5331/31146 [24:27<3:18:32,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5330 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5341/31146 [24:29<3:06:30,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5340 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5351/31146 [24:32<2:44:56,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5350 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5361/31146 [24:35<3:10:06,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5360 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5371/31146 [24:37<2:47:17,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5370 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5381/31146 [24:40<3:13:13,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5380 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5391/31146 [24:43<3:01:29,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5390 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5401/31146 [24:46<3:15:35,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5400 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5411/31146 [24:49<3:04:43,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5410 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5422/31146 [24:51<2:33:12,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5420 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5431/31146 [24:54<2:45:25,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5430 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5441/31146 [24:57<3:04:11,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5440 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5451/31146 [24:59<3:02:27,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5450 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5461/31146 [25:02<2:44:26,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5460 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5471/31146 [25:05<3:11:03,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5470 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5481/31146 [25:07<3:05:45,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5480 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5491/31146 [25:10<3:09:27,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5490 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5501/31146 [25:13<3:23:07,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5500 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5511/31146 [25:16<2:45:56,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5510 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5521/31146 [25:19<3:15:23,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5520 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5531/31146 [25:22<2:51:59,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5530 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5541/31146 [25:24<3:02:58,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5540 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5551/31146 [25:27<2:50:13,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5550 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5561/31146 [25:30<2:44:13,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5560 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5571/31146 [25:32<2:50:48,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5570 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5581/31146 [25:35<3:11:28,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5580 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5591/31146 [25:38<2:48:47,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5590 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5601/31146 [25:41<2:51:22,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5600 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5611/31146 [25:44<2:45:12,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5610 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5621/31146 [25:46<3:07:39,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5620 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5632/31146 [25:49<2:35:58,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5630 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5641/31146 [25:52<2:31:10,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5640 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5651/31146 [25:54<3:06:20,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5650 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5661/31146 [25:57<3:06:01,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5660 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5671/31146 [26:00<3:11:14,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5670 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5681/31146 [26:02<3:04:53,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5680 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5690/31146 [26:05<4:07:23,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5690 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5701/31146 [26:08<3:04:48,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5700 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5711/31146 [26:11<3:09:10,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5710 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5721/31146 [26:13<2:58:31,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5720 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5732/31146 [26:16<2:27:16,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5730 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5741/31146 [26:19<2:32:48,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5740 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5751/31146 [26:22<2:41:28,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5750 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5761/31146 [26:24<3:03:52,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5760 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 5771/31146 [26:27<3:05:38,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5770 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 5781/31146 [26:30<3:01:36,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5780 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 5791/31146 [26:33<3:09:15,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5790 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 5801/31146 [26:35<3:13:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5800 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 5811/31146 [26:38<2:44:30,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5810 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 5821/31146 [26:41<3:07:14,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5820 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 5831/31146 [26:44<3:02:23,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5830 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5841/31146 [26:46<2:52:11,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5840 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5851/31146 [26:49<3:10:43,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5850 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5861/31146 [26:52<2:52:32,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5860 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5871/31146 [26:55<2:41:10,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5870 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5881/31146 [26:57<3:12:21,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5880 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5891/31146 [27:00<3:15:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5890 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5901/31146 [27:03<2:40:01,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5900 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5911/31146 [27:06<2:59:36,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5910 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5921/31146 [27:09<2:51:51,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5920 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5931/31146 [27:11<2:42:19,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5930 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5941/31146 [27:14<2:55:33,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5940 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5951/31146 [27:17<3:13:03,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5950 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5961/31146 [27:20<2:54:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5960 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5971/31146 [27:22<3:04:47,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5970 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5982/31146 [27:25<2:17:43,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5980 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5991/31146 [27:28<2:40:48,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5990 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 6001/31146 [27:30<3:01:34,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6000 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 6011/31146 [27:33<2:49:36,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6010 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 6021/31146 [27:36<2:52:49,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6020 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 6031/31146 [27:39<3:09:14,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6030 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 6041/31146 [27:41<3:11:34,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6040 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 6051/31146 [27:44<3:02:43,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6050 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 6061/31146 [27:47<2:56:33,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6060 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 6071/31146 [27:49<2:48:45,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6070 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 6082/31146 [27:52<2:24:42,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6080 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 6091/31146 [27:55<2:42:01,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6090 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 6101/31146 [27:58<2:41:28,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6100 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 6112/31146 [28:01<2:34:27,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6110 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 6121/31146 [28:03<3:05:01,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6120 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 6131/31146 [28:06<3:06:31,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6130 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 6141/31146 [28:09<3:01:14,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6140 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 6151/31146 [28:11<3:04:33,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6150 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 6161/31146 [28:14<2:53:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6160 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 6171/31146 [28:17<2:41:01,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6170 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 6181/31146 [28:20<3:08:41,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6180 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 6191/31146 [28:22<3:01:19,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6190 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 6201/31146 [28:25<2:55:11,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6200 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 6211/31146 [28:28<3:03:44,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6210 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 6222/31146 [28:31<2:20:50,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6220 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6231/31146 [28:33<2:50:22,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6230 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6241/31146 [28:36<3:07:17,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6240 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6251/31146 [28:39<3:02:46,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6261/31146 [28:42<2:39:47,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6260 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6271/31146 [28:45<3:15:20,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6270 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6281/31146 [28:47<2:37:52,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6280 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6291/31146 [28:50<2:39:05,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6290 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6301/31146 [28:53<2:59:28,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6300 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6311/31146 [28:55<2:56:41,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6310 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6321/31146 [28:58<3:05:24,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6320 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6331/31146 [29:01<2:59:29,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6330 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6341/31146 [29:04<3:00:08,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6340 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6351/31146 [29:06<2:59:43,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6350 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6361/31146 [29:09<3:00:12,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6360 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6371/31146 [29:12<2:41:20,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6370 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6380/31146 [29:15<4:06:02,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6380 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6391/31146 [29:17<2:39:08,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6390 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6401/31146 [29:20<3:06:44,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6400 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6411/31146 [29:23<3:01:23,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6410 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6421/31146 [29:26<3:11:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6420 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6431/31146 [29:28<2:49:54,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6430 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6441/31146 [29:31<3:11:30,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6440 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6451/31146 [29:34<3:00:45,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6450 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6461/31146 [29:37<2:56:08,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6460 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6471/31146 [29:40<3:07:12,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6470 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6481/31146 [29:42<2:51:51,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6480 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6492/31146 [29:45<2:29:35,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6490 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6501/31146 [29:48<3:02:27,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6500 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6511/31146 [29:51<3:03:06,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6510 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6521/31146 [29:53<3:07:31,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6520 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6532/31146 [29:56<2:30:27,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6530 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6541/31146 [29:59<2:51:13,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6540 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6551/31146 [30:02<2:59:44,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6550 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6561/31146 [30:04<2:49:18,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6560 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6571/31146 [30:07<2:56:44,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6570 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6581/31146 [30:09<2:56:22,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6580 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6591/31146 [30:12<2:54:49,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6590 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6601/31146 [30:15<3:02:47,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6600 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6610/31146 [30:18<4:08:53,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6610 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 6621/31146 [30:20<2:57:58,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6620 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 6631/31146 [30:23<2:57:40,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6630 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 6641/31146 [30:26<2:40:38,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6640 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 6651/31146 [30:29<2:39:53,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6650 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 6661/31146 [30:32<3:07:32,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6660 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 6671/31146 [30:34<2:51:27,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6670 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 6681/31146 [30:37<2:37:42,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6680 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 6691/31146 [30:40<2:33:50,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6690 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6701/31146 [30:42<2:39:40,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6700 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6711/31146 [30:45<2:34:56,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6710 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6721/31146 [30:48<3:04:39,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6720 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6731/31146 [30:51<2:51:52,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6730 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6741/31146 [30:53<2:59:29,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6740 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6751/31146 [30:56<2:59:22,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6750 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6761/31146 [30:59<2:45:57,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6760 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6771/31146 [31:02<2:35:47,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6770 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6781/31146 [31:04<2:58:19,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6780 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6791/31146 [31:07<2:57:56,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6790 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6801/31146 [31:10<2:41:23,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6800 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6811/31146 [31:13<3:04:16,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6810 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6821/31146 [31:16<3:01:28,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6820 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6831/31146 [31:18<2:54:56,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6830 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6841/31146 [31:21<2:41:07,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6840 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6851/31146 [31:24<2:42:30,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6850 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6861/31146 [31:26<3:00:47,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6860 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6871/31146 [31:29<3:01:49,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6870 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6881/31146 [31:32<2:36:37,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6880 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6891/31146 [31:35<3:00:29,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6890 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6901/31146 [31:38<3:02:02,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6900 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6911/31146 [31:40<2:41:38,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6910 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6921/31146 [31:43<2:45:56,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6920 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6931/31146 [31:46<2:52:29,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6930 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6941/31146 [31:48<2:48:22,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6940 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6951/31146 [31:51<2:59:17,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6950 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6961/31146 [31:54<2:38:43,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6960 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6971/31146 [31:57<2:54:06,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6970 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6981/31146 [31:59<2:59:06,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6980 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6990/31146 [32:02<3:53:30,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6990 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 7001/31146 [32:05<2:50:14,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7000 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7011/31146 [32:07<2:55:39,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7010 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7021/31146 [32:10<2:30:01,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7020 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7031/31146 [32:13<2:40:04,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7030 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7040/31146 [32:15<3:52:26,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7040 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7051/31146 [32:18<2:44:24,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7050 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7061/31146 [32:21<3:05:51,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7060 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7071/31146 [32:24<2:57:05,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7070 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7081/31146 [32:26<2:31:40,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7080 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7091/31146 [32:29<2:50:15,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7090 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7101/31146 [32:32<2:55:08,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7100 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7111/31146 [32:34<2:47:13,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7110 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7121/31146 [32:37<2:31:06,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7120 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7131/31146 [32:40<2:55:54,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7130 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7141/31146 [32:43<2:45:43,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7140 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7151/31146 [32:46<3:01:44,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7150 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7161/31146 [32:48<2:38:14,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7160 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7171/31146 [32:51<3:01:34,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7170 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7181/31146 [32:54<2:59:52,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7180 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7191/31146 [32:57<2:26:35,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7190 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7201/31146 [32:59<2:57:54,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7200 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7211/31146 [33:02<2:29:50,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7210 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7221/31146 [33:05<2:58:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7220 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7231/31146 [33:08<2:58:04,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7230 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7241/31146 [33:10<2:53:30,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7240 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7251/31146 [33:13<2:38:56,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7261/31146 [33:16<2:58:28,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7260 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7271/31146 [33:18<2:31:57,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7270 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7281/31146 [33:21<2:40:38,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7280 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7291/31146 [33:24<2:58:46,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7290 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7301/31146 [33:27<2:30:11,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7300 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7311/31146 [33:29<2:55:44,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7310 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 7321/31146 [33:32<2:52:14,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7320 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 7331/31146 [33:35<3:02:13,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7330 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 7341/31146 [33:37<2:34:19,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7340 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 7351/31146 [33:40<2:47:05,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7350 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 7362/31146 [33:43<2:16:08,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7360 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 7371/31146 [33:45<2:46:05,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7370 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 7381/31146 [33:48<2:56:12,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7380 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 7391/31146 [33:51<2:54:48,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7390 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7401/31146 [33:54<2:54:21,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7400 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7411/31146 [33:57<2:56:09,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7410 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7421/31146 [33:59<3:07:56,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7420 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7430/31146 [34:02<3:52:32,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7430 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7441/31146 [34:05<2:39:38,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7440 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7451/31146 [34:08<3:02:48,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7450 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7462/31146 [34:11<2:14:47,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7460 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7471/31146 [34:13<2:26:13,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7470 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7480/31146 [34:16<3:50:02,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7480 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7491/31146 [34:19<2:33:14,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7490 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7501/31146 [34:22<3:04:12,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7500 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7511/31146 [34:24<2:50:39,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7510 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7521/31146 [34:27<2:53:06,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7520 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7531/31146 [34:30<2:31:36,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7530 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7541/31146 [34:33<2:40:56,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7540 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7552/31146 [34:35<2:11:32,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7550 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7561/31146 [34:38<2:23:33,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7560 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7571/31146 [34:41<2:39:39,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7570 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7581/31146 [34:44<2:39:20,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7580 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7591/31146 [34:46<2:37:32,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7590 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7601/31146 [34:49<2:51:08,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7600 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7612/31146 [34:52<2:13:26,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7610 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7621/31146 [34:54<2:47:55,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7620 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 7631/31146 [34:57<2:48:20,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7630 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 7641/31146 [35:00<2:57:32,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7640 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 7651/31146 [35:03<2:45:16,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7650 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 7661/31146 [35:05<2:56:11,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7660 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 7671/31146 [35:08<3:00:32,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7670 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 7680/31146 [35:11<3:52:51,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7680 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 7691/31146 [35:14<2:30:39,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7690 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 7701/31146 [35:16<2:33:39,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7700 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 7711/31146 [35:19<2:53:26,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7710 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 7721/31146 [35:22<2:38:44,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7720 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 7731/31146 [35:25<2:56:34,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7730 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 7741/31146 [35:27<2:33:34,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7740 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 7751/31146 [35:30<2:54:02,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7750 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 7761/31146 [35:33<2:34:54,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7760 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 7771/31146 [35:36<2:50:51,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7770 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 7781/31146 [35:38<2:52:54,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7780 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7791/31146 [35:41<2:56:15,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7790 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7801/31146 [35:44<2:18:20,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7800 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7811/31146 [35:47<2:36:12,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7810 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7821/31146 [35:50<2:54:58,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7820 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7831/31146 [35:52<2:58:41,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7830 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7841/31146 [35:55<2:34:34,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7840 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7851/31146 [35:58<2:49:53,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7850 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7861/31146 [36:01<2:34:20,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7860 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7871/31146 [36:04<3:01:15,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7870 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7881/31146 [36:06<2:50:46,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7880 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7890/31146 [36:09<3:46:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7890 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7901/31146 [36:12<2:47:46,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7900 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7910/31146 [36:14<3:47:01,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7910 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7921/31146 [36:17<2:53:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7920 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7931/31146 [36:20<3:03:53,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7930 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7941/31146 [36:23<2:48:11,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7940 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 7951/31146 [36:26<2:31:08,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7950 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 7961/31146 [36:29<2:51:26,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7960 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 7970/31146 [36:31<3:45:22,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7970 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 7981/31146 [36:34<2:55:09,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7980 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 7991/31146 [36:37<3:10:03,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7990 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8001/31146 [36:40<2:34:10,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8000 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8011/31146 [36:43<3:04:39,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8010 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8021/31146 [36:46<3:01:38,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8020 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8031/31146 [36:48<2:27:12,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8030 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8041/31146 [36:51<2:55:37,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8040 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8051/31146 [36:54<2:28:05,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8050 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8061/31146 [36:57<2:25:38,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8060 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8071/31146 [36:59<2:40:20,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8070 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8081/31146 [37:02<2:45:53,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8080 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8091/31146 [37:05<2:23:24,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8090 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8101/31146 [37:07<2:47:28,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8100 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8111/31146 [37:10<2:34:35,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8110 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8121/31146 [37:13<2:47:44,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8120 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8131/31146 [37:16<2:53:24,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8130 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8141/31146 [37:18<2:29:46,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8140 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8151/31146 [37:21<2:48:26,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8150 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8161/31146 [37:24<2:28:30,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8160 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8171/31146 [37:27<2:25:23,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8170 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 8181/31146 [37:29<2:45:03,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8180 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 8191/31146 [37:32<2:28:48,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8190 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 8200/31146 [37:35<3:50:05,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8200 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 8211/31146 [37:38<2:28:32,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8210 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 8221/31146 [37:40<2:42:22,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8220 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 8231/31146 [37:43<2:52:54,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8230 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 8241/31146 [37:46<2:45:53,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8240 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 8251/31146 [37:48<2:38:22,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8261/31146 [37:51<2:43:56,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8260 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8271/31146 [37:54<2:46:34,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8270 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8281/31146 [37:57<2:47:43,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8280 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8291/31146 [37:59<2:58:07,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8290 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8301/31146 [38:02<2:40:57,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8300 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8311/31146 [38:05<2:51:50,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8310 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8321/31146 [38:08<2:28:46,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8320 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8331/31146 [38:11<2:34:13,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8330 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8341/31146 [38:14<2:59:08,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8340 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8351/31146 [38:16<2:37:04,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8350 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8361/31146 [38:19<2:39:37,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8360 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8371/31146 [38:22<2:56:25,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8370 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8381/31146 [38:25<2:26:17,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8380 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8388/31146 [38:25<52:11,  7.27it/s]  "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T15:35:24.035591Z",
     "start_time": "2025-04-06T15:35:24.019833Z"
    }
   },
   "source": [
    "def test(loader, test_model, is_validation=False, save_model_preds=False):\n",
    "    test_model.eval()\n",
    "\n",
    "    # Define K for Hit@K metrics.\n",
    "    k = 10\n",
    "    correct = 0\n",
    "    top_k_correct = 0\n",
    "\n",
    "    for _, data in enumerate(tqdm(loader)):\n",
    "        data.to('cuda')\n",
    "        with torch.no_grad():\n",
    "            # max(dim=1) returns values, indices tuple; only need indices\n",
    "            score = test_model(data)\n",
    "            pred = score.max(dim=1)[1]\n",
    "            label = data.y\n",
    "\n",
    "        if save_model_preds:\n",
    "          data = {}\n",
    "          data['pred'] = pred.view(-1).cpu().detach().numpy()\n",
    "          data['label'] = label.view(-1).cpu().detach().numpy()\n",
    "\n",
    "          df = pd.DataFrame(data=data)\n",
    "          # Save locally as csv\n",
    "          df.to_csv('pred.csv', sep=',', index=False)\n",
    "            \n",
    "        correct += pred.eq(label).sum().item()\n",
    "\n",
    "        # We calculate Hit@K accuracy only at test time.\n",
    "        if not is_validation:\n",
    "            score = score.cpu().detach().numpy()\n",
    "            for row in range(pred.size(0)):\n",
    "                top_k_pred = np.argpartition(score[row], -k)[-k:]\n",
    "                if label[row].item() in top_k_pred:\n",
    "                    top_k_correct += 1\n",
    "    \n",
    "    if not is_validation:\n",
    "        return correct / len(loader), top_k_correct / len(loader)\n",
    "    else:\n",
    "        return correct / len(loader), 0"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pdNUqKJl1r35",
    "outputId": "e2e8b168-4ad1-4830-cb65-c3b3ff3d3cba",
    "ExecuteTime": {
     "end_time": "2025-04-05T05:24:09.504552Z",
     "start_time": "2025-04-05T04:41:33.303625Z"
    }
   },
   "source": [
    "test_accs, top_k_accs, losses, best_model, best_acc, test_loader = train(args) \n",
    "\n",
    "print(test_accs, top_k_accs)\n",
    "print(\"Maximum test set accuracy: {0}\".format(max(test_accs)))\n",
    "print(\"Minimum loss: {0}\".format(min(losses)))\n",
    "\n",
    "# plt.title(dataset.name)\n",
    "plt.plot(losses, label=\"training loss\" + \" - \")\n",
    "plt.plot(test_accs, label=\"test accuracy\" + \" - \")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Desktop\\ML viva\\.venv\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "100%|██████████| 2919/2919 [04:08<00:00, 11.76it/s]\n",
      "100%|██████████| 387/387 [00:07<00:00, 52.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.12919896640827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2919/2919 [03:53<00:00, 12.53it/s]\n",
      "100%|██████████| 387/387 [00:05<00:00, 74.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.58656330749354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2919/2919 [04:08<00:00, 11.75it/s]\n",
      "100%|██████████| 387/387 [00:08<00:00, 47.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.11111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2919/2919 [04:13<00:00, 11.51it/s]\n",
      "100%|██████████| 387/387 [00:07<00:00, 53.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.10594315245478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2919/2919 [04:09<00:00, 11.70it/s]\n",
      "100%|██████████| 387/387 [00:07<00:00, 55.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.795865633074936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2919/2919 [04:08<00:00, 11.76it/s]\n",
      "100%|██████████| 387/387 [00:06<00:00, 56.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.064599483204134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2919/2919 [04:09<00:00, 11.71it/s]\n",
      "100%|██████████| 387/387 [00:06<00:00, 56.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.470284237726098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2919/2919 [04:09<00:00, 11.70it/s]\n",
      "100%|██████████| 387/387 [00:06<00:00, 58.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.684754521963825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2919/2919 [04:09<00:00, 11.68it/s]\n",
      "100%|██████████| 387/387 [00:07<00:00, 53.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.857881136950905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2919/2919 [04:10<00:00, 11.65it/s]\n",
      "100%|██████████| 387/387 [00:10<00:00, 36.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.09043927648579\n",
      "[14.12919896640827, 13.58656330749354, 15.11111111111111, 16.10594315245478, 16.795865633074936, 19.064599483204134, 19.470284237726098, 19.684754521963825, 19.857881136950905, 20.09043927648579] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Maximum test set accuracy: 20.09043927648579\n",
      "Minimum loss: 5.762361051059308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9rTB4_lI1Ocg",
    "ExecuteTime": {
     "end_time": "2025-04-05T06:29:08.659023Z",
     "start_time": "2025-04-05T06:29:08.423398Z"
    }
   },
   "source": [
    "# Save the best model\n",
    "torch.save(best_model.state_dict(), 'model')"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T09:02:35.266895Z",
     "start_time": "2025-04-05T08:03:40.592095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run test for our best model to save the predictions!\n",
    "train_dataset = GraphDataset('./', 'train')\n",
    "train_loader = pyg_data.DataLoader(train_dataset,\n",
    "                                  batch_size=args.batch_size,\n",
    "                                  shuffle=False,\n",
    "                                  drop_last=True)\n",
    "\n",
    "test(train_loader, best_model, is_validation=False, save_model_preds=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Desktop\\ML viva\\.venv\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "100%|██████████| 2919/2919 [58:54<00:00,  1.21s/it] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32.29496402877698, 70.33059266872216)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MoK2gVD7HVep",
    "outputId": "0ba517f1-5d52-4ef2-ce23-201fe28454f3",
    "ExecuteTime": {
     "end_time": "2025-04-05T11:05:39.471029Z",
     "start_time": "2025-04-05T11:04:15.033518Z"
    }
   },
   "source": [
    "# Run test for our best model to save the predictions!\n",
    "test_dataset = GraphDataset('./', 'test')\n",
    "test_loader = pyg_data.DataLoader(test_dataset,\n",
    "                                  batch_size=args.batch_size,\n",
    "                                  shuffle=False,\n",
    "                                  drop_last=True)\n",
    "\n",
    "test(test_loader, best_model, is_validation=False, save_model_preds=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Desktop\\ML viva\\.venv\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "100%|██████████| 70/70 [01:24<00:00,  1.21s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(31.7, 70.14285714285714)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T06:40:06.139299Z",
     "start_time": "2025-04-06T06:40:05.847798Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Instantiate the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "best_model = model = SRGNN(args.hidden_dim, args.num_items).to(device)\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "best_model.load_state_dict(torch.load('model_full', map_location=device))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "best_model.eval()\n",
    "\n",
    "#best_model.to('cuda')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SRGNN(\n",
       "  (embedding): Embedding(466868, 64)\n",
       "  (gated): GatedSessionGraphConv()\n",
       "  (q): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (W_1): Linear(in_features=64, out_features=64, bias=False)\n",
       "  (W_2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (W_3): Linear(in_features=128, out_features=64, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T16:01:55.013830Z",
     "start_time": "2025-04-02T16:01:48.462596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the preprocessed data\n",
    "with open('raw/train.txt', 'rb') as f:\n",
    "    train_sessions = pickle.load(f)\n",
    "with open('raw/val.txt', 'rb') as f:\n",
    "    val_sessions = pickle.load(f)\n",
    "with open('raw/test.txt', 'rb') as f:\n",
    "    test_sessions = pickle.load(f)\n",
    "\n",
    "# Combine all sessions\n",
    "all_sessions = train_sessions + val_sessions + test_sessions\n",
    "\n",
    "def generate_recommendations(visitor_id, sessions, model, top_k=10):\n",
    "    # Filter sessions for the given visitor ID\n",
    "    user_sessions = [session for session in sessions if session[0] == visitor_id]\n",
    "    if not user_sessions:\n",
    "        return \"No sessions found for the given visitor ID.\"\n",
    "\n",
    "    # Generate recommendations using the model\n",
    "    recommendations = []\n",
    "    for session in user_sessions:\n",
    "        if len(session) < 2:\n",
    "            continue  # Ensure session has enough elements\n",
    "        session_data = np.array(session[1:])  # Convert to NumPy array for factorization\n",
    "\n",
    "        # Build Data instance\n",
    "        codes, uniques = pd.factorize(session_data)\n",
    "        senders, receivers = codes[:-1], codes[1:]\n",
    "        if len(senders) == 0 or len(receivers) == 0:\n",
    "            continue  # Skip if there are no edges\n",
    "\n",
    "        edge_index = torch.tensor(np.array([senders, receivers]), dtype=torch.long).to(device)\n",
    "        x = torch.tensor(codes, dtype=torch.long).unsqueeze(1).to(device)\n",
    "        batch = torch.zeros(len(codes), dtype=torch.long).to(device)\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, batch=batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "            if output.numel() < top_k:\n",
    "                top_k = output.numel()  # Adjust top_k if not enough predictions\n",
    "            top_items = torch.topk(output.squeeze(), top_k).indices.tolist()\n",
    "            recommendations.extend(top_items)\n",
    "\n",
    "    # Flatten and get unique recommendations\n",
    "    unique_recommendations = list(set(recommendations))\n",
    "    return unique_recommendations[:top_k]\n",
    "\n",
    "# Example usage\n",
    "visitor_id = 1234\n",
    "recommendations = generate_recommendations(visitor_id, all_sessions, best_model, top_k=5)\n",
    "print(\"Top 10 Recommended Items:\", recommendations)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 58\u001B[0m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;66;03m# Example usage\u001B[39;00m\n\u001B[0;32m     57\u001B[0m visitor_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1234\u001B[39m\n\u001B[1;32m---> 58\u001B[0m recommendations \u001B[38;5;241m=\u001B[39m generate_recommendations(visitor_id, all_sessions, \u001B[43mbest_model\u001B[49m, top_k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTop 10 Recommended Items:\u001B[39m\u001B[38;5;124m\"\u001B[39m, recommendations)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
