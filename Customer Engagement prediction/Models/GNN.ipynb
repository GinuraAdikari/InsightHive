{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   campaign_item_id  no_of_days  ext_service_id  creative_id  template_id  \\\n",
      "0              2733    0.059322             128         1000         90.0   \n",
      "1              2733    0.067797              16         1000         90.0   \n",
      "2              2733    0.076271             128         1000         90.0   \n",
      "3              2733    0.084746             128         1000         90.0   \n",
      "4              2733    0.093220               4         1000         90.0   \n",
      "\n",
      "   advertiser_id  network_id  channel_id  campaign_budget_usd  clicks  ...  \\\n",
      "0           4756         190          32             0.201396       8  ...   \n",
      "1           4756         190           8             0.201396      44  ...   \n",
      "2           4756         190           8             0.201396      32  ...   \n",
      "3           4756         190          64             0.201396      48  ...   \n",
      "4           4756         190          32             0.201396      20  ...   \n",
      "\n",
      "   advertiser_emb_40  advertiser_emb_41  advertiser_emb_42  advertiser_emb_43  \\\n",
      "0           0.003433           0.019426           0.009145           0.016177   \n",
      "1           0.003433           0.019426           0.009145           0.016177   \n",
      "2           0.003433           0.019426           0.009145           0.016177   \n",
      "3           0.003433           0.019426           0.009145           0.016177   \n",
      "4           0.003433           0.019426           0.009145           0.016177   \n",
      "\n",
      "   advertiser_emb_44  advertiser_emb_45  advertiser_emb_46  advertiser_emb_47  \\\n",
      "0          -0.000941            0.00129          -0.005337          -0.017559   \n",
      "1          -0.000941            0.00129          -0.005337          -0.017559   \n",
      "2          -0.000941            0.00129          -0.005337          -0.017559   \n",
      "3          -0.000941            0.00129          -0.005337          -0.017559   \n",
      "4          -0.000941            0.00129          -0.005337          -0.017559   \n",
      "\n",
      "   advertiser_emb_48  advertiser_emb_49  \n",
      "0           0.006863           0.004187  \n",
      "1           0.006863           0.004187  \n",
      "2           0.006863           0.004187  \n",
      "3           0.006863           0.004187  \n",
      "4           0.006863           0.004187  \n",
      "\n",
      "[5 rows x 244 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your raw dataset (assuming it's a CSV)\n",
    "df = pd.read_csv('../Datasets/processed_data.csv')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting all the relevent columns to the relevent nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       template_id\n",
      "0             90.0\n",
      "1             90.0\n",
      "2             90.0\n",
      "3             90.0\n",
      "4             90.0\n",
      "...            ...\n",
      "69195         90.0\n",
      "69196         90.0\n",
      "69197         90.0\n",
      "69198         90.0\n",
      "69199         90.0\n",
      "\n",
      "[69200 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Campaign Node - Collect features for the campaign node\n",
    "campaign_features = df[['campaign_item_id'] + [col for col in df.columns if col.startswith('zone_')] + [col for col in df.columns if col.startswith('search_tag_emb_')]]\n",
    "\n",
    "# Platform Node - Collect features for the platform node \n",
    "platform_features = df[['ext_service_id'] + [col for col in df.columns if col.startswith('plateform_')]]\n",
    "\n",
    "# Advertiser Node - Collect features for the advertiser node \n",
    "advertiser_features = df[['advertiser_id'] + [col for col in df.columns if col.startswith('advertiser_emb_')]]\n",
    "\n",
    "# Creative Node - Collect features for the creative node \n",
    "creative_features = df[['creative_id','creative_dimension']]\n",
    "\n",
    "# Template Node - Collect features for the template node\n",
    "template_features = df[['template_id']]\n",
    "\n",
    "# Channel Node - Collect features for the channel node\n",
    "channel_features = df[[col for col in df.columns if col.startswith('channel_')]]\n",
    "\n",
    "# Network Node - Collect features for the network node\n",
    "network_features = df[['network_id']]\n",
    "\n",
    "# Landing Page Node - Collect features for the landing page node \n",
    "landing_page_features = df[[col for col in df.columns if col.startswith('landing_page_emb_')]]\n",
    "\n",
    "# Time Node - Collect features for the time node (day_of_week, month, day_of_year, etc.)\n",
    "time_features = df[['day_of_week', 'month', 'day_of_year']]\n",
    "\n",
    "# Keyword Node - Collect features for the keyword node (keyword embeddings)\n",
    "keyword_features = df[[col for col in df.columns if col.startswith('keyword_')]]\n",
    "\n",
    "print(template_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating id's for nodes which dont have id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To uniquely identify each keyword embedding, we'll hash the rows\n",
    "df['keyword_id'] = keyword_features.apply(lambda row: hash(tuple(row)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To uniquely identify each keyword embedding, we'll hash the rows\n",
    "df['landing_page_id'] = landing_page_features.apply(lambda row: hash(tuple(row)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique identifier for each time combination\n",
    "df['time_id'] = df['day_of_week'].astype(str) + '_' + df['month'].astype(str) + '_' + df['day_of_year'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(channel_features['channel_id']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['channel_id', 'channel_Display', 'channel_Mobile', 'channel_Search',\n",
      "       'channel_Social', 'channel_Video'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(channel_features.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thinkpad\\AppData\\Local\\Temp\\ipykernel_17168\\300363278.py:36: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  edge_index_campaign_platform = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Creating the Nodes    \n",
    "campaign = torch.tensor(campaign_features.values, dtype=torch.float)  # node features for Campaign\n",
    "platform = torch.tensor(platform_features.values, dtype=torch.float)  # node features for Platform\n",
    "advertiser = torch.tensor(advertiser_features.values, dtype=torch.float)  # node features for Advertiser\n",
    "creative = torch.tensor(creative_features.values, dtype=torch.float)  # node features for Creative\n",
    "template = torch.tensor(template_features.values, dtype=torch.float) # node features for  template\n",
    "channel = torch.tensor(channel_features.values, dtype=torch.float)  # node features for channel\n",
    "time = torch.tensor(time_features.values, dtype=torch.float)   # node features for Time\n",
    "keyword = torch.tensor(keyword_features.values, dtype=torch.float)\n",
    "network = torch.tensor(network_features.values, dtype=torch.float)  # node features for Network\n",
    "landing_page = torch.tensor(landing_page_features.values, dtype=torch.float)\n",
    "\n",
    "# MAKING CONNECTION BETWEEN NODES\n",
    "# Mapping IDs to indices for each node type\n",
    "campaign_id_to_index = {cid: idx for idx, cid in enumerate(campaign_features['campaign_item_id'].unique())}\n",
    "platform_id_to_index = {pid: idx for idx, pid in enumerate(platform_features['ext_service_id'].unique())}\n",
    "advertiser_id_to_index = {aid: idx for idx, aid in enumerate(advertiser_features['advertiser_id'].unique())}\n",
    "network_id_to_index = {nid: idx for idx, nid in enumerate(network_features['network_id'].unique())}\n",
    "creative_id_to_index = {crid: idx for idx, crid in enumerate(creative_features['creative_id'].unique())}\n",
    "template_id_to_index = {tid: idx for idx, tid in enumerate(template_features['template_id'].unique())}\n",
    "channel_id_to_index = {chid: idx for idx, chid in enumerate(channel_features['channel_id'].unique())}\n",
    "keyword_id_to_index = {kid: idx for idx, kid in enumerate(df['keyword_id'].unique())}\n",
    "landing_page_id_to_index = {lid: idx for idx, lid in enumerate(df['landing_page_id'].unique())}\n",
    "time_id_to_index = {tid: idx for idx, tid in enumerate(df['time_id'].unique())}\n",
    "\n",
    "\n",
    "# CREATING EDGES\n",
    "\n",
    "# Campaign -> Platform\n",
    "source_nodes = df['campaign_item_id'].map(campaign_id_to_index).values\n",
    "target_nodes = df['ext_service_id'].map(platform_id_to_index).values\n",
    "edge_index_campaign_platform = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Campaign -> Advertiser\n",
    "source_nodes = df['campaign_item_id'].map(campaign_id_to_index).values\n",
    "target_nodes = df['advertiser_id'].map(advertiser_id_to_index).values\n",
    "edge_index_campaign_advertiser = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Campaign -> Network\n",
    "source_nodes = df['campaign_item_id'].map(campaign_id_to_index).values\n",
    "target_nodes = df['network_id'].map(network_id_to_index).values\n",
    "edge_index_campaign_network = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Campaign -> Channel\n",
    "source_nodes = df['campaign_item_id'].map(campaign_id_to_index).values\n",
    "target_nodes = df['channel_id'].map(channel_id_to_index).values\n",
    "edge_index_campaign_channel = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Campaign -> Keyword\n",
    "source_nodes = df['campaign_item_id'].map(campaign_id_to_index).values\n",
    "target_nodes = df['keyword_id'].map(keyword_id_to_index).values\n",
    "edge_index_campaign_keyword = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Campaign -> Time\n",
    "source_nodes = df['ext_service_id'].map(platform_id_to_index).values\n",
    "target_nodes = df['time_id'].map(time_id_to_index).values\n",
    "edge_index_campaign_time = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Platform -> Channel\n",
    "source_nodes = df['ext_service_id'].map(platform_id_to_index).values\n",
    "target_nodes = df['channel_id'].map(channel_id_to_index).values\n",
    "edge_index_platform_channel = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Platform -> Time\n",
    "source_nodes = df['ext_service_id'].map(platform_id_to_index).values\n",
    "target_nodes = df['time_id'].map(time_id_to_index).values\n",
    "edge_index_platform_time = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Plateform -> Keyword\n",
    "source_nodes = df['ext_service_id'].map(platform_id_to_index).values\n",
    "target_nodes = df['keyword_id'].map(keyword_id_to_index).values\n",
    "edge_index_campaign_keyword = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Creative -> Campaign\n",
    "source_nodes = df['creative_id'].map(creative_id_to_index).values\n",
    "target_nodes = df['campaign_item_id'].map(campaign_id_to_index).values\n",
    "edge_index_creative_campaign = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Creative -> Template\n",
    "source_nodes = df['creative_id'].map(creative_id_to_index).values\n",
    "target_nodes = df['template_id'].map(template_id_to_index).values\n",
    "edge_index_creative_template = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Campaign -> LandingPage\n",
    "source_nodes = df['campaign_item_id'].map(campaign_id_to_index).values\n",
    "target_nodes = df['landing_page_id'].map(landing_page_id_to_index).values\n",
    "edge_index_campaign_landingpage = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_features_campaign_platform = df[['no_of_days', 'media_cost_usd'] + [col for col in df.columns if col.startswith('weekday_week_')]]\n",
    "edge_features_campaign_channel = df[['media_cost_usd','normalized_impressions']]\n",
    "edge_features_campaign_clicks = df[['clicks','campaign_budget_usd']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([69200, 58])\n",
      "torch.Size([69200, 4])\n",
      "torch.Size([69200, 51])\n",
      "torch.Size([69200, 2])\n",
      "torch.Size([69200, 3])\n",
      "torch.Size([69200, 6])\n",
      "torch.Size([69200, 1])\n",
      "torch.Size([69200, 50])\n",
      "torch.Size([69200, 50])\n"
     ]
    }
   ],
   "source": [
    "print(campaign.shape)\n",
    "print(platform.shape)\n",
    "print(advertiser.shape)\n",
    "print(creative.shape)\n",
    "print(time.shape)\n",
    "print(channel.shape)\n",
    "print(network.shape)\n",
    "print(landing_page.shape)\n",
    "print(keyword.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([69200, 58])\n",
      "torch.Size([69200, 58])\n",
      "torch.Size([69200, 58])\n",
      "torch.Size([69200, 58])\n",
      "torch.Size([69200, 58])\n",
      "torch.Size([69200, 58])\n",
      "torch.Size([69200, 58])\n",
      "torch.Size([69200, 58])\n",
      "torch.Size([69200, 58])\n",
      "torch.Size([622800, 58])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define maximum feature dimension (based on the largest tensor)\n",
    "max_dim = max(campaign.shape[1], platform.shape[1], advertiser.shape[1], creative.shape[1], \n",
    "              time.shape[1], channel.shape[1], network.shape[1], landing_page.shape[1], keyword.shape[1])\n",
    "\n",
    "def pad_tensor(tensor, max_dim):\n",
    "    \"\"\"Pads tensor to match max_dim.\"\"\"\n",
    "    current_dim = tensor.shape[1]\n",
    "    if current_dim < max_dim:\n",
    "        padding_size = max_dim - current_dim\n",
    "        # Pad the tensor with zeros\n",
    "        tensor = F.pad(tensor, (0, padding_size), value=0)\n",
    "    return tensor\n",
    "\n",
    "# Padding the feature tensors\n",
    "campaign = pad_tensor(campaign, max_dim)\n",
    "platform = pad_tensor(platform, max_dim)\n",
    "advertiser = pad_tensor(advertiser, max_dim)\n",
    "creative = pad_tensor(creative, max_dim)\n",
    "time = pad_tensor(time, max_dim)\n",
    "channel = pad_tensor(channel, max_dim)\n",
    "network = pad_tensor(network, max_dim)\n",
    "landing_page = pad_tensor(landing_page, max_dim)\n",
    "keyword = pad_tensor(keyword, max_dim)\n",
    "\n",
    "# Check that all tensors have the same dimension\n",
    "print(campaign.shape)\n",
    "print(platform.shape)\n",
    "print(advertiser.shape)\n",
    "print(creative.shape)\n",
    "print(time.shape)\n",
    "print(channel.shape)\n",
    "print(network.shape)\n",
    "print(landing_page.shape)\n",
    "print(keyword.shape)\n",
    "\n",
    "# Now you can safely concatenate them\n",
    "node_features = torch.cat([campaign, platform, advertiser, creative, time, channel, network, landing_page, keyword], dim=0)\n",
    "\n",
    "print(node_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([207600, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Function to pad edge features to the maximum number of columns\n",
    "def pad_edge_features(*edge_features):\n",
    "    max_columns = max([feature.shape[1] for feature in edge_features])  # Find the max column size\n",
    "    padded_edge_features = []\n",
    "    \n",
    "    for feature in edge_features:\n",
    "        if feature.shape[1] < max_columns:\n",
    "            # Padding with zeros (0) to match the max column size\n",
    "            padding_size = max_columns - feature.shape[1]\n",
    "            padded_feature = F.pad(feature, (0, padding_size), value=0)  # Pad only along the last dimension (columns)\n",
    "            padded_edge_features.append(padded_feature)\n",
    "        else:\n",
    "            padded_edge_features.append(feature)\n",
    "    \n",
    "    return padded_edge_features\n",
    "\n",
    "# Convert edge features to tensors if they are DataFrames or Series\n",
    "edge_attr_campaign_platform = torch.tensor(edge_features_campaign_platform.values, dtype=torch.float) if isinstance(edge_features_campaign_platform, pd.DataFrame) else edge_attr_campaign_platform\n",
    "edge_attr_campaign_channel = torch.tensor(edge_features_campaign_channel.values, dtype=torch.float) if isinstance(edge_features_campaign_channel, pd.DataFrame) else edge_features_campaign_channel\n",
    "edge_attr_campaign_clicks = torch.tensor(edge_features_campaign_clicks.values, dtype=torch.float) if isinstance(edge_features_campaign_clicks, pd.DataFrame) else edge_features_campaign_clicks\n",
    "\n",
    "\n",
    "# Pad edge features to have the same number of columns\n",
    "edge_attr_campaign_platform, edge_attr_campaign_channel, edge_attr_campaign_clicks = pad_edge_features(\n",
    "    edge_attr_campaign_platform, edge_attr_campaign_channel, edge_attr_campaign_clicks\n",
    ")\n",
    "\n",
    "# Concatenate edge features after padding\n",
    "edge_attr = torch.cat([edge_attr_campaign_platform, edge_attr_campaign_channel, edge_attr_campaign_clicks], dim=0)\n",
    "\n",
    "# Check the shape of concatenated edge features\n",
    "print(edge_attr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define edge_index (source and target nodes)\n",
    "edge_index = torch.cat([edge_index_campaign_platform, edge_index_campaign_advertiser, edge_index_creative_campaign,\n",
    "                        edge_index_campaign_time, edge_index_campaign_channel, edge_index_campaign_network,\n",
    "                        edge_index_campaign_landingpage, edge_index_campaign_keyword,edge_index_creative_template,\n",
    "                        edge_index_platform_channel,edge_index_platform_time], dim=1)  # Add all edge indices\n",
    "\n",
    "# Define edge attributes (edge features)\n",
    "edge_attr = torch.cat([edge_attr_campaign_platform, edge_attr_campaign_channel, edge_attr_campaign_clicks ], dim=0)\n",
    "\n",
    "# Combine node features into one tensor\n",
    "node_features = torch.cat([campaign, platform, advertiser, creative, time, channel, network, landing_page, keyword], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features shape: torch.Size([622800, 58])\n",
      "Edge index shape: torch.Size([2, 761200])\n",
      "Edge attributes shape: torch.Size([761200, 4])\n",
      "Data(x=[622800, 58], edge_index=[2, 761200], edge_attr=[761200, 4])\n"
     ]
    }
   ],
   "source": [
    "# Check the size of the edge_index and edge_attr\n",
    "num_edges = edge_index.shape[1]  # Number of edges in the graph\n",
    "num_edge_features = edge_attr.shape[1] if edge_attr.shape[0] > 0 else 0  # Number of features per edge\n",
    "\n",
    "# If there are missing edge features, pad with zeros\n",
    "# First, calculate how many additional edge features are needed\n",
    "if num_edges > edge_attr.shape[0]:\n",
    "    missing_edge_features = num_edges - edge_attr.shape[0]\n",
    "    \n",
    "    # Create a tensor of zeros to pad missing edge features\n",
    "    default_edge_features = torch.zeros((missing_edge_features, num_edge_features), dtype=torch.float)\n",
    "    \n",
    "    # Concatenate the default edge features to match the number of edges\n",
    "    edge_attr = torch.cat([edge_attr, default_edge_features], dim=0)\n",
    "\n",
    "# Now, create the data object\n",
    "data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "# Verify the sizes\n",
    "print(\"Node features shape:\", node_features.shape)\n",
    "print(\"Edge index shape:\", edge_index.shape)\n",
    "print(\"Edge attributes shape:\", edge_attr.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert edge_attr.shape[0] == edge_index.shape[1], \"Edge attribute count mismatch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3131\n"
     ]
    }
   ],
   "source": [
    "num_nodes_campaigns = len(df['campaign_item_id'].unique())  # Count unique campaign nodes\n",
    "num_nodes_plateform = len(df['ext_service_id'].unique())\n",
    "num_nodes_channel = len(df['channel_id'].unique())\n",
    "num_nodes_time = len(df['time_id'].unique())\n",
    "num_nodes_template = len(df['template_id'].unique())\n",
    "num_nodes_creative = len(df['creative_id'].unique())\n",
    "num_nodes_network = len(df['network_id'].unique())\n",
    "num_nodes_advertiser = len(df['advertiser_id'].unique())\n",
    "num_nodes_keyword = len(df['keyword_id'].unique())\n",
    "num_nodes_landingpage = len(df['landing_page_id'].unique())\n",
    "print(num_nodes_campaigns + num_nodes_plateform + num_nodes_channel + num_nodes_time + num_nodes_template + num_nodes_creative + num_nodes_network +\n",
    "      num_nodes_advertiser + num_nodes_keyword + num_nodes_landingpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Index (Campaign -> Platform): tensor([[  0,   0,   0,  ..., 140, 140, 140],\n",
      "        [  0,   1,   0,  ...,   0,   0,   1]])\n",
      "Edge Index (Campaign -> Advertiser): tensor([[  0,   0,   0,  ..., 140, 140, 140],\n",
      "        [  0,   0,   0,  ...,  11,  11,  11]])\n",
      "Edge Index (Campaign -> Network): tensor([[  0,   0,   0,  ..., 140, 140, 140],\n",
      "        [  0,   0,   0,  ...,   5,   5,   5]])\n",
      "Edge Index (Campaign -> Channel): tensor([[  0,   0,   0,  ..., 140, 140, 140],\n",
      "        [  0,   1,   1,  ...,   4,   1,   1]])\n",
      "Edge Index (Campaign -> Keyword): tensor([[ 0,  1,  0,  ...,  0,  0,  1],\n",
      "        [ 0,  1,  2,  ..., 50, 36, 26]])\n",
      "Edge Index (Campaign -> Time): tensor([[  0,   1,   0,  ...,   0,   0,   1],\n",
      "        [  0,   1,   2,  ..., 207, 208, 209]])\n",
      "Edge Index (Platform -> Channel): tensor([[0, 1, 0,  ..., 0, 0, 1],\n",
      "        [0, 1, 1,  ..., 4, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Edge Index (Campaign -> Platform):\", edge_index_campaign_platform)\n",
    "print(\"Edge Index (Campaign -> Advertiser):\", edge_index_campaign_advertiser)\n",
    "print(\"Edge Index (Campaign -> Network):\", edge_index_campaign_network)\n",
    "print(\"Edge Index (Campaign -> Channel):\", edge_index_campaign_channel)\n",
    "print(\"Edge Index (Campaign -> Keyword):\", edge_index_campaign_keyword)\n",
    "print(\"Edge Index (Campaign -> Time):\", edge_index_campaign_time)\n",
    "print(\"Edge Index (Platform -> Channel):\", edge_index_platform_channel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "# # List to hold Data objects for each graph\n",
    "# graph_data_list = []\n",
    "\n",
    "# # Loop through the DataFrame to create graphs\n",
    "# for _, row in df.iterrows():\n",
    "#     # Fetch node features and other graph-related data from your dataset (modify as per your needs)\n",
    "#     node_features = torch.randn(3131, 58)  # Replace with your actual node features\n",
    "#     edge_index = torch.randint(0, 100, (2, 150))  # Replace with actual edge indices\n",
    "#     edge_attr = torch.randn(150, 4)  # Replace with actual edge attributes\n",
    "    \n",
    "#     # Create Data object for this graph\n",
    "#     graph = Data(\n",
    "#         x=node_features,  # Node features\n",
    "#         edge_index=edge_index,  # Edge indices\n",
    "#         edge_attr=edge_attr,  # Edge attributes\n",
    "#         y=torch.tensor([row['clicks']])  # Target (clicks for this graph)\n",
    "#     )\n",
    "    \n",
    "#     # Add the graph to the list\n",
    "#     graph_data_list.append(graph)\n",
    "\n",
    "# # Define a DataLoader for batching\n",
    "# batch_size = 2  # Number of graphs per batch\n",
    "# data_loader = DataLoader(graph_data_list, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# # Iterate through the DataLoader\n",
    "# for batch in data_loader:\n",
    "#     print(\"Batched Node Features Shape:\", batch.x.shape)\n",
    "#     print(\"Batched Edge Index Shape:\", batch.edge_index.shape)\n",
    "#     print(\"Batched Edge Attributes Shape:\", batch.edge_attr.shape)\n",
    "#     print(\"Batched Targets (data.y):\", batch.y)\n",
    "#     print(\"Batch object:\", batch)\n",
    "#     break  # To only show one batch example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels=64):\n",
    "        super(GNNModel, self).__init__()\n",
    "        \n",
    "        # Define the GCN layers\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, out_channels)\n",
    "        \n",
    "        # If needed, add a fully connected layer for final predictions\n",
    "        self.fc = nn.Linear(out_channels, 1)  # For click prediction (regression)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        \n",
    "        # Apply the first convolution layer with ReLU activation\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # Apply the second convolution layer\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # Apply the third convolution layer\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        \n",
    "        # Use global mean pooling (can be modified depending on your task)\n",
    "        x = global_mean_pool(x, data.batch)  # Data.batch assumes batched graphs, otherwise, skip\n",
    "        \n",
    "        # Final prediction using a fully connected layer\n",
    "        out = self.fc(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5403916) must match the size of tensor b (1350979) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 21\u001b[0m\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass the data to the model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Assuming 'data.y' contains the target values (clicks in this case)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, data\u001b[38;5;241m.\u001b[39my)  \u001b[38;5;66;03m# 'data.y' should contain the actual number of clicks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[20], line 21\u001b[0m, in \u001b[0;36mGNNModel.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     18\u001b[0m x, edge_index, edge_attr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39medge_attr\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Apply the first convolution layer with ReLU activation\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Apply the second convolution layer\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:263\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    260\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[1;32m--> 263\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.gcn_conv_GCNConv_propagate_jblshsks.py:209\u001b[0m, in \u001b[0;36mpropagate\u001b[1;34m(self, edge_index, x, edge_weight, size)\u001b[0m\n\u001b[0;32m    200\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[0;32m    201\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_j\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    202\u001b[0m                 edge_weight\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_weight\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mdim_size,\n\u001b[0;32m    206\u001b[0m             )\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# End Message Forward Pre Hook #########################################\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_j\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_j\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m# Begin Message Forward Hook ###########################################\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:271\u001b[0m, in \u001b[0;36mGCNConv.message\u001b[1;34m(self, x_j, edge_weight)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessage\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_j: Tensor, edge_weight: OptTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_j \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_j\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (5403916) must match the size of tensor b (1350979) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "# Initialize the model\n",
    "model = GNNModel(in_channels=node_features.shape[1], out_channels=64)  # Adjust as needed\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()  # For regression (click prediction)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100  # Adjust as needed\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Forward pass\n",
    "    out = model(data)  # Pass the data to the model\n",
    "\n",
    "    # Assuming 'data.y' contains the target values (clicks in this case)\n",
    "    loss = criterion(out, data.y)  # 'data.y' should contain the actual number of clicks\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every few epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_features = campaign_features.to_numpy()\n",
    "platform_features = platform_features.to_numpy()\n",
    "advertiser_features = advertiser_features.to_numpy()\n",
    "network_features = network_features.to_numpy()\n",
    "channel_features = channel_features.to_numpy()\n",
    "keyword_features = keyword_features.to_numpy()\n",
    "time_features = time_features.to_numpy()\n",
    "creative_features = creative_features.to_numpy()\n",
    "template_features = template_features.to_numpy()\n",
    "landing_page_features = landing_page_features.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "# Initialize a HeteroData object\n",
    "hetero_data = HeteroData()\n",
    "\n",
    "# Add nodes and features (assuming you have features for each type of node)\n",
    "hetero_data['campaign'].x = torch.tensor(campaign_features, dtype=torch.float)\n",
    "hetero_data['platform'].x = torch.tensor(platform_features, dtype=torch.float)\n",
    "hetero_data['advertiser'].x = torch.tensor(advertiser_features, dtype=torch.float)\n",
    "hetero_data['network'].x = torch.tensor(network_features, dtype=torch.float)\n",
    "hetero_data['channel'].x = torch.tensor(channel_features, dtype=torch.float)\n",
    "hetero_data['keyword'].x = torch.tensor(keyword_features, dtype=torch.float)\n",
    "hetero_data['time'].x = torch.tensor(time_features, dtype=torch.float)\n",
    "hetero_data['creative'].x = torch.tensor(creative_features, dtype=torch.float)\n",
    "hetero_data['template'].x = torch.tensor(template_features, dtype=torch.float)\n",
    "hetero_data['landing_page'].x = torch.tensor(landing_page_features, dtype=torch.float)\n",
    "\n",
    "# Add edge indices\n",
    "hetero_data['campaign', 'to', 'platform'].edge_index = edge_index_campaign_platform\n",
    "hetero_data['campaign', 'to', 'advertiser'].edge_index = edge_index_campaign_advertiser\n",
    "hetero_data['campaign', 'to', 'network'].edge_index = edge_index_campaign_network\n",
    "hetero_data['campaign', 'to', 'channel'].edge_index = edge_index_campaign_channel\n",
    "hetero_data['campaign', 'to', 'keyword'].edge_index = edge_index_campaign_keyword\n",
    "hetero_data['campaign', 'to', 'time'].edge_index = edge_index_campaign_time\n",
    "hetero_data['platform', 'to', 'channel'].edge_index = edge_index_platform_channel\n",
    "hetero_data['platform', 'to', 'time'].edge_index = edge_index_platform_time\n",
    "hetero_data['platform', 'to', 'keyword'].edge_index = edge_index_campaign_keyword\n",
    "hetero_data['creative', 'to', 'campaign'].edge_index = edge_index_creative_campaign\n",
    "hetero_data['creative', 'to', 'template'].edge_index = edge_index_creative_template\n",
    "hetero_data['campaign', 'to', 'landing_page'].edge_index = edge_index_campaign_landingpage\n",
    "\n",
    "# (Optional) Add edge attributes if available\n",
    "# Example: hetero_data['campaign', 'to', 'platform'].edge_attr = torch.randn(edge_index_campaign_platform.size(1), edge_attr_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  campaign={ x=[69200, 58] },\n",
      "  platform={ x=[69200, 4] },\n",
      "  advertiser={ x=[69200, 51] },\n",
      "  network={ x=[69200, 1] },\n",
      "  channel={ x=[69200, 6] },\n",
      "  keyword={ x=[69200, 50] },\n",
      "  time={ x=[69200, 3] },\n",
      "  creative={ x=[69200, 2] },\n",
      "  template={ x=[69200, 1] },\n",
      "  landing_page={ x=[69200, 50] },\n",
      "  (campaign, to, platform)={ edge_index=[2, 69200] },\n",
      "  (campaign, to, advertiser)={ edge_index=[2, 69200] },\n",
      "  (campaign, to, network)={ edge_index=[2, 69200] },\n",
      "  (campaign, to, channel)={ edge_index=[2, 69200] },\n",
      "  (campaign, to, keyword)={ edge_index=[2, 69200] },\n",
      "  (campaign, to, time)={ edge_index=[2, 69200] },\n",
      "  (platform, to, channel)={ edge_index=[2, 69200] },\n",
      "  (platform, to, time)={ edge_index=[2, 69200] },\n",
      "  (platform, to, keyword)={ edge_index=[2, 69200] },\n",
      "  (creative, to, campaign)={ edge_index=[2, 69200] },\n",
      "  (creative, to, template)={ edge_index=[2, 69200] },\n",
      "  (campaign, to, landing_page)={ edge_index=[2, 69200] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(hetero_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([69200, 58])\n",
      "torch.Size([2, 69200])\n"
     ]
    }
   ],
   "source": [
    "print(hetero_data['campaign'].x.shape)  # Shape of campaign features\n",
    "print(hetero_data['campaign', 'to', 'platform'].edge_index.shape)  # Shape of campaign-to-platform edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import HeteroConv, GCNConv, SAGEConv\n",
    "\n",
    "class HeterogeneousGNN(torch.nn.Module):\n",
    "    def __init__(self, metadata):\n",
    "        super().__init__()\n",
    "        # HeteroConv layers to aggregate messages for each edge type\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('campaign', 'to', 'platform'): SAGEConv((-1, -1), 32),\n",
    "            ('campaign', 'to', 'advertiser'): SAGEConv((-1, -1), 32),\n",
    "            ('campaign', 'to', 'network'): SAGEConv((-1, -1), 32),\n",
    "            ('campaign', 'to', 'channel'): SAGEConv((-1, -1), 32),\n",
    "            ('campaign', 'to', 'keyword'): SAGEConv((-1, -1), 32),\n",
    "            ('campaign', 'to', 'time'): SAGEConv((-1, -1), 32),\n",
    "            ('platform', 'to', 'channel'): SAGEConv((-1, -1), 32),\n",
    "            ('campaign', 'to', 'network'): SAGEConv((-1, -1), 32),\n",
    "        }, aggr='mean')  # Aggregation method\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('campaign', 'to', 'platform'): SAGEConv((32, 32), 16),\n",
    "            ('campaign', 'to', 'advertiser'): SAGEConv((32, 32), 16),\n",
    "            ('campaign', 'to', 'network'): SAGEConv((32, 32), 16),\n",
    "            # Add other edge types here\n",
    "        }, aggr='mean')  # Aggregation method\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # First layer\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: x.relu() for key, x in x_dict.items()}  # Apply ReLU\n",
    "\n",
    "        # Second layer\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        return x_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = torch.rand(hetero_data['campaign'].x.size(0)) < 0.8  # 80% training\n",
    "val_mask = ~train_mask\n",
    "hetero_data['campaign'].train_mask = train_mask\n",
    "hetero_data['campaign'].val_mask = val_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\conv\\hetero_conv.py:76: UserWarning: There exist node types ({'campaign'}) whose representations do not get updated during message passing as they do not occur as destination type in any edge type. This may lead to unexpected behavior.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 10\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhetero_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhetero_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Assume you are predicting something for the 'campaign' node type\u001b[39;00m\n\u001b[0;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcampaign\u001b[39m\u001b[38;5;124m'\u001b[39m][hetero_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcampaign\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtrain_mask], \n\u001b[0;32m     14\u001b[0m                  labels[hetero_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcampaign\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtrain_mask])\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[28], line 31\u001b[0m, in \u001b[0;36mHeterogeneousGNN.forward\u001b[1;34m(self, x_dict, edge_index_dict)\u001b[0m\n\u001b[0;32m     28\u001b[0m x_dict \u001b[38;5;241m=\u001b[39m {key: x\u001b[38;5;241m.\u001b[39mrelu() \u001b[38;5;28;01mfor\u001b[39;00m key, x \u001b[38;5;129;01min\u001b[39;00m x_dict\u001b[38;5;241m.\u001b[39mitems()}  \u001b[38;5;66;03m# Apply ReLU\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Second layer\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m x_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_dict\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\conv\\hetero_conv.py:158\u001b[0m, in \u001b[0;36mHeteroConv.forward\u001b[1;34m(self, *args_dict, **kwargs_dict)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_edge_level_arg:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dst \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m out_dict:\n\u001b[0;32m    161\u001b[0m     out_dict[dst] \u001b[38;5;241m=\u001b[39m [out]\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\conv\\sage_conv.py:134\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[1;34m(self, x, edge_index, size)\u001b[0m\n\u001b[0;32m    131\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mrelu(), x[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[0;32m    137\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_5nd67yy6.py:229\u001b[0m, in \u001b[0;36mpropagate\u001b[1;34m(self, edge_index, x, size)\u001b[0m\n\u001b[0;32m    221\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[0;32m    222\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mx_j,\n\u001b[0;32m    223\u001b[0m                 index\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    224\u001b[0m                 ptr\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mptr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    225\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    226\u001b[0m             )\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# End Aggregate Forward Pre Hook #######################################\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# Begin Aggregate Forward Hook #########################################\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:594\u001b[0m, in \u001b[0;36mMessagePassing.aggregate\u001b[1;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    579\u001b[0m     inputs: Tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    582\u001b[0m     dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    583\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    584\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;124;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;124;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggr_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\experimental.py:117\u001b[0m, in \u001b[0;36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_experimental_mode_enabled(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_dynamic_shapes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m required_arg \u001b[38;5;129;01min\u001b[39;00m required_args:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m required_args_pos[required_arg]\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\aggr\\base.py:112\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[1;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;129m@disable_dynamic_shapes\u001b[39m(required_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_size\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    110\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m() \u001b[38;5;129;01mor\u001b[39;00m dim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mx\u001b[38;5;241m.\u001b[39mdim():\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered invalid dimension \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    114\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource tensor with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ptr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = HeterogeneousGNN(metadata=hetero_data.metadata())\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Use appropriate loss for your task\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(hetero_data.x_dict, hetero_data.edge_index_dict)\n",
    "    \n",
    "    # Assume you are predicting something for the 'campaign' node type\n",
    "    loss = criterion(out['campaign'][hetero_data['campaign'].train_mask], \n",
    "                     labels[hetero_data['campaign'].train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(hetero_data.x_dict, hetero_data.edge_index_dict)\n",
    "    # Evaluation metrics on test data\n",
    "    test_acc = (out['campaign'][test_mask].argmax(dim=-1) == labels[test_mask]).sum() / test_mask.sum()\n",
    "    print(f\"Test Accuracy: {test_acc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
