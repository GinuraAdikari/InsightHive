{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   campaign_item_id  no_of_days  ext_service_id  creative_id  template_id  \\\n",
      "0              2733    0.059322             128         1000         90.0   \n",
      "1              2733    0.067797              16         1000         90.0   \n",
      "2              2733    0.076271             128         1000         90.0   \n",
      "3              2733    0.084746             128         1000         90.0   \n",
      "4              2733    0.093220               4         1000         90.0   \n",
      "\n",
      "   advertiser_id  network_id  channel_id  campaign_budget_usd  clicks  ...  \\\n",
      "0           4756         190          32             0.201396       8  ...   \n",
      "1           4756         190           8             0.201396      44  ...   \n",
      "2           4756         190           8             0.201396      32  ...   \n",
      "3           4756         190          64             0.201396      48  ...   \n",
      "4           4756         190          32             0.201396      20  ...   \n",
      "\n",
      "   advertiser_emb_40  advertiser_emb_41  advertiser_emb_42  advertiser_emb_43  \\\n",
      "0           0.003433           0.019426           0.009145           0.016177   \n",
      "1           0.003433           0.019426           0.009145           0.016177   \n",
      "2           0.003433           0.019426           0.009145           0.016177   \n",
      "3           0.003433           0.019426           0.009145           0.016177   \n",
      "4           0.003433           0.019426           0.009145           0.016177   \n",
      "\n",
      "   advertiser_emb_44  advertiser_emb_45  advertiser_emb_46  advertiser_emb_47  \\\n",
      "0          -0.000941            0.00129          -0.005337          -0.017559   \n",
      "1          -0.000941            0.00129          -0.005337          -0.017559   \n",
      "2          -0.000941            0.00129          -0.005337          -0.017559   \n",
      "3          -0.000941            0.00129          -0.005337          -0.017559   \n",
      "4          -0.000941            0.00129          -0.005337          -0.017559   \n",
      "\n",
      "   advertiser_emb_48  advertiser_emb_49  \n",
      "0           0.006863           0.004187  \n",
      "1           0.006863           0.004187  \n",
      "2           0.006863           0.004187  \n",
      "3           0.006863           0.004187  \n",
      "4           0.006863           0.004187  \n",
      "\n",
      "[5 rows x 244 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your raw dataset (assuming it's a CSV)\n",
    "df = pd.read_csv('../Datasets/processed_data.csv')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting all the relevent columns to the relevent nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       template_id\n",
      "0             90.0\n",
      "1             90.0\n",
      "2             90.0\n",
      "3             90.0\n",
      "4             90.0\n",
      "...            ...\n",
      "69195         90.0\n",
      "69196         90.0\n",
      "69197         90.0\n",
      "69198         90.0\n",
      "69199         90.0\n",
      "\n",
      "[69200 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Campaign Node - Collect features for the campaign node\n",
    "campaign_features = df[['campaign_item_id'] + [col for col in df.columns if col.startswith('zone_')] + [col for col in df.columns if col.startswith('search_tag_emb_')]]\n",
    "\n",
    "# Platform Node - Collect features for the platform node \n",
    "platform_features = df[['ext_service_id'] + [col for col in df.columns if col.startswith('plateform_')]]\n",
    "\n",
    "# Advertiser Node - Collect features for the advertiser node \n",
    "advertiser_features = df[['advertiser_id'] + [col for col in df.columns if col.startswith('advertiser_emb_')]]\n",
    "\n",
    "# Creative Node - Collect features for the creative node \n",
    "creative_features = df[['creative_id','creative_dimension']]\n",
    "\n",
    "# Template Node - Collect features for the template node\n",
    "template_features = df[['template_id']]\n",
    "\n",
    "# Channel Node - Collect features for the channel node\n",
    "channel_features = df[[col for col in df.columns if col.startswith('channel_')]]\n",
    "\n",
    "# Network Node - Collect features for the network node\n",
    "network_features = df[['network_id']]\n",
    "\n",
    "# Landing Page Node - Collect features for the landing page node \n",
    "landing_page_features = df[[col for col in df.columns if col.startswith('landing_page_emb_')]]\n",
    "\n",
    "# Time Node - Collect features for the time node (day_of_week, month, day_of_year, etc.)\n",
    "time_features = df[['day_of_week', 'month', 'day_of_year']]\n",
    "\n",
    "# Keyword Node - Collect features for the keyword node (keyword embeddings)\n",
    "keyword_features = df[[col for col in df.columns if col.startswith('keyword_')]]\n",
    "\n",
    "print(template_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating id's for nodes which dont have id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To uniquely identify each keyword embedding, we'll hash the rows\n",
    "df['keyword_id'] = keyword_features.apply(lambda row: hash(tuple(row)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To uniquely identify each keyword embedding, we'll hash the rows\n",
    "df['landing_page_id'] = landing_page_features.apply(lambda row: hash(tuple(row)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique identifier for each time combination\n",
    "df['time_id'] = df['day_of_week'].astype(str) + '_' + df['month'].astype(str) + '_' + df['day_of_year'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(channel_features['channel_id']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['channel_id', 'channel_Display', 'channel_Mobile', 'channel_Search',\n",
      "       'channel_Social', 'channel_Video'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(channel_features.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Creating the Nodes    \n",
    "campaign = torch.tensor(campaign_features.values, dtype=torch.float)  # node features for Campaign\n",
    "platform = torch.tensor(platform_features.values, dtype=torch.float)  # node features for Platform\n",
    "advertiser = torch.tensor(advertiser_features.values, dtype=torch.float)  # node features for Advertiser\n",
    "creative = torch.tensor(creative_features.values, dtype=torch.float)  # node features for Creative\n",
    "template = torch.tensor(template_features.values, dtype=torch.float) # node features for  template\n",
    "channel = torch.tensor(channel_features.values, dtype=torch.float)  # node features for channel\n",
    "time = torch.tensor(time_features.values, dtype=torch.float)   # node features for Time\n",
    "keyword = torch.tensor(keyword_features.values, dtype=torch.float)\n",
    "network = torch.tensor(network_features.values, dtype=torch.float)  # node features for Network\n",
    "landing_page = torch.tensor(landing_page_features.values, dtype=torch.float)\n",
    "\n",
    "# MAKING CONNECTION BETWEEN NODES\n",
    "# Mapping IDs to indices for each node type\n",
    "campaign_id_to_index = {cid: idx for idx, cid in enumerate(campaign_features['campaign_item_id'].unique())}\n",
    "platform_id_to_index = {pid: idx for idx, pid in enumerate(platform_features['ext_service_id'].unique())}\n",
    "advertiser_id_to_index = {aid: idx for idx, aid in enumerate(advertiser_features['advertiser_id'].unique())}\n",
    "network_id_to_index = {nid: idx for idx, nid in enumerate(network_features['network_id'].unique())}\n",
    "creative_id_to_index = {crid: idx for idx, crid in enumerate(creative_features['creative_id'].unique())}\n",
    "template_id_to_index = {tid: idx for idx, tid in enumerate(template_features['template_id'].unique())}\n",
    "channel_id_to_index = {chid: idx for idx, chid in enumerate(channel_features['channel_id'].unique())}\n",
    "keyword_id_to_index = {kid: idx for idx, kid in enumerate(df['keyword_id'].unique())}\n",
    "landing_page_id_to_index = {lid: idx for idx, lid in enumerate(df['landing_page_id'].unique())}\n",
    "time_id_to_index = {tid: idx for idx, tid in enumerate(df['time_id'].unique())}\n",
    "\n",
    "\n",
    "# CREATING EDGES\n",
    "\n",
    "# Campaign -> Platform\n",
    "source_nodes = df['campaign_item_id'].map(campaign_id_to_index).values\n",
    "target_nodes = df['ext_service_id'].map(platform_id_to_index).values\n",
    "edge_index_campaign_platform = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Campaign -> Advertiser\n",
    "source_nodes = df['campaign_item_id'].map(campaign_id_to_index).values\n",
    "target_nodes = df['advertiser_id'].map(advertiser_id_to_index).values\n",
    "edge_index_campaign_advertiser = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Campaign -> Network\n",
    "source_nodes = df['campaign_item_id'].map(campaign_id_to_index).values\n",
    "target_nodes = df['network_id'].map(network_id_to_index).values\n",
    "edge_index_campaign_network = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Campaign -> Channel\n",
    "source_nodes = df['campaign_item_id'].map(campaign_id_to_index).values\n",
    "target_nodes = df['channel_id'].map(channel_id_to_index).values\n",
    "edge_index_campaign_channel = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Campaign -> Keyword\n",
    "source_nodes = df['campaign_item_id'].map(campaign_id_to_index).values\n",
    "target_nodes = df['keyword_id'].map(keyword_id_to_index).values\n",
    "edge_index_campaign_keyword = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Campaign -> Time\n",
    "source_nodes = df['ext_service_id'].map(platform_id_to_index).values\n",
    "target_nodes = df['time_id'].map(time_id_to_index).values\n",
    "edge_index_campaign_time = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Platform -> Channel\n",
    "source_nodes = df['ext_service_id'].map(platform_id_to_index).values\n",
    "target_nodes = df['channel_id'].map(channel_id_to_index).values\n",
    "edge_index_platform_channel = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Platform -> Time\n",
    "source_nodes = df['ext_service_id'].map(platform_id_to_index).values\n",
    "target_nodes = df['time_id'].map(time_id_to_index).values\n",
    "edge_index_platform_time = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Plateform -> Keyword\n",
    "source_nodes = df['ext_service_id'].map(platform_id_to_index).values\n",
    "target_nodes = df['keyword_id'].map(keyword_id_to_index).values\n",
    "edge_index_campaign_keyword = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Creative -> Campaign\n",
    "source_nodes = df['creative_id'].map(creative_id_to_index).values\n",
    "target_nodes = df['campaign_item_id'].map(campaign_id_to_index).values\n",
    "edge_index_creative_campaign = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Creative -> Template\n",
    "source_nodes = df['creative_id'].map(creative_id_to_index).values\n",
    "target_nodes = df['template_id'].map(template_id_to_index).values\n",
    "edge_index_creative_template = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Campaign -> LandingPage\n",
    "source_nodes = df['campaign_item_id'].map(campaign_id_to_index).values\n",
    "target_nodes = df['landing_page_id'].map(landing_page_id_to_index).values\n",
    "edge_index_campaign_landingpage = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       clicks  campaign_budget_usd\n",
      "0           8             0.201396\n",
      "1          44             0.201396\n",
      "2          32             0.201396\n",
      "3          48             0.201396\n",
      "4          20             0.201396\n",
      "...       ...                  ...\n",
      "69195      12             0.113102\n",
      "69196       7             0.113102\n",
      "69197      25             0.113102\n",
      "69198      11             0.113102\n",
      "69199       3             0.113102\n",
      "\n",
      "[69200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "edge_features_campaign_platform = df[['no_of_days', 'media_cost_usd'] + [col for col in df.columns if col.startswith('weekday_week_')]]\n",
    "edge_features_campaign_channel = df[['media_cost_usd','normalized_impressions']]\n",
    "edge_features_campaign_clicks = df[['clicks','campaign_budget_usd']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([69200, 58])\n",
      "torch.Size([69200, 4])\n",
      "torch.Size([69200, 51])\n",
      "torch.Size([69200, 2])\n",
      "torch.Size([69200, 3])\n",
      "torch.Size([69200, 6])\n",
      "torch.Size([69200, 1])\n",
      "torch.Size([69200, 50])\n",
      "torch.Size([69200, 51])\n"
     ]
    }
   ],
   "source": [
    "print(campaign.shape)\n",
    "print(platform.shape)\n",
    "print(advertiser.shape)\n",
    "print(creative.shape)\n",
    "print(time.shape)\n",
    "print(channel.shape)\n",
    "print(network.shape)\n",
    "print(landing_page.shape)\n",
    "print(keyword.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([69200, 58])\n",
      "torch.Size([69200, 58])\n",
      "torch.Size([69200, 58])\n",
      "torch.Size([69200, 58])\n",
      "torch.Size([69200, 58])\n",
      "torch.Size([69200, 58])\n",
      "torch.Size([69200, 58])\n",
      "torch.Size([69200, 58])\n",
      "torch.Size([69200, 58])\n",
      "torch.Size([622800, 58])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define maximum feature dimension (based on the largest tensor)\n",
    "max_dim = max(campaign.shape[1], platform.shape[1], advertiser.shape[1], creative.shape[1], \n",
    "              time.shape[1], channel.shape[1], network.shape[1], landing_page.shape[1], keyword.shape[1])\n",
    "\n",
    "def pad_tensor(tensor, max_dim):\n",
    "    \"\"\"Pads tensor to match max_dim.\"\"\"\n",
    "    current_dim = tensor.shape[1]\n",
    "    if current_dim < max_dim:\n",
    "        padding_size = max_dim - current_dim\n",
    "        # Pad the tensor with zeros\n",
    "        tensor = F.pad(tensor, (0, padding_size), value=0)\n",
    "    return tensor\n",
    "\n",
    "# Padding the feature tensors\n",
    "campaign = pad_tensor(campaign, max_dim)\n",
    "platform = pad_tensor(platform, max_dim)\n",
    "advertiser = pad_tensor(advertiser, max_dim)\n",
    "creative = pad_tensor(creative, max_dim)\n",
    "time = pad_tensor(time, max_dim)\n",
    "channel = pad_tensor(channel, max_dim)\n",
    "network = pad_tensor(network, max_dim)\n",
    "landing_page = pad_tensor(landing_page, max_dim)\n",
    "keyword = pad_tensor(keyword, max_dim)\n",
    "\n",
    "# Check that all tensors have the same dimension\n",
    "print(campaign.shape)\n",
    "print(platform.shape)\n",
    "print(advertiser.shape)\n",
    "print(creative.shape)\n",
    "print(time.shape)\n",
    "print(channel.shape)\n",
    "print(network.shape)\n",
    "print(landing_page.shape)\n",
    "print(keyword.shape)\n",
    "\n",
    "# Now you can safely concatenate them\n",
    "node_features = torch.cat([campaign, platform, advertiser, creative, time, channel, network, landing_page, keyword], dim=0)\n",
    "\n",
    "print(node_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([207600, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Function to pad edge features to the maximum number of columns\n",
    "def pad_edge_features(*edge_features):\n",
    "    max_columns = max([feature.shape[1] for feature in edge_features])  # Find the max column size\n",
    "    padded_edge_features = []\n",
    "    \n",
    "    for feature in edge_features:\n",
    "        if feature.shape[1] < max_columns:\n",
    "            # Padding with zeros (0) to match the max column size\n",
    "            padding_size = max_columns - feature.shape[1]\n",
    "            padded_feature = F.pad(feature, (0, padding_size), value=0)  # Pad only along the last dimension (columns)\n",
    "            padded_edge_features.append(padded_feature)\n",
    "        else:\n",
    "            padded_edge_features.append(feature)\n",
    "    \n",
    "    return padded_edge_features\n",
    "\n",
    "# Convert edge features to tensors if they are DataFrames or Series\n",
    "edge_attr_campaign_platform = torch.tensor(edge_features_campaign_platform.values, dtype=torch.float) if isinstance(edge_features_campaign_platform, pd.DataFrame) else edge_attr_campaign_platform\n",
    "edge_attr_campaign_channel = torch.tensor(edge_features_campaign_channel.values, dtype=torch.float) if isinstance(edge_features_campaign_channel, pd.DataFrame) else edge_features_campaign_channel\n",
    "edge_attr_campaign_clicks = torch.tensor(edge_features_campaign_clicks.values, dtype=torch.float) if isinstance(edge_features_campaign_clicks, pd.DataFrame) else edge_features_campaign_clicks\n",
    "\n",
    "# Pad edge features to have the same number of columns\n",
    "edge_attr_campaign_platform, edge_attr_campaign_channel, edge_attr_campaign_clicks = pad_edge_features(\n",
    "    edge_attr_campaign_platform, edge_attr_campaign_channel, edge_attr_campaign_clicks\n",
    ")\n",
    "\n",
    "# Concatenate edge features after padding\n",
    "edge_attr = torch.cat([edge_attr_campaign_platform, edge_attr_campaign_channel, edge_attr_campaign_clicks], dim=0)\n",
    "\n",
    "# Check the shape of concatenated edge features\n",
    "print(edge_attr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define edge_index (source and target nodes)\n",
    "edge_index = torch.cat([edge_index_campaign_platform, edge_index_campaign_advertiser, edge_index_creative_campaign,\n",
    "                        edge_index_campaign_time, edge_index_campaign_channel, edge_index_campaign_network,\n",
    "                        edge_index_campaign_landingpage, edge_index_campaign_keyword], dim=1)  # Add all edge indices\n",
    "\n",
    "# Define edge attributes (edge features)\n",
    "edge_attr = torch.cat([edge_attr_campaign_platform, edge_attr_campaign_channel, edge_attr_campaign_clicks ], dim=0)\n",
    "\n",
    "# Combine node features into one tensor\n",
    "node_features = torch.cat([campaign, platform, advertiser, creative, time, channel, network, landing_page, keyword], dim=0)\n",
    "\n",
    "# Create the data object\n",
    "data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 64)  # First GCN layer\n",
    "        self.conv2 = GCNConv(64, out_channels)  # Second GCN layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = self.conv1(x, edge_index, edge_attr)  # Apply the first GCN layer\n",
    "        x = x.relu()  # Apply ReLU activation\n",
    "        x = self.conv2(x, edge_index, edge_attr)  # Apply the second GCN layer\n",
    "        return x  # Output node embeddings (or logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [553600] at index 0 does not match the shape of the indexed tensor [207600, 4] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass the data to the model\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Assuming you're performing a classification task, use the labels in data.y\u001b[39;00m\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, data\u001b[38;5;241m.\u001b[39my)  \u001b[38;5;66;03m# 'data.y' should contain your target labels\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[89], line 12\u001b[0m, in \u001b[0;36mGNNModel.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m     11\u001b[0m     x, edge_index, edge_attr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39medge_attr\n\u001b[1;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Apply the first GCN layer\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mrelu()  \u001b[38;5;66;03m# Apply ReLU activation\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index, edge_attr)  \u001b[38;5;66;03m# Apply the second GCN layer\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    239\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 241\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:99\u001b[0m, in \u001b[0;36mgcn_norm\u001b[1;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m num_nodes \u001b[38;5;241m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[1;32m---> 99\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), ), dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    104\u001b[0m                              device\u001b[38;5;241m=\u001b[39medge_index\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\utils\\loop.py:642\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[1;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[0;32m    638\u001b[0m     loop_attr \u001b[38;5;241m=\u001b[39m compute_loop_attr(  \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    639\u001b[0m         edge_index, edge_attr, N, \u001b[38;5;28;01mFalse\u001b[39;00m, fill_value)\n\u001b[0;32m    641\u001b[0m     inv_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mmask\n\u001b[1;32m--> 642\u001b[0m     loop_attr[edge_index[\u001b[38;5;241m0\u001b[39m][inv_mask]] \u001b[38;5;241m=\u001b[39m \u001b[43medge_attr\u001b[49m\u001b[43m[\u001b[49m\u001b[43minv_mask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    644\u001b[0m     edge_attr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edge_attr[mask], loop_attr], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    646\u001b[0m is_undirected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: The shape of the mask [553600] at index 0 does not match the shape of the indexed tensor [207600, 4] at index 0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Initialize the model\n",
    "model = GNNModel(in_channels=node_features.shape[1], out_channels=1)  # Single output for regression (number of clicks)\n",
    "\n",
    "# Define optimizer and loss function for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()  # Use Mean Squared Error (MSE) for regression\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100  # Adjust as needed\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    out = model(data)  # Pass the data to the model\n",
    "    \n",
    "    # Assuming you're predicting number of clicks, use the labels in data.y\n",
    "    loss = criterion(out.squeeze(), data.y)  # 'data.y' contains the target labels (number of clicks)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every few epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of tensor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtensor\u001b[49m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of mask: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmask\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensor' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Shape of mask: {mask.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
