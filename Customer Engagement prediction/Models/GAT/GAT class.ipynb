{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv\n",
    "\n",
    "\n",
    "df = pd.read_csv('../Datasets/processed_data.csv')\n",
    "df_advertiser = pd.read_csv('../Datasets/advertiser_embeddings.csv')\n",
    "df_keywords = pd.read_csv('../Datasets/keyword_embeddings.csv')\n",
    "df_search_tags = pd.read_csv('../Datasets/search_tag_embeddings.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_advertiser, df_keywords, df_search_tags], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "# Initialize graph\n",
    "data = HeteroData()\n",
    "\n",
    "# Node ID mappings\n",
    "campaign_mapping = {}  # {campaign_id: index}\n",
    "platform_mapping = {}  # {platform_id: index}\n",
    "channel_mapping = {}  # {channel_id: index}\n",
    "advertiser_mapping = {}  # {advertiser_word: index}\n",
    "keywords_mapping = {}  # {keyword: index}\n",
    "search_tags_mapping = {}  # {search_tag: index}\n",
    "\n",
    "\n",
    "\n",
    "# Unique ID counters\n",
    "campaign_counter = 0\n",
    "platform_counter = 0\n",
    "channel_counter = 0\n",
    "advertiser_counter = 0\n",
    "keywords_counter = 0\n",
    "search_tags_counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mapping(mapping, key, counter):\n",
    "    \"\"\"Ensure new inputs are added to the mapping with unique indices.\"\"\"\n",
    "    if key not in mapping:\n",
    "        mapping[key] = counter\n",
    "        counter += 1\n",
    "    return mapping[key], counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with any NaN values in any column\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Campaign Nodes\n",
    "### Each campaign treated as single entity across different rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_features = []  \n",
    "campaign_counter = len(campaign_mapping)  # Start from existing mappings\n",
    "\n",
    "for _, row in df[['campaign_index', 'no_of_days']].iterrows():\n",
    "    campaign_id = row['campaign_index']\n",
    "    features = row['no_of_days']\n",
    "\n",
    "    campaign_id, campaign_counter = update_mapping(campaign_mapping, campaign_id, campaign_counter)\n",
    "    campaign_features.append([features])  \n",
    "\n",
    "data['campaign'].x = torch.tensor(campaign_features, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Platform Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_data = df[['DV360', 'Facebook Ads', 'Google Ads']]\n",
    "# Convert to tensor format\n",
    "platform_features = torch.tensor(platform_data.values, dtype=torch.float)\n",
    "# data['platform'] is the platform node feature storage\n",
    "data['platform'].x = platform_features\n",
    "\n",
    "# Assign unique indices\n",
    "platform_mapping = {'DV360': 0, 'Google Ads': 1, 'Facebook Ads': 2}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel  Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data = df[['Display','Mobile','Search','Social','Video']].values\n",
    "# Convert to tensor format\n",
    "channel_features = torch.tensor(channel_data, dtype=torch.float)\n",
    "data['channel'].x = channel_features\n",
    "\n",
    "# Assign unique indices\n",
    "channel_mapping = {'Display': 4,'Mobile': 0, 'Search': 1, 'Social': 2, 'Video': 3}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advertiser Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "advertiser_mapping = {}  # Initialize the mapping\n",
    "advertiser_counter = 0  # Initialize the counter for unique advertiser indices\n",
    "\n",
    "advertiser_features = []  # Store advertiser embeddings\n",
    "\n",
    "for _, row in df[['advertiser_name'] + [f'advertiser_emb_{i}' for i in range(50)]].iterrows():\n",
    "    advertiser_name = str(row['advertiser_name'])  # Convert to string to avoid \"unhashable type: Series\"\n",
    "    embedding = row[[f'advertiser_emb_{i}' for i in range(50)]].values  \n",
    "\n",
    "    # Ensure the advertiser is mapped and assign a unique index\n",
    "    if advertiser_name not in advertiser_mapping:\n",
    "        advertiser_mapping[advertiser_name] = advertiser_counter\n",
    "        advertiser_counter += 1\n",
    "\n",
    "    advertiser_features.append(embedding)\n",
    "\n",
    "# Store the embeddings in the data structure\n",
    "data['advertiser'].x = torch.tensor(advertiser_features, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([58930, 50])\n"
     ]
    }
   ],
   "source": [
    "print(data['advertiser'].x.shape)  # Expected: (58930, 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_features = []  \n",
    "keywords_counter = len(keywords_mapping)  \n",
    "\n",
    "for _, row in df[['keyword'] + [f'keyword_emb_{i}' for i in range(50)]].iterrows():\n",
    "    keyword = row['keyword']\n",
    "    embedding = row[[f'keyword_emb_{i}' for i in range(50)]].values  \n",
    "\n",
    "    keyword, keywords_counter = update_mapping(keywords_mapping, keyword, keywords_counter)\n",
    "    keyword_features.append(embedding)\n",
    "\n",
    "data['keyword'].x = torch.tensor(keyword_features, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creative Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "creative_data = df[['has_image']]\n",
    "# Convert to tensor format\n",
    "creative_features = torch.tensor(creative_data.values, dtype=torch.float)\n",
    "\n",
    "# Assign to creative nodes\n",
    "data['creative'].x = creative_features  # Assign binary feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([58930, 1])\n"
     ]
    }
   ],
   "source": [
    "print(data['creative'].x.shape)  # Expected: (58930, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search tag Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag_features = []  \n",
    "search_tags_counter = len(search_tags_mapping)  \n",
    "\n",
    "for _, row in df[['search_tag'] + [f'search_tag_emb_{i}' for i in range(50)]].iterrows():\n",
    "    search_tag = row['search_tag']\n",
    "    embedding = row[[f'search_tag_emb_{i}' for i in range(50)]].values  \n",
    "\n",
    "    search_tag, search_tags_counter = update_mapping(search_tags_mapping, search_tag, search_tags_counter)\n",
    "    search_tag_features.append(embedding)\n",
    "\n",
    "data['search_tag'].x = torch.tensor(search_tag_features, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âž¤ Campaign â†’ Platform Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_platform_edges = []\n",
    "campaign_platform_data = []\n",
    "\n",
    "\n",
    "# Iterate over your dataset (df_filtered) and get campaign_id and platform\n",
    "for index, row in df.iterrows():\n",
    "    campaign_id = row['campaign_index']  # Get campaign_id\n",
    "    platform_name = row['platform']   # Get platform name\n",
    "    campaign_platform_data.append([campaign_id, platform_name])  # Add to list\n",
    "\n",
    "for campaign_id, platform_name in campaign_platform_data:  # (campaign_id, platform_name)\n",
    "    campaign_idx = campaign_mapping[campaign_id]\n",
    "    platform_idx = platform_mapping[platform_name]\n",
    "\n",
    "    campaign_platform_edges.append([campaign_idx, platform_idx])\n",
    "\n",
    "platform_campaign_edges = [[platform_idx, campaign_idx] for campaign_idx, platform_idx in campaign_platform_edges]\n",
    "data['platform', 'rev_hosted_on', 'campaign'].edge_index = torch.tensor(platform_campaign_edges, dtype=torch.long).T\n",
    "data['campaign', 'hosted_on', 'platform'].edge_index = torch.tensor(campaign_platform_edges, dtype=torch.long).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âž¤ Campaign â†’ Channel Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_channel_edges = []\n",
    "campaign_channel_data = []\n",
    "\n",
    "# Iterate over your dataset (df_filtered) and get campaign_id and channel\n",
    "for index, row in df.iterrows():\n",
    "    campaign_id = row['campaign_index']  # Get campaign_id\n",
    "    channel_name = row['channel_name']   # Get channel name\n",
    "    campaign_channel_data.append([campaign_id, channel_name])  # Add to list\n",
    "\n",
    "for campaign_id, channel_name in campaign_channel_data:  # (campaign_id, channel_name)\n",
    "    campaign_idx = campaign_mapping[campaign_id]\n",
    "    channel_idx = channel_mapping[channel_name]\n",
    "\n",
    "    campaign_channel_edges.append([campaign_idx, channel_idx])\n",
    "\n",
    "channel_campaign_edges = [[channel_idx, campaign_idx] for campaign_idx, channel_idx in campaign_channel_edges]\n",
    "data['channel', 'rev_uses', 'campaign'].edge_index = torch.tensor(channel_campaign_edges, dtype=torch.long).T\n",
    "data['campaign', 'uses', 'channel'].edge_index = torch.tensor(campaign_channel_edges, dtype=torch.long).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âž¤ Campaign â†’ Advertiser Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_advertiser_edges = []\n",
    "campaign_advertiser_data = []\n",
    "\n",
    "# Iterate over your dataset (df_filtered) and get campaign_id and advertiser_name\n",
    "for index, row in df.iterrows():\n",
    "    campaign_id = row['campaign_index']  # Get campaign_id\n",
    "    advertiser_name = str(row['advertiser_name'])\n",
    "    campaign_advertiser_data.append([campaign_id, advertiser_name])  # Add to list\n",
    "\n",
    "for campaign_id, advertiser_name in campaign_advertiser_data:  # (campaign_id, advertiser_name)\n",
    "    campaign_idx = campaign_mapping[campaign_id]  # Ensure campaign mapping is valid\n",
    "    if advertiser_name not in advertiser_mapping:\n",
    "        raise KeyError(f\"Advertiser '{advertiser_name}' not found in advertiser mapping.\")\n",
    "    advertiser_idx = advertiser_mapping[advertiser_name]  # Map advertiser name to index\n",
    "    campaign_advertiser_edges.append([campaign_idx, advertiser_idx])\n",
    "\n",
    "advertiser_campaign_edges = [[advertiser_idx, campaign_idx] for campaign_idx, advertiser_idx in campaign_advertiser_edges]\n",
    "data['advertiser', 'rev_belongs_to', 'campaign'].edge_index = torch.tensor(advertiser_campaign_edges, dtype=torch.long).T\n",
    "data['campaign', 'belongs_to', 'advertiser'].edge_index = torch.tensor(campaign_advertiser_edges, dtype=torch.long).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âž¤ Campaign â†’ keywords Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_keywords_edges = []\n",
    "campaign_keywords_data = []\n",
    "\n",
    "# Iterate over your dataset (df_filtered) and get campaign_id and keywords\n",
    "for index, row in df.iterrows():\n",
    "    campaign_id = row['campaign_index']  # Get campaign_id\n",
    "    keywords = row['keywords']   # Get keywords name\n",
    "    campaign_keywords_data.append([campaign_id, keywords])  # Add to list\n",
    "\n",
    "for campaign_id, keywords in campaign_keywords_data:  # (campaign_id, keywords)\n",
    "    campaign_idx = campaign_mapping[campaign_id]\n",
    "    keywords_idx = keywords_mapping[keywords]\n",
    "    campaign_keywords_edges.append([campaign_idx, keywords_idx])\n",
    "\n",
    "keywords_campaign_edges = [[keywords_idx, campaign_idx] for campaign_idx, keywords_idx in campaign_keywords_edges]\n",
    "data['keyword', 'rev_associated_with', 'campaign'].edge_index = torch.tensor(keywords_campaign_edges, dtype=torch.long).T\n",
    "data['campaign', 'associated_with', 'keyword'].edge_index = torch.tensor(campaign_keywords_edges, dtype=torch.long).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âž¤ Campaign â†’ Creative Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_creates_edges = []\n",
    "campaign_creates_data = []\n",
    "\n",
    "# Iterate over your dataset (df_filtered) and get campaign_id and creative\n",
    "for index, row in df.iterrows():\n",
    "    campaign_id = row['campaign_index']  # Get campaign_id\n",
    "    creative = row['has_image']   # Get creative\n",
    "    campaign_creates_data.append([campaign_id, creative])  # Add to list\n",
    "\n",
    "for campaign_id, creative in campaign_creates_data:  # (campaign_id, creative)\n",
    "    campaign_idx = campaign_mapping[campaign_id]\n",
    "\n",
    "    campaign_creates_edges.append([campaign_idx, creative])\n",
    "\n",
    "creative_campaign_edges = [[creative, campaign_idx] for campaign_idx, creative in campaign_creates_edges]\n",
    "data['creative', 'rev_uses', 'campaign'].edge_index = torch.tensor(creative_campaign_edges, dtype=torch.long).T\n",
    "data['campaign', 'uses', 'creative'].edge_index = torch.tensor(campaign_creates_edges, dtype=torch.long).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âž¤ Platform â†’ Channel Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_channel_data = {\n",
    "    'DV360': ['Display', 'Mobile', 'Search', 'Social', 'Video'],\n",
    "    'Google Ads': ['Display', 'Mobile', 'Search', 'Social', 'Video'],\n",
    "    'Facebook Ads': ['Display', 'Mobile', 'Search', 'Social', 'Video']\n",
    "}\n",
    "\n",
    "# List to store platform-channel edges\n",
    "platform_channel_edges = []\n",
    "\n",
    "# Iterate over the platform-channel relationships\n",
    "for platform, channels in platform_channel_data.items():\n",
    "    # Get the platform index\n",
    "    platform_idx = platform_mapping[platform]\n",
    "    \n",
    "    # Iterate over the channels associated with this platform\n",
    "    for channel in channels:\n",
    "        # Get the channel index\n",
    "        channel_idx = channel_mapping[channel]\n",
    "        \n",
    "        # Add the edge (platform -> channel)\n",
    "        platform_channel_edges.append([platform_idx, channel_idx])\n",
    "\n",
    "# Convert to tensor and assign to the graph\n",
    "data['platform', 'supports', 'channel'].edge_index = torch.tensor(platform_channel_edges, dtype=torch.long).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âž¤ Campaign â†’ Search tag Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_searchtag_edges = []\n",
    "campaign_searchtag_data = []\n",
    "\n",
    "# Iterate over your dataset (df_filtered) and get campaign_id and keywords\n",
    "for index, row in df.iterrows():\n",
    "    campaign_id = row['campaign_index']  # Get campaign_id\n",
    "    search_tag = row['search_tags']   # Get keywords name\n",
    "    campaign_searchtag_data.append([campaign_id, search_tag])  # Add to list\n",
    "\n",
    "for campaign_id, keywords in campaign_searchtag_data:  # (campaign_id, keywords)\n",
    "    campaign_idx = campaign_mapping[campaign_id]\n",
    "    search_tag_idx = search_tags_mapping[search_tag]\n",
    "    campaign_searchtag_edges.append([campaign_idx, search_tag_idx])\n",
    "\n",
    "searchtag_campaign_edges = [[search_tag_idx, campaign_idx] for campaign_idx, search_tag_idx in campaign_searchtag_edges]\n",
    "data['search_tag', 'rev_targeted_by', 'campaign'].edge_index = torch.tensor(searchtag_campaign_edges, dtype=torch.long).T\n",
    "data['campaign', 'targeted_by', 'search_tag'].edge_index = torch.tensor(campaign_searchtag_edges, dtype=torch.long).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âž¤ Platform â†’ Keywords Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Facebook Ads': ['affordable jewelry', 'elegant jewelry', 'seashell jewelry', 'cuff bracelets', 'holiday jewelry', 'unique jewelry', 'dazzling jewelry', 'jewelry sets', 'boho jewelry', 'statement jewelry', 'cocktail rings', 'beaded jewelry', 'bold jewelry', 'toe rings', 'vintage-inspired jewelry', 'handcrafted jewelry', 'ear cuffs', 'zodiac jewelry', 'formal jewelry', 'mixed metal jewelry', 'choker necklaces', 'exquisite jewelry', 'pearl jewelry', 'wedding jewelry', 'dainty jewelry', 'whimsical jewelry', 'bangles', 'affordable statement jewelry', 'stackable bracelets', 'artisan jewelry', 'fall jewelry', 'fashion brooches', 'minimalistic jewelry', 'pendant necklaces', 'layered bracelets', 'hoop earrings', 'anklets', 'charm bracelets', 'handmade jewelry', 'retro jewelry', 'initial jewelry', 'casual chic jewelry', 'threader earrings', 'nature-inspired jewelry', 'artisanal jewelry', 'fashion jewelry for women', 'body chains', 'animal jewelry', 'beaded bracelets', 'festival jewelry', 'personalized jewelry', 'chunky jewelry', 'seasonal jewelry', 'body piercings', 'party jewelry', 'baroque jewelry', 'fashionable jewelry', 'costume jewelry', 'religious jewelry', 'minimalist jewelry', 'trendy and timeless jewelry', 'elegant and modern jewelry', 'affordable luxury jewelry', 'statement pins', 'statement rings', 'bridal jewelry', 'tassel earrings', 'dangle earrings', 'bohemian jewelry', 'tribal jewelry', 'drop earrings', 'designer-inspired jewelry', 'office jewelry', 'spring jewelry', 'rhinestone jewelry', 'art deco jewelry', 'renaissance jewelry', 'multi-strand necklaces', 'affordable trendy jewelry', 'stud earrings', 'hair accessories', 'layered jewelry', 'chic jewelry', 'vintage jewelry', 'modern jewelry', 'beach jewelry', 'concert jewelry', 'delicate bracelets', 'victorian jewelry', 'long necklaces', 'crystal jewelry', 'edwardian jewelry', 'trendy jewelry', 'midi rings', 'statement necklaces', 'body jewelry', 'costume jewelry sets', 'gemstone jewelry', 'art nouveau jewelry', 'chic and affordable jewelry', 'everyday jewelry', 'brooches', 'huggie earrings', 'vibrant jewelry', 'layered earrings', 'sophisticated jewelry', 'winter jewelry', 'colorful jewelry', 'glamorous jewelry', 'layered necklaces', 'birthstone jewelry', 'summer jewelry', 'funky jewelry', 'arm cuffs', 'clip-on earrings', 'luxury jewelry', 'unique and trendy jewelry', 'casual jewelry'], 'DV360': ['affordable jewelry', 'elegant jewelry', 'seashell jewelry', 'cuff bracelets', 'holiday jewelry', 'unique jewelry', 'dazzling jewelry', 'jewelry sets', 'boho jewelry', 'statement jewelry', 'cocktail rings', 'beaded jewelry', 'toe rings', 'bold jewelry', 'vintage-inspired jewelry', 'handcrafted jewelry', 'zodiac jewelry', 'ear cuffs', 'formal jewelry', 'mixed metal jewelry', 'choker necklaces', 'exquisite jewelry', 'pearl jewelry', 'wedding jewelry', 'whimsical jewelry', 'dainty jewelry', 'bangles', 'affordable statement jewelry', 'stackable bracelets', 'artisan jewelry', 'fall jewelry', 'fashion brooches', 'minimalistic jewelry', 'pendant necklaces', 'layered bracelets', 'anklets', 'hoop earrings', 'charm bracelets', 'handmade jewelry', 'retro jewelry', 'initial jewelry', 'threader earrings', 'nature-inspired jewelry', 'artisanal jewelry', 'fashion jewelry for women', 'body chains', 'animal jewelry', 'beaded bracelets', 'festival jewelry', 'personalized jewelry', 'chunky jewelry', 'seasonal jewelry', 'body piercings', 'party jewelry', 'baroque jewelry', 'fashionable jewelry', 'costume jewelry', 'religious jewelry', 'minimalist jewelry', 'trendy and timeless jewelry', 'elegant and modern jewelry', 'affordable luxury jewelry', 'statement pins', 'statement rings', 'casual jewelry', 'bridal jewelry', 'tassel earrings', 'dangle earrings', 'bohemian jewelry', 'tribal jewelry', 'drop earrings', 'designer-inspired jewelry', 'office jewelry', 'spring jewelry', 'rhinestone jewelry', 'art deco jewelry', 'renaissance jewelry', 'multi-strand necklaces', 'affordable trendy jewelry', 'stud earrings', 'hair accessories', 'layered jewelry', 'vintage jewelry', 'chic jewelry', 'modern jewelry', 'beach jewelry', 'concert jewelry', 'delicate bracelets', 'victorian jewelry', 'long necklaces', 'crystal jewelry', 'edwardian jewelry', 'trendy jewelry', 'midi rings', 'statement necklaces', 'body jewelry', 'costume jewelry sets', 'gemstone jewelry', 'art nouveau jewelry', 'chic and affordable jewelry', 'everyday jewelry', 'brooches', 'huggie earrings', 'layered earrings', 'vibrant jewelry', 'sophisticated jewelry', 'winter jewelry', 'colorful jewelry', 'glamorous jewelry', 'layered necklaces', 'birthstone jewelry', 'summer jewelry', 'funky jewelry', 'arm cuffs', 'clip-on earrings', 'luxury jewelry', 'unique and trendy jewelry', 'casual chic jewelry'], 'Google Ads': ['affordable jewelry', 'elegant jewelry', 'seashell jewelry', 'cuff bracelets', 'holiday jewelry', 'unique jewelry', 'jewelry sets', 'dazzling jewelry', 'boho jewelry', 'statement jewelry', 'cocktail rings', 'beaded jewelry', 'bold jewelry', 'toe rings', 'vintage-inspired jewelry', 'handcrafted jewelry', 'zodiac jewelry', 'ear cuffs', 'formal jewelry', 'mixed metal jewelry', 'choker necklaces', 'exquisite jewelry', 'pearl jewelry', 'wedding jewelry', 'whimsical jewelry', 'dainty jewelry', 'affordable statement jewelry', 'bangles', 'stackable bracelets', 'artisan jewelry', 'fall jewelry', 'fashion brooches', 'minimalistic jewelry', 'pendant necklaces', 'layered bracelets', 'hoop earrings', 'anklets', 'charm bracelets', 'handmade jewelry', 'retro jewelry', 'initial jewelry', 'threader earrings', 'nature-inspired jewelry', 'artisanal jewelry', 'fashion jewelry for women', 'body chains', 'animal jewelry', 'beaded bracelets', 'festival jewelry', 'personalized jewelry', 'chunky jewelry', 'seasonal jewelry', 'body piercings', 'baroque jewelry', 'party jewelry', 'fashionable jewelry', 'costume jewelry', 'religious jewelry', 'minimalist jewelry', 'affordable luxury jewelry', 'elegant and modern jewelry', 'trendy and timeless jewelry', 'statement pins', 'statement rings', 'casual jewelry', 'bridal jewelry', 'tassel earrings', 'dangle earrings', 'bohemian jewelry', 'tribal jewelry', 'drop earrings', 'designer-inspired jewelry', 'office jewelry', 'spring jewelry', 'rhinestone jewelry', 'art deco jewelry', 'renaissance jewelry', 'multi-strand necklaces', 'affordable trendy jewelry', 'stud earrings', 'hair accessories', 'layered jewelry', 'chic jewelry', 'vintage jewelry', 'modern jewelry', 'beach jewelry', 'concert jewelry', 'delicate bracelets', 'victorian jewelry', 'long necklaces', 'crystal jewelry', 'edwardian jewelry', 'trendy jewelry', 'midi rings', 'statement necklaces', 'body jewelry', 'costume jewelry sets', 'gemstone jewelry', 'art nouveau jewelry', 'chic and affordable jewelry', 'everyday jewelry', 'brooches', 'huggie earrings', 'vibrant jewelry', 'layered earrings', 'sophisticated jewelry', 'winter jewelry', 'colorful jewelry', 'glamorous jewelry', 'layered necklaces', 'birthstone jewelry', 'summer jewelry', 'funky jewelry', 'arm cuffs', 'clip-on earrings', 'luxury jewelry', 'unique and trendy jewelry', 'casual chic jewelry']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the data from the JSON file\n",
    "with open('../Datasets/platform_keyword_data.json', 'r') as f:\n",
    "    platform_keyword_data = json.load(f)\n",
    "\n",
    "print(platform_keyword_data)  # You can now use this data in your program\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_keyword_edges = []\n",
    "\n",
    "# Iterate over the platform-to-keyword relationships\n",
    "for platform, keywords in platform_keyword_data.items():\n",
    "    # Get the platform index\n",
    "    platform_idx = platform_mapping[platform]\n",
    "\n",
    "    # Iterate over the associated keywords\n",
    "    for keyword in keywords:\n",
    "        # Get the keyword index\n",
    "        keyword_idx = keywords_mapping[keyword]\n",
    "\n",
    "        # Add the edge (platform -> keyword)\n",
    "        platform_keyword_edges.append([platform_idx, keyword_idx])\n",
    "\n",
    "# Convert to tensor and assign to the graph\n",
    "data['platform', 'optimized_for', 'keyword'].edge_index = torch.tensor(platform_keyword_edges, dtype=torch.long).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where engagement_level is NaN\n",
    "df = df.dropna(subset=['engagement_level'])\n",
    "\n",
    "# Extract engagement levels for each unique campaign-feature instance (row-wise)\n",
    "engagement_labels = torch.tensor(df['engagement_level'].values, dtype=torch.long)\n",
    "\n",
    "# Assign each instance's engagement level as its target\n",
    "data['campaign'].y = engagement_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campaign labels shape: torch.Size([58930])\n"
     ]
    }
   ],
   "source": [
    "# print(f\"Campaign features shape: {campaign_features.shape}\")  # Should be (58930, feature_dim)\n",
    "print(f\"Campaign labels shape: {data['campaign'].y.shape}\")  # Should match the number of campaign features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, HeteroConv\n",
    "\n",
    "class EngagementGNN(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_channels, out_channels):\n",
    "        super(EngagementGNN, self).__init__()\n",
    "\n",
    "        # Convert all node features to the same size\n",
    "        self.feature_transforms = torch.nn.ModuleDict({\n",
    "            'campaign': torch.nn.Linear(1, hidden_channels),  # Project scalar feature\n",
    "            'platform': torch.nn.Linear(3, hidden_channels),  # Project one-hot to hidden size\n",
    "            'channel': torch.nn.Linear(5, hidden_channels),\n",
    "            'advertiser': torch.nn.Linear(50, hidden_channels),\n",
    "            'keyword': torch.nn.Linear(50, hidden_channels),\n",
    "            'creative': torch.nn.Linear(1, hidden_channels),  # Project scalar feature\n",
    "            'search_tag': torch.nn.Linear(50, hidden_channels),\n",
    "        })\n",
    "        \n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.metadata = metadata  # Store metadata for use in forward()\n",
    "        \n",
    "        # Create GAT layers for each edge type\n",
    "        self.convs = HeteroConv({\n",
    "            edge_type: GATConv(in_channels, hidden_channels, heads=4, concat=True, add_self_loops=False)\n",
    "            for edge_type, (in_channels, _) in metadata['edge_dim'].items()\n",
    "        })\n",
    "        \n",
    "        # Final linear layer for classification\n",
    "        self.out = torch.nn.ModuleDict({\n",
    "            node_type: torch.nn.Linear(hidden_channels * 4, out_channels)\n",
    "            for node_type in metadata['node_types']\n",
    "        })\n",
    "\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        \n",
    "        # Apply feature transformation to each node type\n",
    "        x_dict = {node: self.feature_transforms[node](feat) for node, feat in x_dict.items()}\n",
    "        # Apply GAT layers on heterogeneous graph\n",
    "        x_dict = self.convs(x_dict, edge_index_dict)\n",
    "        out_dict = {node: self.out[node](x_dict[node]) for node in x_dict}\n",
    "\n",
    "        return out_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, labels):\n",
    "    _, predicted = torch.max(predictions, dim=1)  # Get the predicted class\n",
    "    correct = (predicted == labels).sum()  # Count the number of correct predictions\n",
    "    accuracy = correct / len(labels)  # Accuracy as a fraction\n",
    "    return accuracy.item()  # Return as a scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "\n",
    "# Define training function\n",
    "def train(model, data, optimizer, criterion, epochs=100):\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    loss_values = []\n",
    "    accuracy_values = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Collect node features dynamically\n",
    "        node_features = {node_type: data[node_type].x for node_type in data.node_types}\n",
    "\n",
    "        # Collect edge indices dynamically\n",
    "        edge_index_dict = {edge_type: data[edge_type].edge_index for edge_type in data.edge_types}\n",
    "\n",
    "        # Forward pass with node features & edge index\n",
    "        out_dict = model(node_features, edge_index_dict)\n",
    "\n",
    "        total_loss = 0\n",
    "        total_accuracy = 0\n",
    "        count = 0\n",
    "\n",
    "        for node_type in data.node_types:\n",
    "            if hasattr(data[node_type], 'y'):  # Ensure the node type has labels\n",
    "                node_output = out_dict[node_type]  # Get predictions for the node type\n",
    "                node_labels = data[node_type].y  # True labels\n",
    "\n",
    "                loss = criterion(node_output, node_labels)\n",
    "                total_loss += loss\n",
    "\n",
    "                # Compute accuracy for this node type\n",
    "                accuracy = compute_accuracy(node_output, node_labels)\n",
    "                total_accuracy += accuracy\n",
    "                count += 1\n",
    "\n",
    "                # Get predictions and labels for classification report\n",
    "                predictions = torch.argmax(node_output, dim=1).cpu().numpy()\n",
    "                labels = node_labels.cpu().numpy()\n",
    "\n",
    "                all_predictions.extend(predictions)\n",
    "                all_labels.extend(labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Average loss and accuracy\n",
    "        avg_loss = total_loss.item() / count\n",
    "        avg_accuracy = total_accuracy / count\n",
    "\n",
    "        loss_values.append(avg_loss)\n",
    "        accuracy_values.append(avg_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.4f}\")\n",
    "\n",
    "    # Final classification report\n",
    "    print(\"\\nFinal Classification Report:\")\n",
    "    print(classification_report(all_labels, all_predictions))\n",
    "\n",
    "    # Plot loss and accuracy over epochs\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(epochs), loss_values, label='Loss', color='blue')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(epochs), accuracy_values, label='Accuracy', color='green')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Types: ['campaign', 'platform', 'channel', 'advertiser', 'keyword', 'creative', 'search_tag']\n",
      "Edge Types: [('platform', 'rev_hosted_on', 'campaign'), ('campaign', 'hosted_on', 'platform'), ('channel', 'rev_uses', 'campaign'), ('campaign', 'uses', 'channel'), ('advertiser', 'rev_belongs_to', 'campaign'), ('campaign', 'belongs_to', 'advertiser'), ('keyword', 'rev_associated_with', 'campaign'), ('campaign', 'associated_with', 'keyword'), ('creative', 'rev_uses', 'campaign'), ('campaign', 'uses', 'creative'), ('platform', 'supports', 'channel'), ('search_tag', 'rev_targeted_by', 'campaign'), ('campaign', 'targeted_by', 'search_tag'), ('platform', 'optimized_for', 'keyword')]\n",
      "Epoch 1/100, Loss: 0.6931, Accuracy: 0.5131\n",
      "Epoch 2/100, Loss: 0.6930, Accuracy: 0.5132\n",
      "Epoch 3/100, Loss: 0.6929, Accuracy: 0.5131\n",
      "Epoch 4/100, Loss: 0.6929, Accuracy: 0.5131\n",
      "Epoch 5/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 6/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 7/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 8/100, Loss: 0.6928, Accuracy: 0.5133\n",
      "Epoch 9/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 10/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 11/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 12/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 13/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 14/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 15/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 16/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 17/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 18/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 19/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 20/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 21/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 22/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 23/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 24/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 25/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 26/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 27/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 28/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 29/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 30/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 31/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 32/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 33/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 34/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 35/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 36/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 37/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 38/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 39/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 40/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 41/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 42/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 43/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 44/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 45/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 46/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 47/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 48/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 49/100, Loss: 0.6928, Accuracy: 0.5132\n",
      "Epoch 50/100, Loss: 0.6928, Accuracy: 0.5132\n"
     ]
    }
   ],
   "source": [
    "node_types, edge_types = data.metadata()  # Unpack the tuple\n",
    "\n",
    "# Check output to confirm\n",
    "print(\"Node Types:\", node_types)  # List of nodes\n",
    "print(\"Edge Types:\", edge_types)  # List of edges\n",
    "\n",
    "# Now manually construct metadata the way the model expects\n",
    "metadata = {\n",
    "    'node_types': node_types,\n",
    "    'edge_types': edge_types,\n",
    "    'edge_dim': {edge: (64, 8) for edge in edge_types}  # Example, adjust dimensions as needed\n",
    "}\n",
    "\n",
    "# Now it should work\n",
    "model = EngagementGNN(metadata=metadata, hidden_channels=64, out_channels=2)\n",
    "\n",
    "# Optimizer & Loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "train(model, data, optimizer, criterion, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def process_user_input(user_input):\n",
    "    \"\"\"\n",
    "    Convert user inputs into numerical tensors for prediction.\n",
    "    \n",
    "    Args:\n",
    "    user_input (dict): Dictionary containing user-provided values.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with tensors formatted for model input.\n",
    "    \"\"\"\n",
    "\n",
    "    # ðŸ”¹ Retrieve Campaign Index (Ensure it's valid)\n",
    "    campaign_idx = campaign_mapping.get(user_input['campaign'], None)\n",
    "    if campaign_idx is None:\n",
    "        raise KeyError(f\"Campaign ID {user_input['campaign']} not found in mapping!\")\n",
    "\n",
    "    # ðŸ”¹ Campaign Features (MUST include campaign index + no_of_days)\n",
    "    campaign_features = [campaign_idx, user_input['no_of_days']]  # FIXED\n",
    "\n",
    "    # ðŸ”¹ One-hot encode platform\n",
    "    platform_vector = [0, 0, 0]\n",
    "    if user_input['platform'] in platform_mapping:\n",
    "        platform_vector[platform_mapping[user_input['platform']]] = 1\n",
    "    else:\n",
    "        print(f\"Warning: Platform '{user_input['platform']}' not found in mapping.\")\n",
    "\n",
    "    # ðŸ”¹ One-hot encode channel\n",
    "    channel_vector = [0, 0, 0, 0, 0]\n",
    "    if user_input['channel'] in channel_mapping:\n",
    "        channel_vector[channel_mapping[user_input['channel']]] = 1\n",
    "    else:\n",
    "        print(f\"Warning: Channel '{user_input['channel']}' not found in mapping.\")\n",
    "\n",
    "    # ðŸ”¹ Advertiser embedding (use existing if available, otherwise random)\n",
    "    advertiser_vector = advertiser_mapping.get(\n",
    "        user_input['advertiser_name'], np.random.rand(50)\n",
    "    )\n",
    "\n",
    "    # ðŸ”¹ Keyword embedding (use existing if available, otherwise random)\n",
    "    keyword_vector = keywords_mapping.get(\n",
    "        user_input['keyword'], np.random.rand(50)\n",
    "    )\n",
    "\n",
    "    # ðŸ”¹ Creative feature (binary)\n",
    "    creative_vector = [user_input['has_image']]\n",
    "\n",
    "    # ðŸ”¹ Search tag embedding (use existing if available, otherwise random)\n",
    "    search_tag_vector = search_tags_mapping.get(\n",
    "        user_input['search_tag'], np.random.rand(50)\n",
    "    )\n",
    "\n",
    "    # ðŸ”¹ Retrieve Node IDs for Edge Index\n",
    "    platform_idx = platform_mapping.get(user_input['platform'], None)\n",
    "    channel_idx = channel_mapping.get(user_input['channel'], None)\n",
    "    advertiser_idx = advertiser_mapping.get(user_input['advertiser_name'], None)\n",
    "    keyword_idx = keywords_mapping.get(user_input['keyword'], None)\n",
    "\n",
    "    # Validate all indices before creating edge index\n",
    "    missing_mappings = []\n",
    "    if platform_idx is None: missing_mappings.append('platform')\n",
    "    if channel_idx is None: missing_mappings.append('channel')\n",
    "    if advertiser_idx is None: missing_mappings.append('advertiser')\n",
    "    if keyword_idx is None: missing_mappings.append('keyword')\n",
    "\n",
    "    if missing_mappings:\n",
    "        raise KeyError(f\"One or more input mappings were not found: {', '.join(missing_mappings)}\")\n",
    "\n",
    "    # ðŸ”¹ Construct Edge Index (Source -> Target)\n",
    "    edge_index = torch.tensor([ \n",
    "        [campaign_idx, platform_idx],   # Campaign -> Platform\n",
    "        [campaign_idx, channel_idx],    # Campaign -> Channel\n",
    "        [campaign_idx, advertiser_idx], # Campaign -> Advertiser\n",
    "        [campaign_idx, keyword_idx]     # Campaign -> Keyword\n",
    "    ], dtype=torch.long).T  # Transpose for PyG format\n",
    "\n",
    "    # Convert all inputs to tensors\n",
    "    input_tensors = {\n",
    "        'campaign': torch.tensor([campaign_features], dtype=torch.float),  # FIXED\n",
    "        'platform': torch.tensor([platform_vector], dtype=torch.float),\n",
    "        'channel': torch.tensor([channel_vector], dtype=torch.float),\n",
    "        'advertiser': torch.tensor([advertiser_vector], dtype=torch.float),\n",
    "        'keyword': torch.tensor([keyword_vector], dtype=torch.float),\n",
    "        'has_image': torch.tensor([creative_vector], dtype=torch.float),\n",
    "        'search_tag': torch.tensor([search_tag_vector], dtype=torch.float),\n",
    "        'edge_index': edge_index\n",
    "    }\n",
    "\n",
    "    return input_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'One or more input mappings were not found: advertiser'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 14\u001b[0m\n\u001b[0;32m      2\u001b[0m user_input \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcampaign\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m13\u001b[39m,  \u001b[38;5;66;03m# Categorical input\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_of_days\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m,  \u001b[38;5;66;03m# Numeric input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_tag\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAthletic\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Mapped to embedding\u001b[39;00m\n\u001b[0;32m     11\u001b[0m }\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Convert input to numeric tensors\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m formatted_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_user_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Display formatted tensors\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m formatted_inputs\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[1;32mIn[61], line 69\u001b[0m, in \u001b[0;36mprocess_user_input\u001b[1;34m(user_input)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keyword_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: missing_mappings\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeyword\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_mappings:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne or more input mappings were not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing_mappings)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# ðŸ”¹ Construct Edge Index (Source -> Target)\u001b[39;00m\n\u001b[0;32m     72\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([ \n\u001b[0;32m     73\u001b[0m     [campaign_idx, platform_idx],   \u001b[38;5;66;03m# Campaign -> Platform\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     [campaign_idx, channel_idx],    \u001b[38;5;66;03m# Campaign -> Channel\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     [campaign_idx, advertiser_idx], \u001b[38;5;66;03m# Campaign -> Advertiser\u001b[39;00m\n\u001b[0;32m     76\u001b[0m     [campaign_idx, keyword_idx]     \u001b[38;5;66;03m# Campaign -> Keyword\u001b[39;00m\n\u001b[0;32m     77\u001b[0m ], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mT  \u001b[38;5;66;03m# Transpose for PyG format\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'One or more input mappings were not found: advertiser'"
     ]
    }
   ],
   "source": [
    "# Example user input (from an API or user form)\n",
    "user_input = {\n",
    "    \"campaign\": 13,  # Categorical input\n",
    "    \"no_of_days\": 10,  # Numeric input\n",
    "    \"platform\": \"Google Ads\",  # One-hot encoded\n",
    "    \"channel\": \"Social\",  # One-hot encoded\n",
    "    \"advertiser_name\": \"Web\",  # Mapped to embedding\n",
    "    \"keyword\": \"bohemian jewelry\",  # Mapped to embedding\n",
    "    \"has_image\": 1,  # Binary feature\n",
    "    \"search_tag\": \"Athletic\"  # Mapped to embedding\n",
    "}\n",
    "\n",
    "# Convert input to numeric tensors\n",
    "formatted_inputs = process_user_input(user_input)\n",
    "\n",
    "# Display formatted tensors\n",
    "for key, value in formatted_inputs.items():\n",
    "    print(f\"{key}: {value.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campaign Mapping: {0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 6.0: 6, 9.0: 7, 10.0: 8, 11.0: 9, 13.0: 10, 12.0: 11, 14.0: 12, 15.0: 13, 16.0: 14, 17.0: 15, 18.0: 16, 19.0: 17, 20.0: 18, 21.0: 19, 22.0: 20, 23.0: 21, 24.0: 22, 26.0: 23, 28.0: 24, 30.0: 25, 31.0: 26, 32.0: 27, 33.0: 28, 34.0: 29, 35.0: 30, 36.0: 31, 38.0: 32, 39.0: 33, 40.0: 34, 41.0: 35, 42.0: 36, 43.0: 37, 45.0: 38, 46.0: 39, 7.0: 40, 48.0: 41, 49.0: 42, 51.0: 43, 54.0: 44, 55.0: 45, 56.0: 46, 57.0: 47, 58.0: 48, 59.0: 49, 61.0: 50, 62.0: 51, 60.0: 52, 8.0: 53, 63.0: 54, 64.0: 55, 65.0: 56, 66.0: 57, 67.0: 58, 68.0: 59, 69.0: 60, 70.0: 61, 71.0: 62, 72.0: 63, 73.0: 64, 74.0: 65, 75.0: 66, 76.0: 67, 77.0: 68, 78.0: 69, 79.0: 70, 80.0: 71, 81.0: 72, 82.0: 73, 83.0: 74, 84.0: 75, 85.0: 76, 86.0: 77, 87.0: 78, 88.0: 79, 89.0: 80, 90.0: 81, 91.0: 82, 92.0: 83, 93.0: 84, 94.0: 85, 95.0: 86, 96.0: 87, 97.0: 88, 98.0: 89, 99.0: 90, 100.0: 91, 101.0: 92, 102.0: 93, 103.0: 94, 104.0: 95, 105.0: 96, 106.0: 97, 107.0: 98}\n",
      "Campaign ID from user: 13\n",
      "Mapped Campaign Index: 98\n"
     ]
    }
   ],
   "source": [
    "print(\"Campaign Mapping:\", campaign_mapping)\n",
    "print(\"Campaign ID from user:\", user_input['campaign'])\n",
    "print(\"Mapped Campaign Index:\", campaign_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform Mapping: {'DV360': 0, 'Google Ads': 1, 'Facebook Ads': 2}\n",
      "User Platform: Google Ads\n",
      "Mapped Platform Index: 1\n",
      "Channel Mapping: {'Display': 4, 'Mobile': 0, 'Search': 1, 'Social': 2, 'Video': 3}\n",
      "User Channel: Social\n",
      "Mapped Channel Index: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Platform Mapping:\", platform_mapping)\n",
    "print(\"User Platform:\", user_input['platform'])\n",
    "print(\"Mapped Platform Index:\", platform_idx)\n",
    "\n",
    "print(\"Channel Mapping:\", channel_mapping)\n",
    "print(\"User Channel:\", user_input['channel'])\n",
    "print(\"Mapped Channel Index:\", channel_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "print(matplotlib.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_engagement(model, input_data):\n",
    "    \"\"\"\n",
    "    Predict engagement level using the trained model.\n",
    "    \n",
    "    Args:\n",
    "    model (torch.nn.Module): Trained GNN model.\n",
    "    input_data (dict): Dictionary containing tensors of user input features.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: Predicted engagement level.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        prediction = model(input_data['campaign'], input_data['edge_index'])  # Pass edge_index\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x2 and 1x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming 'gnn_model' is your trained GNN model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_engagement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatted_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Engagement Level:\u001b[39m\u001b[38;5;124m\"\u001b[39m, prediction\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[1;32mIn[36], line 15\u001b[0m, in \u001b[0;36mpredict_engagement\u001b[1;34m(model, input_data)\u001b[0m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set model to evaluation mode\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# No need to track gradients\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcampaign\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43medge_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass edge_index\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[29], line 19\u001b[0m, in \u001b[0;36mEngagementGNN.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[1;32m---> 19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39melu(x)  \u001b[38;5;66;03m# Activation function\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index)\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gat_conv.py:302\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[1;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[0;32m    299\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres(x)\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 302\u001b[0m     x_src \u001b[38;5;241m=\u001b[39m x_dst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, H, C)\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;66;03m# If the module is initialized as bipartite, transform source\u001b[39;00m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;66;03m# and destination node features separately:\u001b[39;00m\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_src \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_dst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Thinkpad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\nn\\dense\\linear.py:147\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x2 and 1x128)"
     ]
    }
   ],
   "source": [
    "# Assuming 'gnn_model' is your trained GNN model\n",
    "prediction = predict_engagement(model, formatted_inputs)\n",
    "\n",
    "print(\"Predicted Engagement Level:\", prediction.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
